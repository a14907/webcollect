<!DOCTYPE html> <html lang=en-US theme=light class=js style><!--
 Page saved with SingleFile 
 url: https://devblogs.microsoft.com/dotnet/performance-improvements-in-net-8/#json 
 saved date: Tue Mar 12 2024 20:03:39 GMT+0800 (中国标准时间)
--><meta charset=utf-8>
<meta name=awa-ver content=light>
<meta http-equiv=X-UA-Compatible content="IE=edge">
<meta name=awa-pageType content=post>
<meta name=awa-product content=".NET Blog">
<meta name=viewport content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name=mobile-web-app-capable content=yes>
<meta name=color-scheme content="dark light">
<meta name=apple-mobile-web-app-capable content=yes>
<meta name=apple-mobile-web-app-title content=".NET Blog - Free. Cross-platform. Open source. A developer platform for building all your apps.">
<link rel=profile href=http://gmpg.org/xfn/11>
<link rel=pingback href=https://devblogs.microsoft.com/dotnet/xmlrpc.php>
<meta name=robots content="index, follow, max-image-preview:large, max-snippet:-1, max-video-preview:-1">
<title>Performance Improvements in .NET 8 - .NET Blog</title>
<link rel=canonical href=https://devblogs.microsoft.com/dotnet/performance-improvements-in-net-8/>
<meta property=og:locale content=en_US>
<meta property=og:type content=article>
<meta property=og:title content="Performance Improvements in .NET 8 - .NET Blog">
<meta property=og:description content=".NET 7 was super fast, .NET 8 is faster. Take an in-depth tour through over 500 pull requests that make that a reality.">
<meta property=og:url content=https://devblogs.microsoft.com/dotnet/performance-improvements-in-net-8/>
<meta property=og:site_name content=".NET Blog">
<meta property=article:published_time content=2023-09-13T12:05:00+00:00>
<meta property=article:modified_time content=2023-10-26T11:09:54+00:00>
<meta property=og:image content=https://devblogs.microsoft.com/dotnet/wp-content/uploads/sites/10/2023/09/TierFlow.png>
<meta property=og:image:width content=1207>
<meta property=og:image:height content=703>
<meta property=og:image:type content=image/png>
<meta name=author content="Stephen Toub - MSFT">
<meta name=twitter:card content=summary_large_image>
<script type=application/ld+json class=yoast-schema-graph>{"@context":"https://schema.org","@graph":[{"@type":"WebPage","@id":"https://devblogs.microsoft.com/dotnet/performance-improvements-in-net-8/","url":"https://devblogs.microsoft.com/dotnet/performance-improvements-in-net-8/","name":"Performance Improvements in .NET 8 - .NET Blog","isPartOf":{"@id":"https://devblogs.microsoft.com/dotnet/#website"},"primaryImageOfPage":{"@id":"https://devblogs.microsoft.com/dotnet/performance-improvements-in-net-8/#primaryimage"},"image":{"@id":"https://devblogs.microsoft.com/dotnet/performance-improvements-in-net-8/#primaryimage"},"thumbnailUrl":"https://devblogs.microsoft.com/dotnet/wp-content/uploads/sites/10/2023/09/TierFlow.png","datePublished":"2023-09-13T12:05:00+00:00","dateModified":"2023-10-26T11:09:54+00:00","author":{"@id":"https://devblogs.microsoft.com/dotnet/#/schema/person/07639e75647242d5dd1f9b9cf6b6abb1"},"breadcrumb":{"@id":"https://devblogs.microsoft.com/dotnet/performance-improvements-in-net-8/#breadcrumb"},"inLanguage":"en-US","potentialAction":[{"@type":"ReadAction","target":["https://devblogs.microsoft.com/dotnet/performance-improvements-in-net-8/"]}]},{"@type":"ImageObject","inLanguage":"en-US","@id":"https://devblogs.microsoft.com/dotnet/performance-improvements-in-net-8/#primaryimage","url":"https://devblogs.microsoft.com/dotnet/wp-content/uploads/sites/10/2023/09/TierFlow.png","contentUrl":"https://devblogs.microsoft.com/dotnet/wp-content/uploads/sites/10/2023/09/TierFlow.png","width":1207,"height":703,"caption":"Image TierFlow png"},{"@type":"BreadcrumbList","@id":"https://devblogs.microsoft.com/dotnet/performance-improvements-in-net-8/#breadcrumb","itemListElement":[{"@type":"ListItem","position":1,"name":"Home","item":"https://devblogs.microsoft.com/dotnet/"},{"@type":"ListItem","position":2,"name":"Performance Improvements in .NET 8"}]},{"@type":"WebSite","@id":"https://devblogs.microsoft.com/dotnet/#website","url":"https://devblogs.microsoft.com/dotnet/","name":".NET Blog","description":"Free. Cross-platform. Open source. A developer platform for building all your apps.","potentialAction":[{"@type":"SearchAction","target":{"@type":"EntryPoint","urlTemplate":"https://devblogs.microsoft.com/dotnet/?s={search_term_string}"},"query-input":"required name=search_term_string"}],"inLanguage":"en-US"},{"@type":"Person","@id":"https://devblogs.microsoft.com/dotnet/#/schema/person/07639e75647242d5dd1f9b9cf6b6abb1","name":"Stephen Toub - MSFT","image":{"@type":"ImageObject","inLanguage":"en-US","@id":"https://devblogs.microsoft.com/dotnet/#/schema/person/image/","url":"https://secure.gravatar.com/avatar/2f85938ff9d752d14977fa35c0af37e5?s=96&d=mm&r=g","contentUrl":"https://secure.gravatar.com/avatar/2f85938ff9d752d14977fa35c0af37e5?s=96&d=mm&r=g","caption":"Stephen Toub - MSFT"},"description":"Stephen Toub is a developer on the .NET team at Microsoft.","url":"https://devblogs.microsoft.com/dotnet/author/toub/"}]}</script>
<link rel=alternate type=application/rss+xml title=".NET Blog » Feed" href=https://devblogs.microsoft.com/dotnet/feed/>
<link rel=alternate type=application/rss+xml title=".NET Blog » Comments Feed" href=https://devblogs.microsoft.com/dotnet/comments/feed/>
<link rel=alternate type=application/rss+xml title=".NET Blog » Performance Improvements in .NET 8 Comments Feed" href=https://devblogs.microsoft.com/dotnet/performance-improvements-in-net-8/feed/>
<style>:where(.wp-block-button__link){border-radius:9999px;box-shadow:none;padding:calc(.667em + 2px) calc(1.333em + 2px);text-decoration:none}:where(.wp-block-calendar table:not(.has-background) th){background:#ddd}@media (min-width:782px){}@media (max-width:781px){}@media (min-width:782px){}:where(.wp-block-columns){margin-bottom:1.75em}:where(.wp-block-columns.has-background){padding:1.25em 2.375em}:where(.wp-block-post-comments input[type=submit]){border:none}@supports (position:sticky){.wp-block-cover-image:after,.wp-block-cover:after{content:none}}@supports (-webkit-touch-callout:inherit){.wp-block-cover-image.has-parallax,.wp-block-cover.has-parallax,.wp-block-cover__image-background.has-parallax,video.wp-block-cover__video-background.has-parallax{background-attachment:scroll}}@media (prefers-reduced-motion:reduce){}:where(.wp-block-cover-image:not(.has-text-color)),:where(.wp-block-cover:not(.has-text-color)){color:#fff}:where(.wp-block-cover-image.is-light:not(.has-text-color)),:where(.wp-block-cover.is-light:not(.has-text-color)){color:#000}:where(.wp-block-file){margin-bottom:1.5em}:where(.wp-block-file__button){border-radius:2em;display:inline-block;padding:.5em 1em}:where(.wp-block-file__button):is(a):active,:where(.wp-block-file__button):is(a):focus,:where(.wp-block-file__button):is(a):hover,:where(.wp-block-file__button):is(a):visited{box-shadow:none;color:#fff;opacity:.85;text-decoration:none}@media (min-width:600px){}@media (min-width:600px){}@supports ((-webkit-mask-image:none) or (mask-image:none)) or (-webkit-mask-image:none){.wp-block-image.is-style-circle-mask img{border-radius:0;-webkit-mask-image:url(data:image/svg+xml;utf8,<svg\ viewBox=\"0\ 0\ 100\ 100\"\ xmlns=\"http://www.w3.org/2000/svg\"><circle\ cx=\"50\"\ cy=\"50\"\ r=\"50\"\/><\/svg>);mask-image:url(data:image/svg+xml;utf8,<svg\ viewBox=\"0\ 0\ 100\ 100\"\ xmlns=\"http://www.w3.org/2000/svg\"><circle\ cx=\"50\"\ cy=\"50\"\ r=\"50\"\/><\/svg>);mask-mode:alpha;-webkit-mask-position:center;mask-position:center;-webkit-mask-repeat:no-repeat;mask-repeat:no-repeat;-webkit-mask-size:contain;mask-size:contain}}@media (prefers-reduced-motion:no-preference){}@keyframes turn-on-visibility{0%{opacity:0}to{opacity:1}}@keyframes turn-off-visibility{0%{opacity:1;visibility:visible}99%{opacity:0;visibility:visible}to{opacity:0;visibility:hidden}}@keyframes lightbox-zoom-in{0%{transform:translate(calc(-50vw + var(--wp--lightbox-initial-left-position)),calc(-50vh + var(--wp--lightbox-initial-top-position))) scale(var(--wp--lightbox-scale))}to{transform:translate(-50%,-50%) scale(1)}}@keyframes lightbox-zoom-out{0%{transform:translate(-50%,-50%) scale(1);visibility:visible}99%{visibility:visible}to{transform:translate(calc(-50vw + var(--wp--lightbox-initial-left-position)),calc(-50vh + var(--wp--lightbox-initial-top-position))) scale(var(--wp--lightbox-scale));visibility:hidden}}:where(.wp-block-latest-comments:not([style*=line-height] .wp-block-latest-comments__comment)){line-height:1.1}:where(.wp-block-latest-comments:not([style*=line-height] .wp-block-latest-comments__comment-excerpt p)){line-height:1.8}@media (min-width:600px){}@media (max-width:600px){}@media (min-width:782px){}@media (min-width:782px){}:where(.wp-block-navigation.has-background .wp-block-navigation-item a:not(.wp-element-button)),:where(.wp-block-navigation.has-background .wp-block-navigation-submenu a:not(.wp-element-button)){padding:.5em 1em}:where(.wp-block-navigation .wp-block-navigation__submenu-container .wp-block-navigation-item a:not(.wp-element-button)),:where(.wp-block-navigation .wp-block-navigation__submenu-container .wp-block-navigation-submenu a:not(.wp-element-button)),:where(.wp-block-navigation .wp-block-navigation__submenu-container .wp-block-navigation-submenu button.wp-block-navigation-item__content),:where(.wp-block-navigation .wp-block-navigation__submenu-container .wp-block-pages-list__item button.wp-block-navigation-item__content){padding:.5em 1em}@media (min-width:782px){}@keyframes overlay-menu__fade-in-animation{0%{opacity:0;transform:translateY(.5em)}to{opacity:1;transform:translateY(0)}}@media (prefers-reduced-motion:reduce){}@media (min-width:600px){}@media (min-width:600px){}@media (min-width:782px){}:where(p.has-text-color:not(.has-link-color)) a{color:inherit}:where(.wp-block-post-excerpt){margin-bottom:var(--wp--style--block-gap);margin-top:var(--wp--style--block-gap)}:where(.wp-block-preformatted.has-background){padding:1.25em 2.375em}:where(.wp-block-pullquote){margin:0 0 1em}@media (min-width:600px){}@media (max-width:600px){}@media (min-width:600px){}:where(.wp-block-search__button){border:1px solid #ccc;padding:6px 10px}:where(.wp-block-search__button-inside .wp-block-search__inside-wrapper){border:1px solid #949494;box-sizing:border-box;padding:4px}:where(.wp-block-search__button-inside .wp-block-search__inside-wrapper) :where(.wp-block-search__button){padding:4px 8px}@media (prefers-reduced-motion:reduce){}:where(.wp-block-term-description){margin-bottom:var(--wp--style--block-gap);margin-top:var(--wp--style--block-gap)}:where(pre.wp-block-verse){font-family:inherit}@supports (position:sticky){.wp-block-video [poster]{object-fit:cover}}.entry-content{counter-reset:footnotes}:root{--wp--preset--font-size--normal:16px;--wp--preset--font-size--huge:42px}html :where(.has-border-color){border-style:solid}html :where([style*=border-top-color]){border-top-style:solid}html :where([style*=border-right-color]){border-right-style:solid}html :where([style*=border-bottom-color]){border-bottom-style:solid}html :where([style*=border-left-color]){border-left-style:solid}html :where([style*=border-width]){border-style:solid}html :where([style*=border-top-width]){border-top-style:solid}html :where([style*=border-right-width]){border-right-style:solid}html :where([style*=border-bottom-width]){border-bottom-style:solid}html :where([style*=border-left-width]){border-left-style:solid}html :where(img[class*=wp-image-]){height:auto;max-width:100%}:where(figure){margin:0 0 1em}html :where(.is-position-sticky){--wp-admin--admin-bar--position-offset:var(--wp-admin--admin-bar--height,0px)}@media screen and (max-width:600px){html :where(.is-position-sticky){--wp-admin--admin-bar--position-offset:0px}}</style>
<style>@media only screen and (max-width:600px){}@media only screen and (max-width:400px){}@media only screen and (max-width:400px){}@media only screen and (max-width:600px){}@media only screen and (max-width:400px){}@media only screen and (max-width:400px){}@media only screen and (max-width:400px){}@media only screen and (max-width:400px){}@media only screen and (max-width:400px){}@media only screen and (max-width:400px){}@media only screen and (max-width:400px){}@media only screen and (max-width:600px){}@media only screen and (max-width:600px){}@media only screen and (max-width:600px){}@media only screen and (max-width:500px){}@media only screen and (max-width:500px){}</style>
<style id=global-styles-inline-css>body{--wp--preset--color--black:#000000;--wp--preset--color--cyan-bluish-gray:#abb8c3;--wp--preset--color--white:#fff;--wp--preset--color--pale-pink:#f78da7;--wp--preset--color--vivid-red:#cf2e2e;--wp--preset--color--luminous-vivid-orange:#ff6900;--wp--preset--color--luminous-vivid-amber:#fcb900;--wp--preset--color--light-green-cyan:#7bdcb5;--wp--preset--color--vivid-green-cyan:#00d084;--wp--preset--color--pale-cyan-blue:#8ed1fc;--wp--preset--color--vivid-cyan-blue:#0693e3;--wp--preset--color--vivid-purple:#9b51e0;--wp--preset--color--blue:#007bff;--wp--preset--color--indigo:#6610f2;--wp--preset--color--purple:#5533ff;--wp--preset--color--pink:#e83e8c;--wp--preset--color--red:#dc3545;--wp--preset--color--orange:#fd7e14;--wp--preset--color--yellow:#ffc107;--wp--preset--color--green:#28a745;--wp--preset--color--teal:#20c997;--wp--preset--color--cyan:#17a2b8;--wp--preset--color--gray:#6c757d;--wp--preset--color--gray-dark:#343a40;--wp--preset--gradient--vivid-cyan-blue-to-vivid-purple:linear-gradient(135deg,rgba(6,147,227,1) 0%,rgb(155,81,224) 100%);--wp--preset--gradient--light-green-cyan-to-vivid-green-cyan:linear-gradient(135deg,rgb(122,220,180) 0%,rgb(0,208,130) 100%);--wp--preset--gradient--luminous-vivid-amber-to-luminous-vivid-orange:linear-gradient(135deg,rgba(252,185,0,1) 0%,rgba(255,105,0,1) 100%);--wp--preset--gradient--luminous-vivid-orange-to-vivid-red:linear-gradient(135deg,rgba(255,105,0,1) 0%,rgb(207,46,46) 100%);--wp--preset--gradient--very-light-gray-to-cyan-bluish-gray:linear-gradient(135deg,rgb(238,238,238) 0%,rgb(169,184,195) 100%);--wp--preset--gradient--cool-to-warm-spectrum:linear-gradient(135deg,rgb(74,234,220) 0%,rgb(151,120,209) 20%,rgb(207,42,186) 40%,rgb(238,44,130) 60%,rgb(251,105,98) 80%,rgb(254,248,76) 100%);--wp--preset--gradient--blush-light-purple:linear-gradient(135deg,rgb(255,206,236) 0%,rgb(152,150,240) 100%);--wp--preset--gradient--blush-bordeaux:linear-gradient(135deg,rgb(254,205,165) 0%,rgb(254,45,45) 50%,rgb(107,0,62) 100%);--wp--preset--gradient--luminous-dusk:linear-gradient(135deg,rgb(255,203,112) 0%,rgb(199,81,192) 50%,rgb(65,88,208) 100%);--wp--preset--gradient--pale-ocean:linear-gradient(135deg,rgb(255,245,203) 0%,rgb(182,227,212) 50%,rgb(51,167,181) 100%);--wp--preset--gradient--electric-grass:linear-gradient(135deg,rgb(202,248,128) 0%,rgb(113,206,126) 100%);--wp--preset--gradient--midnight:linear-gradient(135deg,rgb(2,3,129) 0%,rgb(40,116,252) 100%);--wp--preset--font-size--small:13px;--wp--preset--font-size--medium:20px;--wp--preset--font-size--large:36px;--wp--preset--font-size--x-large:42px;--wp--preset--spacing--20:0.44rem;--wp--preset--spacing--30:0.67rem;--wp--preset--spacing--40:1rem;--wp--preset--spacing--50:1.5rem;--wp--preset--spacing--60:2.25rem;--wp--preset--spacing--70:3.38rem;--wp--preset--spacing--80:5.06rem;--wp--preset--shadow--natural:6px 6px 9px rgba(0,0,0,0.2);--wp--preset--shadow--deep:12px 12px 50px rgba(0,0,0,0.4);--wp--preset--shadow--sharp:6px 6px 0px rgba(0,0,0,0.2);--wp--preset--shadow--outlined:6px 6px 0px -3px rgba(255,255,255,1),6px 6px rgba(0,0,0,1);--wp--preset--shadow--crisp:6px 6px 0px rgba(0,0,0,1)}body{--wp--style--global--content-size:840px;--wp--style--global--wide-size:840px}:where(.is-layout-flex){gap:0.5em}:where(.is-layout-grid){gap:0.5em}body{padding-top:0px;padding-right:0px;padding-bottom:0px;padding-left:0px}a:where(:not(.wp-element-button)){text-decoration:underline}:where(.wp-block-post-template.is-layout-flex){gap:1.25em}:where(.wp-block-post-template.is-layout-grid){gap:1.25em}:where(.wp-block-columns.is-layout-flex){gap:2em}:where(.wp-block-columns.is-layout-grid){gap:2em}</style>
<style>article,main{display:block}a{background-color:transparent;-webkit-text-decoration-skip:objects}a:active,a:hover{outline-width:0}button{margin:0}button{overflow:visible}button{text-transform:none}button{-webkit-appearance:button}::-webkit-file-upload-button{-webkit-appearance:button;font:inherit}h2{font-family:"Segoe UI";line-height:1.2;color:inherit}h2{font-size:1.75rem}code{word-break:break-word;color:#c00}pre code{font-size:inherit;color:inherit;word-break:normal}.container{width:100%;padding-right:15px;padding-left:15px;margin-right:auto;margin-left:auto}@media (min-width:576px){.container{padding-left:10px;padding-right:10px}}@media (min-width:768px){.container{max-width:720px}.col-md{-ms-flex-preferred-size:0;flex-basis:0;-webkit-box-flex:1;-ms-flex-positive:1;flex-grow:1;max-width:100%}}@media (min-width:992px){.container{max-width:960px}}@media (min-width:1200px){.container{max-width:1140px}}.row{display:-webkit-box;display:-ms-flexbox;display:flex;-ms-flex-wrap:wrap;flex-wrap:wrap;margin-right:-15px;margin-left:-15px}.col-12,.col-md{position:relative;width:100%;min-height:1px;padding-right:15px;padding-left:15px}.col-12{-webkit-box-flex:0;-ms-flex:0 0 100%;flex:0 0 100%;max-width:100%}@media (max-width:575.98px){}@media (max-width:767.98px){}@media (max-width:991.98px){}@media (max-width:1199.98px){}.table-responsive{display:block;width:100%;overflow-x:auto;-webkit-overflow-scrolling:touch;-ms-overflow-style:-ms-autohiding-scrollbar}@-webkit-keyframes progress-bar-stripes{from{background-position:1rem 0}to{background-position:0 0}}@keyframes progress-bar-stripes{from{background-position:1rem 0}to{background-position:0 0}}@supports ((-webkit-transform-style:preserve-3d) or (transform-style:preserve-3d)){.carousel-item-next.carousel-item-left,.carousel-item-prev.carousel-item-right{-webkit-transform:translate3d(0,0,0);transform:translate3d(0,0,0)}.active.carousel-item-right,.carousel-item-next{-webkit-transform:translate3d(100%,0,0);transform:translate3d(100%,0,0)}.active.carousel-item-left,.carousel-item-prev{-webkit-transform:translate3d(-100%,0,0);transform:translate3d(-100%,0,0)}.carousel-fade .active.carousel-item-left,.carousel-fade .active.carousel-item-prev,.carousel-fade .carousel-item-next,.carousel-fade .carousel-item-prev,.carousel-fade .carousel-item.active{-webkit-transform:translate3d(0,0,0);transform:translate3d(0,0,0)}}.justify-content-center{-webkit-box-pack:center!important;-ms-flex-pack:center!important;justify-content:center!important}@supports ((position:-webkit-sticky) or (position:sticky)){.sticky-top{position:-webkit-sticky;position:sticky;top:0;z-index:1020}}.mr-1{margin-right:.25rem!important}@font-face{font-family:"Segoe UI";font-style:normal;font-weight:400;src:local("Segoe UI"),url(data:font/woff2;base64,d09GMgABAAAAAI34AA8AAAABC2AAAI2bAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABmAAhiAIlCIJlFwREAqC9GCC0R8BNgIkA4lME8dcC4lQAAQgBYMgByAMkEAbzvOniKbV4h5GFPZhRaQm9QD8//+nhDCvbXsVEH765bc//vK3f/zrP//7i8C4iY91nm+IKKfOCtwUgqyoSC8GclIAQMcFAuv+L1XzDwCKEDmUhkV1XGZ2BDcALpXuWIGgC9zY3hvIPoAyvY/Sac+pzG6H9F6upd5yy/tIpfeU2k7JtZR6Co/euf/fTbbCzCalmF0z/dxkAwWOoAeuOE3nJ2mfJvSqa+TIe47cf07tfzs4IxWR3NSCxAEEFexdtkphKIcALGv5tG8vBxyguXWDG/UiyGgBqRywETlWRY6oMejBiIjBiI0cNaIGTqTEBMTGxEgsfBUD33yruPoszc8s16aqu6q7p2d63M7sYgeGvWTP7tAN3dThHHiHEXHESWKLauDkPM6SPAogFECIAcrui1hFcL/09YwjRfDIlQG1oub2LCiH8+SJSzkCdIAsz3Gm/6ZWjxr4NQuwpY4ky/aTug2Rlbg7Xu/EgwH07CozS3CXHIGdBR+BVKUD/j/Obu14OZdSaVGHXgIfcB9+pgzPI53fn0luZvrkJTArsF9A1+6Savx/vs28s15lqXhSS5MaK+xErIqvDyReA7rEsbWxyGfroZbDF9nW8R5CqqTCrDip2NeuQ8XhHFae/987tfscpQgOkAoYQgWdAgB99ewfcJAKhK5PtW9GCyQvuWP177SmJa8jQ6yQAuQATwAdK1HtOt7kSAcBXqA5Quc+kyXlAPjjb5+zpCPAPwD4/021t33zAFDARkr839Y6cp1TvblykKuUSlcuwXvfzEj34QG7bwDy7ACQzg7IH4aSw4DinjNQGIDSHoCrfw5IJ0pO0ndK/DENxJUOqAiu1rv8mQ4pSaq8WzmFLoWmcBXb0u7WnV26deei6kKE5/m9aVI9HzdN6l2UUiphoWHs+f4Zed8/rvJWzVYpTVaqJlXe3lAACmCta2ZbkzZV3rQmJyiLUACEweEBkOUxVEuyd4yCIiBg1y1DzSL7xm5LsA0ak/bzKuG0XdftgZOUDg2ynPfl3v9ydB77udUXQSgR5kLI0LIdKa0KLEC4gy/J/8NAN2rINEz8zAVmQZDY+oXq12mvhfiZWnpTMzRD0/SRkBEolaYYuFody6Ik/r7/5k2nlvj7rdA0C4R+n4G54PQsdLBSp9ycAUMP+4ekNyUxKYA/w1Fiir/kl8JSWspKNakjraSLDJQhMlxmaEW0s9p57bGu61n1k+ZUV/qAEvFBVrAVbsVYCZZtZbHyWYWtstaRJDspi63ZLjvQDrHD7Rg7wc5pV7Rb2u0yb8h84Z/hK+H7rxTgj8UyMSWD5JfCUnrep9aWlolhxpnbuveBg6xQK8qKsyyj0C2XGcGbohNtt+Ar/gOnfqhnoH6ot2q1Oq6Wqn1ql2quktVcVUYlqw4q3PGAEwSO4XviK/Jv4b+or6nP/lB8K3vHeOd4R3sHQmqX1EGeuakJnkngWQuefp5enpaefJ78D+s/+ATaZT3LGnzR6Q4UJeDajP+Q6SSDBEmYRHVLWI9c+aOpKEnh4/8UrmQVoxgtLubykjFMZRKL2cBqJjCR36QwSxLFYgrzGMdJHksSS9jIN77ynRVs5jxn2UJr2jCdtlykHee4wFUucZkrvKI9N7jGdbbSgY/M4DY3uUVH3vCO8XSmE13oRle6s4we9KInvelDP/rSnwG8ZiCDGcQQhjGUfSxnBMMZiZu3vOcAd/HygIc8IpV7eAiS3OxgpxjsYS+n2MVuTpPMCcZKOkkvGfghuvhLAEoCJUiCJYTDEiphEi4REikxEitxEi85JZdkkcySR/JLPskrBVjAB/6wRrJyjOOSTbKb74kAcwFRYC4gCtAGtCwcp16r8bU6p7qTXf0YWcE50Pu02mX1wVyOv1ZRvdMb4Q8L1Dtuj0B9MAoSwio2MhE3A5wtVOV3zRkoNYGk+tSNLs/HXoykNcUn8h3usGcb65h+vMU6VmF710I64spzmQTlCaTA0llMGHEYxdX24mUZz+WIaLB5DGN+K09zEjeVaUwt86H5kDE0ZBoNmcDIm7xaA01XGsgABtOKwbhv0m0ngJGBdPulmYGbGUxkGXPlJlXpS1vWMfzjJFdGztOZblSlFZ04xwpGMpwu5gKCtUwE66hPuOlAL4oLnkob5nDMOeR8pS1t6c9Q7Sf+GvxS+Rtz1DfqUp7OdKFqmk5Ofp5z6PZujMsEu5YNqw/OMzewh67nK+0G9tGVgxzfAgqnja+br79KVinmG/OZccR4r7c1ounOCCaxkLWto6azzE5/FSd8S6RwiFnMUqPVFmrTQ8fnGvAZaEP7/7qQwgfhdXgdnuy+j//T8CHQ8HP4BMSwA5+f/e54vx+DEfwctiD+mV94EAxeHz3eSvrdhw/u34vv3rl9qx1uvhjcvHH92tUrl5uXLl44f+7smdOnTvqee+L4saNHnA31ghSHDx08wNfXVleWlxr1WpUtLlRouTRvF+cKlmkQ8MgqroY62sW1MEWqWooJpA/+dv8UQo1LVRXnTiW+R3r+SsSCi1CPsfFI5xA0E5xz3974B2g67B8SoXafiwgtBy1H3R2O8FhXS8V+wt/WnyS+h+uhlpKj4aDh3EHTQdO5OxQjZI+0JCI2Cy480tdHMJ39oik5QlMmHKGr8RDqc0wSQb+25wCzL78O8oBkLKdrYQuhkQP9BcJS11X/1gSEa3jMRcNhCNc4PiFwCknjH0jqSJbuI9SmgaGf08+adjh1NNpV0WgH18JRmto197eXnlJkIuvq6jkupeCrx/jtjs7LpVCFz0qJ7wHyA0BeKocqLDciVS/nhN4gjXiDRldyA+yK72FNZIquz9zFYC89XpxqSSl9D+vUE6azL+8/Pw2w5raSdSHIO+FciMU3u9jBYIiwJ3Lvy9n+lMF26tKRGg2faDSHie/lYDrRuI8H4kdbGs0bM910LJZctiqwgEERjUWmWvTgOEXTUa2Fb6Z5o/Gz1FXuI6lqneudD/Wb8ssca6F+M8KqixXVwsq7fsXNLFrdEaiXkGVvCvxUR3+TrA2SJMmq74ksUtE4bfletLu5LIVTS4ce6dwZLdA+wd5Q4GR71//Gh/sxMCwzFvyP5FJKuUQ42DSnO0p3xda7Q1Xrol2R7T1TV+6rF5SSi2i3dYXBvwgRIQxwNdzS0VhFk76UIlNDgabzmwUX19zTzbJIzN3D0abvib0E11wdIC56cJeg4YQY9KsO9NdhbxFhMGwlaLMTbQ0FKkuLiVz7WNMRWHTeLJxUIuPKiqs3XCa/Ln3vy74Xd3XU4hY4Dxqhvv7nVf7nxPfiR6R9yWrc1dmpP3M77Y57Ku54Qn5cKab9IC4Yq1+VMhmDnNkPjB+8tm3VTrOsrUQ7S7PhdDbZVoKpLKc0ezlKRfQPRIbT2Tt7HNv7CbJ0TK74nvC5YLsbY73zeIkm22I8TBgH3FSyyWU16XdEj7qYsfaOWAxxLj5jf/I9pKGWXLRTzNbp7G9NzZqh2igQBnrK4KnfYiU0ROhpNHi07GUmTrTTM9I4l04DuU91KH7ie1LG0Un3pgFs+57ESUfjmIjhn4XglJugkVKHvnzN0mBoYrN4haRK+t5q3PPrJp+uz6qqJi6fWgPosvKdEX65r6ez/zXRbi45q1dNbrS2GNxsLLmKiWu44g4Gu6wbj7kZU+LHCpmLhVB/mV9LBKsi1Ijv4W03coKGw36svkPyZxgaDMk1JMu0GtSRpPX7mStNJHUHmhJRlnpYk2rmJvC5GI312xcthymk/+Fj3GpNaSm/n9bMbK2ddjwVuezl3U1wISeXceFPlVV8D3moBZI0Qug0PBGJ8YLXUKStVLAg4SR/OvtZ2kp9rhZRN8Vdu5hw927lbw+QlxsT9oHVxld8D4MT0vfEBSRpxJT62lK4VlZ6ojvqtOhjW9LqN4eFF8Z9TJR3Fj4TQcb9Jzh2YttlJ3BH3XL503y3uwzdCQIajqjeMezXnM6+3OT4yZ7G4CkQd/V7+bv2lG9hg2zmirzVyQPyVm9L5wZsPmcA4q2+/qxBjDDdTPIN8lZHPxcAwS834AkQXNwMMYm73K5P+PMAYNKDWzL5rT2dEsAP2VnIQtJIMCc/MtnMAAx4OrWo+WCEYSXtxAQLnYMN+gWlQmAH8wE1KgbPCXqNny0E9jsEYJ7A5yipEJ5PjLBLmjklk3w+4L2MSS6QsuutwfSNgy39OQoVwmtekiSbxWvwPZygET5CAl7/MbKFjJGKoVj/Ds9YynYxcdMa+/WViGin5Xu5Q956pFevJ9iIu485ksR/fD4L4RLUoTibweIdUE3OPY78boyXAMh70is/TKufpq2FtPGhndsP4NE0aZRlEwqP8beEdqMOV2WOsbBifKRvy29rxCGWFscmvi14HNr4b6rZDMxZ0Ty34CktLS1p2k2dm+whXgA6gQKlKZVpm4hOVROMeQW0m6OftaKsTTaLyiwKMbvditpIcIjU7DFtFkWMM2cScoM/FIpa5AtjUG84VYEXK5iWjMgYwTJzYMuyqGUdsA4XC5RalLYazCqVFinpAqr2ontisbghG/WNRkM2KL39PWtblr3BzpVtm9n2sm3T0jq1KtW5Aw1Ky/YSO1i+aC/QA8sLJduybctaKlcry9VKvbi0VqlRq0IrlqhTWq1UK9VTSzV6oLFUWrPWlqplm1K6UjxwtETZEUrrNqXLzLYobTCrYduNUg+DFGVRFiOD/SjLfX0g5cj+Jewpl/fvlKLYMdrbWywXi8WilHIQR0tSCCFKhq+5KMSBxWKvFL2iTwJq20dKUeoRlpTYLURlzJMJKYfRKlctIa299+kSFkKpd2+xv1UYkT19Bx9VhrOOGhGiWO7H4/YWQpTL5c7O0V4xNHDaYH9P5xlde5eLRTGKpQFRvniwY6AkRGlsaFiIg7uEOLwsjjj++P1Hz+7o6Bgbtg6+bKx6OlLVb1Q6bKpDw48yHuYYpyxIyADTMsAkJT1LSQ9q4EFNaqsmtVVDD2voKfDwagY8cvlvKRayjIe55shSh2WuSFldfsNMEhak40bOw+Up9HREymD8fMmoDuTT4/woy7JzP0ySBFp1PMz187/XKR9B6es9Kj1e4zn5Hh5mY/jQY6PBcTr1UfrTdxh/cxJ7M2nE+a3hrCzLMvfbRKQB0pTC7OcMokQF6Wc/nZLnKv+puRY2Cn9ewDWjOQ6bZmse18WfaKujJjxXb9fbJtCbIWmAKbllomHNeFC73uYVx3Iz6kAU7JSY7R50T55je/LPclX8yWpXoOPZJEmO59/I5COFWSbGcUlyOlfISxKVCFqusE5FAzrP85xoHkQut8zZ8py3JHBsm6GMFB/tNrcyU8RQERkYYNr86z5dtwrHvAmPM4QZRF9++eX+WyrM9p55NfuhoUH0SuwwCYsMOxWUzGhF5HYPfXr227lTQb5nT57nR9m8WpN83suWKf+dhjhLQTMpcMYdW/DJ301z2rIXwBOONJcruibt9XYT7XWc8qBGDU7sGnYtdfKq6ORVqvPr+XXcX7h/ElsY286gA862hkEvOvV9Hp72CcZnvMeCk98l6frwcA/G6T74gMZ/sMCJf0taG3J1zWiuW7FmiVzdMFubVnvdCHZC1PD0tRBM2B4Q+tP3u/DoyCSSJalWbOLaf6BhdK3ISVGvUALsxDrBJAzXimTdIpprslHG9qb5Z7tqU4XZxlVS/TMEUIVEaR4Pfu12Q6FXDIpKAS0gXJF0lUv5TxibJeyGm17ug5/14QOHreANVZvQrxCUQg3J4XVovOxCyoqarJrug/lxhASNl4+Eh1gZf/9BfJyX8EozVJtrDQFmbpqtjWUBepfXYFrRjWzJK1fdzGzp3Go7qdFUn14+J7cnjUglRtNJMda52XKzbpj43AtywMOKooPYWz99lh7REB5f0fw9F0Gf63IzR7I9HXxooZO66oAkfSDJq/Qn++ZCCYtNq22WMFuG0H/NwSc0taczFxKFT6Rl9B+r/3DthqX7j4R7D1+E5SWce+0YzI9awEWqCyg0cMddDj5y3DLVq6yLk827r5VkMfDRhwbOSY4E3CJYgkUg9Dt5lWAeq8Ah8bXJ1sxMyzc/o20olThTeQbYIp0ix3gXa+6EaDqXPhRECSUQbfBwU2+kF3U3X8hXMzF2sID1EWK0JttyRc160SZv6QZdvKL3IWIMGRSh9K9yiK7aKfQnO2BLbZNxovWROE56VSi0EEoIPEjboOh3Hv6B8W8s+NWHDpxxP4z8MWif6BBfhXkwgLCICzjrqBWCAveCYFzswKxFzjF/lXT57Mpog7c2MV5nwVogOtmMix8Js+BRPhRs1Uqtbvp4Ij/H+AStwHPNw89/zi51uPSPr370135KLwlc/S2smgVbBrRhMSkYO2dVlyewahZQNGXJFdxP7oixHcvwHqcf3hcePHpyr4f2wUf221LfUKLFOZh4/ki4U3mwsITjLx2BNarvhOhE/h3GWjfQv2sffGA/ovpes/Fk8+q1/zPN0OU5N1szLGFGoFjKjCB15oDw+oQZza08z7kZap7x3nX/NYzAoRQNeVKCjmAPpVOanXEn1UT0a0ocD7M0N5O2T8L0Vr6xRpNzx8R9g+lEMeBbqX3PYrqY660Fp59V7eQ55+6H1o0xmMUkC1TlenbW3jF2LuNmPNRZ51EWpE5K87zI6dSxsFe44MM1V8JPWDOcFN8+n2aUoWOEp9h/jfkUxZfwLLYG2S0LD7Hhg5sBGFAY4n3lzDP3OCoDPyGKrYLa8LXXE4j+F6z1BCZ4MMHucY1jDesgoAC8QrNQi6F22X6DyPagBtyqSV6poWcx6Vlkm9IDqm4P+15XgMUZ5epsY+ihHZUazTW5Sr/TgUP1NE9XaScYqji+R5+nQTSxK0bGZ3cL23Q3iYpbq7nVto9vszTVpsUFK1lsyOm45NYSTr12DD6ia90AEHHSDXiMCAiBsAgI98hI6TCtGcHOtXzYsInxeAbRTgnWtsfv4tTg3azTr1d9oE4fqPtDf0U+0vWn8vcw5vSZX/GobxNqHb5LnDKlDi1lPbfN/2+GGxCtseY2ZvNt/5Nk19YZn7noquuui7HjXkwnOqG483ZIRT8duaJAorKQm5V+xbl+cerulftykPxvjtlyL6ic3lAtPiUj8T6E6MwMpeMD45K+w5SmIIKwBNzaQayJUQoZTO6U0YXvgdoW4Kit+cEvse4HHT+wtu4uTui7jWxfeFDVCeYXcNZrvWeahYV59MhXTROfdhu3NvvYV/uV7EilNxMppjATV3WkKy24nJP+/Ku1Hcwt9nbMS8zt4t1qWCSvimlq45+myezHgl/nOnl1ESV4alyEpWXcsbS4I7M/XwKrE8Dxfh7uBxxzC11FWcxOnAqTu6xYX017YmXuKDmfE+3mPhHktcLK9nGobeXbtOspl2XblTNT4x7UIOpqih7w8upI6sfIQm0/cBXUkAKZP5VBOM1JcktBKpmLLr/J6bR052LY4LZARgfyt1zfARDtz5HFqSykdWLlIPakNa6LPJhAR5MSUFBcl1DoZSihDyXEGKkKeS5EypyR6wapP3O3ujMoBZwZZ+u6YU4iYyko0nRrwZsswjDPFGH/0JImMJjfAjU/6y7M67kFZ3a58GNyMX8nz/PTsLhiG1/LMmHPr4xZWyJHBYCTLk6TLLYCa+n6Um0KOJY03WE4pytTlgDtv8H/XKlshVUDJ0ySvbYR/Af/QNtsSf9bpsEgLtdG3bc7wPgsJ/PAmGenHBUWONjVQ0SGNClKFlgEnSuKehYB+0ei58r3aBQIZpIoUm7ipPxQu9q5CuLFCSxQS0o3l9ZMaM5XZASEya8OUbdtZkcnpJewn5PxmllhUs5ntEjFbx2gUd311AHs+xPrdV7lNPZuVbufAv3+qQp05VrWup6YZKHHQvRkT/25jw6hp13d10yYcVd8uV2jv/g4/eqrE9j72dc4lC4pJXN3v9ULHrYNkWqCgznZnT2eAdyDZd66IpJcxqXpaK5rhCaOB0AXGdh2TcCSDNa/KzxECuFIGS9WgHgsoxRCoJAQFOqXg6GI6Vb4Nyd5SrQnVI+Pn2Lb5rNkfHiwtfKEqraxk/XLGu9JjBt4gBt4MBQFoGhAF9b1z9fkjAQ4XIYihN+mvVAA59plRITw9YvgARaOQ8Eq2bDyArVHO6Nl1gKMfZIjKytzSrq9xzQPjF35EE1xJUZzQto/JzdankPsn7EUQvLyViUwMWiLNphdszoUE4J+EkdEwmlAy1GRcrQwnbGUMBpRin04mzzXpvlZjYUYZWxqr/qrqKriWc4DYeFjq6qKPF3gyV5Jlp+4T1MYmCsOGaGyO758hQLG7Tc83r3OGUKNdV1jKKsDpzvd4yR4SebGj2x+XJ+aUFavT1vR06XheIMqikP1yS4qh1lZNCt7dcvEdGxtpydn4CSTtbodzK2V6ScgshaJopaVFR4J5BJjwRokQDEke6A5A4Wb1jGEzS/2k9XrDLElbL8VXHspHLBA1S8jp5hRg+DG2lgAQl7RGGKCZVWnBWeJwDRlFzCs530bUBSBoie6+7EC4wklG5zRkCfBik5u9A5LFrXu6bRrMJq2j6tDl3C85jBQ/LBbFTvOM3Txl/U1so54wdIRTN5FDW9/MweZ8lPHO1pQYg9FVjokd92qokpNgkYNsEFbDw1qXboWjATq0fHUER2Wqw5WxWRZpVrU9DtW62lfTVEUf2WdaeExtJGDfYCiN1CMlCS+dvGf1npgwPLwLmHq4mlfSt/NZK+FGOv68B1qClBMAi1KbNFhAn2dUaVsZQmzCMHm8i4rFJLicrbtjMTYgT1Dl6bQpUTaaspO8t5Vlwjb232WJAZwVQWodEd0HBlePaWcJM12N4sslkB6vzWNd6hDFPnEmKC/Zryma+Q5hw+ltCIeDcJWTqpXzfEWipq6NS+tscCw0SJGKXEIBE2WCFNvvUWAjluzBwwokHhdLFEFE5hnCZFv+5jA3EvIEO9jLthj91KT5Eu8iC/x0iwA1Ylo4SyQJ6C7KGFoOWGGtTZbhyoivrXcqCXlt9rPhEBfFnbfsgP7weQa+uWvbuSl06JrdsuIelq75thNyNinNTe3f14HlZNgHj8EGa07bpCbd6k6mxlUaLQMNq4I1XQMrL9rLCz8hHJHTwO9yy3d0YMUm149xljaNYZITWVFn8H8sbIES80DfnGCBrRZ78HcuEITiS1T+EyWLKOs8oKR/aPtQwvK71ZSfE9sE/4gtgknSjKaHzWvWx2fR0/YfU932Nl+W3noyuVDh65cOXTw6pVDh65evrz8Zl5Pas/vPak92+/86bAq2PbS/rXrgpeLL5/zL//Wv3ymf2m3PNjxwv6VK4JX6lOf61P/5VMlferb4H+v7v+/J9D+56A55Ru+Om30hkh+DTbVp6QOzWevaAyqHbC9d/Szv+6j7ZIZn5zWhNfdvUu3r53XL/GOeSLowqfWD/bufW/uSx/PqOkvr2+bLMr92FVZ2TltTvAMfyklh37n7hEsP00O+u5klPPZbyvenI2v0PjXZtQMlNV3TBfkfOqp+tI5bY73CpOfJl7wb3P1UkoJ+rrG8Hj1WWHT3TM3nPQpQboXF7N3uIQ1nHwRdCvXL7fqp6IbSvuhexsMp3Rnkn313+/TPTLuc9Mdj7yZ9EPRD6dvrIt86OHpFJ7yOMppceYuh2tRxVH71rjubLlcyeUfunL47K2av/Zs+kP4958eTx9Fp2vN9Ap9jlMI2dkjKrGOHZNP8NbdTPagB1ilUfH2ScH4HEPYzT8IY4KAoGoYm5sMhFtoki4fVy6zKsldgxFEx9uOb2MQ2h1jZOUd04SuJT++YPYQ2p3zvvxwLRE6p8nLUu3O+O1wXv6YRuuTG5BLoy1/hDlbl0Jj1W0b1W1lYpMoWBVhR21HR11HR22HkOK+MfQ6L/c1Yd8PwypDnUdqcDQGDkdj4bYYLByOweggbousZOp7LV/Ua3mdunkArVZ8bD42O1USlXPQXW7vUdSuolMHYvNO734Xb4TMINhYWNwSrxmS7cJt4y1+TUQVInJRSXg/lK4d3hBrHkNEs3a52EVoBdv4eZnO4bGTxJLQTkRaDKqFGWTa4FNUkOHnGk+qTqCH6oW6XezII0WaNUWUCcs4Pt7O7ASvBG22h3tbVwx5kJu54Jl5udB7rjVriVZoEkyCJ6C1WguasmLlPm/v4SYM1fsvh7fZJ4W5lNF36vqBZNkSp7AQRH62o4lo/5GuI/6j/qPNzOTjH2a+Cb8iMnVP7391jFpde7lwdxoP5dF2KJm0h1u0hMk5H+0+08bs9Sm1CfGH5xD4S4P7df//eLra7kq3UF5H/D9JSid7v3tpOno4wOvJuWTcbEHFODEmdTIsX+L5qXcpwK7n7lperTDMvC/dpSS6Nyit3229HoydfxbV5ZWS6zqyu4BmUkBkJFljPZNsaD6WbHeqRSWNxXZCoxLgJIZZLtHLxF0uck/STc4npjRRQalybkcFVSEKSH4bdy6gp/GqsNUmrMXVKBsbF+v/MhKZNhrn61HLielwCg7pcObEuNf6xKWNhiPXYvyxcUbZrlG4vuL0Sc+kxD2eJen4vn0cnDmHSksxx3glW9Bplhyshzmb5ptsg0WxLel0qxREKNI4GI0OMra3DzbxQpsEIxyMQ7aCjRGOwSYotEFIBOq00Yo3ovPWWnpjM8d+IB/Li+nxTe5x/rcNjDjyLLIXnZHvORaXgp8tLpcQ4lMngrMm3D/NyTMsebRotgPKPQFODbTMJdDNC2gBKVYY13hLKtkylqj4yQWOxsDhaC+4LcYLDsdgpD75wNEYOByNhdtisHA4BuOx3cjFFo2Bw9FetnCMFxyOwVgxhl7n5b6OI56ocDw55+548mlXVRxY5YqjYDenuFPwKe4UknjK1vHkXGeNs0xNXJfjyac4H0GDYoAFGpFICwsLoAUiIl3sjCn/MzRt95Rw53pYYnqtWbyPa54PFZnjEx3B8AlAhjnB1ah7iEPWu5TgttsBGxtguy1caReRfFIMJb+90zBxYe/TF5ZHyZmUb+BO2eAyuKnC1YLU5leLsIgIB4uaIRdkZqHrtxn/0imKdOrRQ3HpN55wApc7CO/+s9vz4B/c9tKe17P5ibzg0tavq3cW/PWBxe626Oa2JcME0Yz8p6zHsdMKGLD/1KPYa0cBqKhn8d7B9uKa/TkmYKvy9BHhEdmNC0rjUlenGge4RddhJxLAZ8LRpuK/4Q/JJzwGGW8RGQ3o0IHdqNVat/29QYvfEBRVGT2nV3cHWL1HAaiI/3WJLm6PUSRIpdzRdrVRM6N2H/gOQEV3e+zWZbplvvpluhKk7D7IdMuUSACo6G6Sz4nYtSI5ZHET0Vs8iftvkLY4nfbufyRNTlnX6YukGNvu1vN05qOk+UWzBICKJHkv8iRF8RIAKpIoW0K21rQPBoZMBAdvVIkkaaP/WbQ8SwVPSQCoSDIK3i7WyLyeONsv3gSgIgkAlULXJekDu09lK4pBjWgLPbFPgJ6Q6KsWC8oGnT4xCkBFj3bWbCKyN2Us83p1YM9uLAYCwBW4ccGinkxZ9zYJABXdt36WYE24AA50fpRM/9GwT2/Dhuf1YS1SWnCsnG6VFcRTLYK8vAp2/Y0SUk1H1rEqTldPAkBFjS9+/7u6qin9/ugGfW7m0GCbjl/rHw27I+cPncdGLK4uXcaYHzx38ByOtXBpTqVd317xQrK+rAniKX+UPyovVz/aMLz+htfL61XTremtETmdOP++TdbTB21PVbdtjJUAUNFU1CA8l4VpjqZZlwbE5OLJKqAX+RuceMX4E0PumVeKiTfRKhGdI6wULBW6ntWNsmXrJ++w6evJTnVDBIURi9FEI6pJlTeL6ZTvFxvU2sSct2HeikYsl4ecc05TD0I6+rs7m/v6YrI9qcZ0kwZGUoJHiV9KQDs/4rB5omGcQpJqpN4N9IrUIACVkgBQqYGejXLvAHykgQIhTRK7kJs0mSUp9kkQGTiKFvRrRUuat7JM5UlgiSZeKzDjfD5UpBUkWlHJ1VTBSvuAUAqMoCLUPq1NEC3AVOkqeJAKxWuFw27RR2Bg4HdZOohUD1IJ9NvCiy5TjDd1wa4KhvGVf68tnL9i/O2kP7gLk2f36eSpsyeIUJFuR72KZLvOTf5xNC9ChybddtCXl0AkZDtw7zv02No6qN782wNMOBMyAZnHmQWPAOjHR672jz90W6o39mmNETIK1gHox/WCDEdKbGYXLUXGIaVDOw6LMXU0sAgoCFDSzT1VASVJdGrEw2DK4Wu9UyN1u/zhCEvozQVhmaSLtZJcPtbx1SBLKccviZYSFVY8OFkz6d0BCsUA9I14GCy89GrlkcpLyA+He5c45JYK8VxFp2Tj0t6Bk7yW6bP9ToBtHnH0wTadjT8GiI+8RHtJlm/1wPnHhw8cvTpUlxdaqyyeAbNW3p18ofL275b97ZuscbBYrIDX7S4d21vetffBqX3i1aaGyZU+z+trN6UnZxdE061ZorqYR/e+qf95v936woUH0i93OwCCuoHC3JFxldpZS2jkT8+pe4Mf+B9yx3Jn+bMTIwuLTbR9jRggwEHnmIAknmINFLdngrmnXx/fVH4B/Ym8fzVuHGwWj9l1F4unS3r2Pjy3V7xa3zh1+uJ3sQ/6XeHYkTa8GIC+EXeBeSfvh490KY2D1g/g8IfWNm/g1m+lHEExIPahWP6+qLxMxOzqpVhjHyd+EPtKWz+Awx9a27yBW7/lfH9x+jX4RgxA34hPgtO31u6/7aOKAegbsVsCGhDTJ9ndpcntx+vI4mj4q9SmA21kMSAeBVMXrif35epEZd18GjCy/l1MJr4rGT4iIIsB8SSYc/KhZN/dy13+Ghvb9d5KaRl8eA5o/fyiaqp4c2Lw8J3lQwvX+4cmLx87MXm1wbsD5IgB6Jr4AFh46dXZdZWXkB8O985lkFsqxHMVnZKNS3sHTvJaps/2YyBrYh6Ycu7TyU2Vt1tbdndvMMfBZvEYorNcPF0h3Hv/3L7x8zWtk2c6rU6HD/sn81f2KogB8U3QkNNSGIbWDUsynquNHbnbakF+HWgohdNOdMLjDUPcyZj0NCrfhFbLtpnIpHTAKaqEM/rmK0W+BkY4LY4TDW8ehqJjMzIobUZ+gyOV8kMsReuoOf7czzEHWym+FCaJEOKPOln6VDwKJizcST8QP0bFfy8UzbX4iEc8DgBaXGBEEw8ckH6p458KytOZSq9LIkAA5gBM3ni44AAaaT57JIbFA1OKOKl2FzmrJ6+3uhRxoJAop/5MURq84WoMhED9fxw/T4MPgmQL/CptOfKLt/zxFWYwGdyafuwZCOjmiss8n6GnOjDWpZ4d/ie1pP8e2sFQ9fkrQ9pQQar3OUtfN9kghPIpSJMNjAlffdySgJBGWF/sk8/tk79i7ISQrhyUPmVyo9MW7LS+aZBBjAqBsLyeCAE5QAhTet8nf9EaYS9dHgwhs9INbgqtQaHtDZNTQ9KV9tJOxlf65BOpo+9kOtpHytP6UqOxKD50lgc2CycqUipDasIwnpQYiC/e0F8fWOxui25uWzJQi41HZoYVpEWGZqQGZrIc01QRf+2ys+0wGDt7jOc2YcDj2GkFDNh/6lHsVjQMtlMDBlPXVteGwdQ1YDB1bXV1GEwDpg6DadjUlEF1zQ7SzQ5CdbtsYGa9/Wa9NjAnTVhVzshobs7QYE7u6FB27sho9n5MRAQGFxaFwTBZWGxEuIt75XWWW6n8ctnxE2rP1K4+eGZ6wvh22aViSIzdVDyxQGZH0T+xlDDqj3y9utWuLt5KxTsu7x7+89KKYOXv0Xvvp/NY5n1xLhnPkW/MBeb9H09En0tpGwqjZHLPjfXVcJwHqyiFgRE+Ho5Ecit9s+j0WLtfcgC/YnGstzrUcjDes1jS6uwXNur9KGVxsqc8HpFKzkzlo0JwbDI7/upIN7uzjZ3U2cVmt3Wy2W1tWg4myEoAikwBoMhBAIpM5aUKunPyhO2cd6WrkGGqLSuN117adW5xH6w6D9Y9np2alh/z0hErDj/x4OXixMpyf0XnhQJTaBGVtW/9/eGEUVdg60cU88ePqKgf36OifvyIYirl+t8wN7tx3dzsxnVTs+s3TM2gsKzGgEOoBooDJu/XWm1rRrRPQnq4ivRbVLnD6peowRJSICKyyBUwcD50yNn50CFnp0PteFgCV6WmRkWlplpFpfrPfzlZAzhos/EtJ6R/HL0vL327iOXQFURqERza3yNc3NfKZXqXhODA1Efg/XX32+vgo8SuisfvwY335fbDsdcdMhyuxG4v0j+rACVVPCLBTI1PmXdbWRaYW/ZYWBRNWk6aW/IsLI5YWPRaUjAo01FPwZjnT66X0OQWV3vAWTDoLMOldps8bWDbAd/a/55oO221IurvsV2X7Zb96ve19R4r7O5+XHX3QW/0wLGBU9YhuYO4/3ZX1o14oxrHD58jsXK6XRSMn62WJSxuaJJk/43ptGeo2jBiq+svvVFyUAW3ZBwwT3er3Bm/cmtqdO1F/5tO5THluxNXb02NrL0cfBrJrZY+mlbdWpDJ62BPK0NroEfTqzvz0+vaUuaaKVi+UFgj7OR2CmuEQuWp2ikm8cRfx5Pzbo4nn3RVxYBVLmadU7VTkcRT844n53tqHGRq4jsdTz4xez1VOxWJMRHFteg2+Vz1afIxEZuENoVeDW0yYrWc+AFZMAYvGFF//RrQnFQnRUMZx07vJhaDH8YAKH8su6KhM6Ooa28bdeLbUabjBhvUemBcUuxr2pePrjp1QtZovepfReDIxLlbB5VNBRvzpAjXa1PDt11vFGfyY7rXUOm0kds8H0tcjtmnwHA3Ed7ESNkMZt1EDDK4LQFkbhMBmdsSQDajy92VEPnTa/IeALUcXFxqos13/PCcugdAzYYXlxrp+3Czq1XxoE9+Txo3n3nxm/4zPUl3fV5QZTqhr1zQUl2Zsl9zt3oGku6FDigtCkrff3j3sfNTB1cv7RlbOrt3/uz1IV5KaUtFaX5TenJxc0l5YbNVeCsg2xH6t/iLms6DR1o7vxSHbXXICSOAiP86XLOS4I4Z8e7t4W/CgQsJMWu3pSZnF3r3tWSJamKebs98BrY++9g7M8yzLteAKlmuzYqKxB2s85u4c2DOuQ8X18HN3U6QFm5fQe74mApv7JzXxX8aZev9WZTk0PCCMcllSrzm7v0xDdd+q5lsnihLaB3y9xaOJdRfktpp8OFISczI7DYDH0r90KE7y1z7CPSlX2bBtLqxyavH6m5l5jUoBligEYm0sLAAWiAi0sXOmPI/Q9N2Twl3roclpteaxfm45flQkTk+0REMnwBkmBNcjbqHOGS9a7stXAmwsQGU4LbbdxFUkG7w9aAsZIF7/ZyROnBtCuIgU+dJQf/lzpjXTlkTxt9oBr3JQr2dLJRTEao+34lx53785dGuMaR3daJxKYznOmK4a7bFAdFlZhRektRYuvO+cvXMQB0a0UAdOyHT1j5SntbHicah+NBZHtgiHKtIqQyp8fKTdSKZ9pOGmRgMmx5pFo4b4RsaB/Hp/r5C1+/0mdF/7nOHpt5xXj+EALIMmOrS573c9c9LLH0tQyYRIQzfiXsbNQEPsXLHalv7j9v42wSNhwRZ+k8i/ZFBk1Y+aBX4ezgchYXboLE054zWwaJ9U//C4Z5Pb+BWMEwdlqUPXFMuUoyRD3ThtGHDi/sI4SHyGYpSc/XTAN9ko4Z2pj7XpklLqVM2cg9n71CTm+YWRLP/SQ8vZn17xhuw+o3u8226b6R2Gn0w5fwH5v+ncOaezNPdCIigdiC3cGJSqfK91eDhu8cPHL7aPzS1unxq6uovNOQnUAUoVUJ+VgJAVSUAKFmszKcvd/CXlzjLXU3LRpbQ+ablfM6yqGk5P33ZSH1lnrPc1bSsqQGdb1rOT19WtcbFWx+1thmCJ3FsL437T9VN3TSzfmBl446BJ6TZ9NHwUpfPrNJPXTx1hY5ajUPFoeLQ5hraViYix3FRq+NB0XavaASX0rnX/0cRPxUFt4tI59cg3mtvv9jAcR7N8m4uO3XedM//fFnZWJkgOf53Upp6DT/4kvW5CUtfyxCJXYgOXMvaf8LW3zZoQscSGvnTc+re4Af+h9yx3Fn+7MTIwmITbd/D1zYP4DbrNja/4dZ/pBxBMSCetTz/dVH58mEUgL4ZFa/J2MDMHPvNHG1gXVBd1+Oux8N4q243/NGfNQay/fNeDMYWVlcLu8s/mpd21Lr+buPRgtSjop5n1Xv1kbUa42/dKXYwebX7jl7t65Ucm9m7dKXp9v44/JLClFom6wVUlMx1yc5foAxugerq6hrq+Qj+9v87qFPFgNjeAjxVPPZc/DzrDq1Wx5Iwn8ziBpDCkXRLy9CsKA6rMhjDQFKsnAJz/YzEp36n/d5hPH5MPrO/MTOvowHMiv9HNIyPZsgTbbd9PmUusTTvtrCos7BoUNlxpickmx0UnseJCMviBAYWZYQg7LzQdpmZCIyXnT3Gy7duaw5mOhI+vlMQ7lOlsHEolR2a6Ms0zwc+e8Zc88x+7xl92dM7oJMfQMTr9XMeOtAjfInF/RXGFnXbblO4a5ScsWdjz3QMjKymi+fE2D35A3vyFcWD00WxqqowmNdFIUMIyAHCQKHB0arhvuFy/tclH3FrjCJB6oVfn9+rO9quNmpm1El7o/OIsBFOkmUXIkaxOo/dxlqnIqMZ+i1OTNkqIuLmBwjy0aMfGh8/ScMfluTyhHvuLh0cvyFsGl070PoTBovzREkAqEjy9Onmz0eXV7UhHxae0uemD/e17fIr8e4AOWJA9rR4GCy89OrsuspLyA+He+cyyC0V4hJvHRSsylTdlB3xiRSTyWD4M5hMhj+DwWT6M1r/3MZg6HqRTgkKiP/xIgkGJEuaw3EiW6ONZBng6RYdykiihvq6hbm4Ub28CqITOgNoPS5MAxzKJMSZ6pIdFBFHCvKo0/mnw6MyqTmRlu0XQUULHgTm+63UFbRGReCbghHlWbX50d2tjuCcxXDeno7mhhhZefkQtc/qEvXh/uHNuz12H2S6ZS58roTBHE1yAwoDlNXV1clGpYDg4PrGL91bD6T13ivIa3bU5KcLpiRXBA2D12YflsTp6kkAqMjlytQN2T+vUzboUX52Ou444fchVk2uYPBaX2PfzzFHu7eNb/cfr3F/gsucK4xtGM029/L9EsHxzC063Npe7W0zzMJlk0NQCFeOFdOUj6JmUMtmm0Wjd0yM+NeuXjOBqdtDNs3lP51gneNzefeIH81X+Cv1K4KVsqP33k/nR5n3xbpkPkdyzAXm9ebtlmOq6avc1YZIduGCivdAv1b6xxzPzIp5jA8V/SQ2glXfwKbV1SfRGhoiWA21tMzSKhqngRfBaqhPo1dXceiN9RGsep53RlmRdw4Vkjs4kpU1PJKdNTqSlTU+wlY1mU9mcQNIBsTCnpoSXfXvFRi5emEaIo5X3cT1e0f2r94Zas4gdJa4iV6oGfz3HuHwmuvQRC1PkZpk5PO9jiQXky83CM8ElOJLNV2meBUm2KBaVHiqbTuDblRJjk1DURQ2kfw261x+rp0kBJnoadmo/cTfsjnHbuTTD3B8cUvtVjlmZ4CttzwZRtKN6/KjaPnuCJZzCPfVUKdmGeZ0pyH2ZNG3aEzG1pDIX6r1zNnyPFVrodbNqglkhfL+LJJOXiqj2/rooz8KypWwM8pQvJ2accR8N6ZGJ43MQoWiQkTF6G0ytt7yc/wrpTUPEgYXQmVHp+K15y68T2+yJoI/riqMx2A0t7CyZskz4RWjxKcNcabTpKaEpLea7cvgrugKjp/uxJeo0KBtdZ/AgJECMZ2onGcfFGZLlj0R/bjri3j180Kv4Go5/JUX08UjQjfXgywGxKNg2sI1RKQu3dnZ+1/P7CjkoD5fCjnT++bSh9esN91v+gX99f38fsVT4LZAxW7FXn5vfe867069VgpPCce7xMNJRw+z2j8tQtOEobWskxM94Pm5We99AnqsBICKoqMG4Fksr+ZomnmVd2IWiaIE+ulimnTi9OXavVJMvIlWieic5kqBoarDvUo7/Fz6rkvbv1mRNaId3NAadFtHm4hgQqmZr2s27OQYPG2Xp/GVvTwtg+Spg+4YtTg4xtPA19nekOlHqbGOIdTohHOjpJQVY5VGY5VexiqNJCpB+a+0eFcF+6M2W8I2FZmb3NBNSPCmIGLzmOCeJu//iHEt3l0Wb1CDd1WFN6/Jq/x6exteigoaK4cbn8xKvSAB6VJG24MMV1Jf9UpLU7YRYGyqSuI27BZWTxpaJWs/5A6p0rHR8i8PNvFsgiptQIEmz2Djcq0AG4MqWbche9lSqrJ4BsxaeZc65M9uRCwkZ7ldyu2ZDcu7FjsOoml1tAPiA/V19WNPu1FWHLpvso1XcBHWO8uok0E3bKSwsz39SNkufizLsuJ9AQUBEX8edDB+3C8DuyWD7YL2DEkWWOZf0ulw6kJ6piAZb1dz8BV39RW3+RX3jiT/XV3zu7rVd3XN7+rE3j24Hh/8K24OG+cRZnicfrhgbE/pIzLfPQEWYkCz1sCgOtyD4JSdCB2ilZ0hpZWqZW6KU7okPOAYFbLNZNJYwvzuHhkmL3JoIJeGrCJ98c6D7H1+J5FJUljScEK0iROGqMchH2/YfiWqQYS/iVTeZ386ZyeBdWuDpO2rBE/ejapKYQo8+nSGqQVui1lciXeq/LRdpjXPZvQ94blNjh+rAhXrmWBMIVok4chW5YFRxY6+Bu+j9l5suDMWV6Kv68s3s8aZvNPwszKHYX0pBo5kO2sizD8araaWdhemrqW24K3iGut4QD3CkWv3x5C2U8ZWxqxFzc+EShG4Nho2kLx2JbqRGWYOdkTD9+rhLoZKbB2uSY+aP5wRM+W7ZH8518+zMy2nkxDyz155aMU82c8NG2ZVQApWHzRvc+D9a1hKfLEzXD9ZNzLON+aLzq0ndoponrLqDqn67WjbJPQxe9Z9zcwdCQpBTKm4P4Iu5dKR+4023ClBq6WOmhmsnX9YGxPKzibzTf1mr0hedfG76oUoA5v/6jeVjYi4pDo8c7Gmv/CYeTkqvspXxg6XeFaMSzyr6XItTeVJnKowLWbadrNlHCtTvXiCXS6rvJymvOwHCoxb5q50OATI2KgnpB4perLN93im9iGXhvAItKqMcVSQQnkoQ2h+PnEKV6oPqb9ldnEX9jRLcNllXihgV7Qt5rU9yGpbKm9LEnS4zK8Kvh9wmz7gdt2rETlv1KYkXToaYHg90FDQhjLCZCD/ok1RgwEcPcezpxBBbqk92X02yTvY+lG2umfnI/WSVOMUDBMPm/MjAtpT/NZVWwM556LS8BZ0kzs5DzmV9W9Jzu6O/kHINHXnc+Uhy9GIW8x5myZmUGusd69pAyraI5s0Ib/EXnquzN8nOoMOnbkpmLqmN8EenAJSXfeXBvYDfWMyeaGmHV3lYlWZ/L6okhbNhgY936MAVOR2iH24XS7cLyG8vbhmf44J2KA8fkR4pCgrLWlM7gb7+u91IqH47oNdvyIUgr6A7WBbwtX2qyt8ArZo75jeUgbTe1yBpFDkzDKq8fYrNQpLareLTLOcrzrTf7fFeaNy8GbQAO8gPrUcfijba1u1IjU5Ro0ZnpQ50T/NcWqJCikzJuHj9Uku1jStYHkmvKgfhZZjG1Lx5onHS0zDgnI88BzdtmCaikCPZ14dNaKFNhPsbN7eiGrE3SxsmaDEIjlqdYcLFw4uYA4sHFyY9x4g67DwzjQ1fyu4Ksss3NWX6MEwtCXk+jmHeJlQdBjKkYgo96q4oCpbgXoziHL1h6Clg27umvCTH5AlUfJlpOVWkAYFzgkUnJluwl5tmql+GQaXTQ6zkNHxV9jvdGH5gpQzory+PFTOgfG8yBiPtYvVxl/h8/jkM8aRoQAfqlogkuTvAncVOSFIl/+Kjm2UybgxsM5+O50yGy4jI/TJboiAkY1wzNjDwYeShwM9Gyi75p6NHvftDoBaFFzCrOBTWI7hcj3C9YBtdmmZs4OKtyd8bCuCwwsQJNo+YWHwzWj6kCfOu50nzptpCkuqBMR5t/q+CDNqUSP9hV0tymu+suEko4pcJmcuXC/fRmGUOwVFW3J9FQtjkyqBUQCaHhckY80odPKONub6Kv7f9H+eOO/myOzmqOt8YcPSdxeqUyFsW6g/4lj6Me6xJTLQiOM4BtXEG3h3EpDJzRcSSjIbbktWTx7nHk8/zj0+K5k9loCZUxhaD576mivOXROmr40+kCYINokQ4u+1j+SSFfV3QcOkYq++A77V6dia4Nyq6WeRTTdjEH8P9NNGMJYX6wYPSqCN+O4J5GVSGkLKWhprtOnRKAw0xiXaLQ78TY9mv6KmUpBHkRHqDHhAeJhuADwgsnaSEed4+h+Oj7GiHSe5Tyqe7WP62yGoKQU0eAl7rmZkQLiWTprXE+uG1PeG1Ne0HhPvhtFYEjuBrXBEDPvT3tbS9u6s6Ttmz7uomndRt3+CPSHJDC+/Wt1UbSI2KWgquFrQVNDKjZyAl7OobXGJ2O6KhMOI/KUW6O4Qrna4h00cmWQRw/Ao0w6MdHyWFig36tISXyAMXrWTGT8iPt5m+hS/N7KQ45dr1fNI/JiXbcHxYRYRpsyeCY+Lj0jsFUIuFwlbYocdAmStxSElXZWSYyRV5oBRcIqTqy8s1ABnnIQmhho7ooKsHAkaQVY9GZRyC6aPUxYFpVXgyox0w6kEoX8ekM0bNtX/N1H2fk6DDMOU8z5E0zWi0cFr3zxxJ02FLmcY0WrJjvRqk0t0xikufL1eZestcydjWJX+QqKm1rcTqzHsakuyUmboqBMQcCP8ZT91+D5tgzNgtvW24p0W/z7aqfHVqSbQ6XZ/ovZQXvq45yqYPQ5GGPZjSuND8Rovs7euXVdSgfz/N/sJUSeRjRXsmo4txN+tHjsaXbjGp/NVKAYFJYxhm8XYUq/1nPmxythdi9mjEAOV7fuujWTDpUwBYwCAyAItwAtIhJQpYAoAgCywLuUKAFKmgDkAQGSBZogGJELKFLAHAIgscBdyEBImZQogAAAiC7RAEiFhUqaACwBAZIEWiC6EKWUK4AEAIgs0A68AQMoUwAMARBbAAZcAQMoUwAMARBZYA7oAQMoUOPtpMkBL7H1XFrj7II72d/EhMM4O4paFkXVIjSLj1q7Usy0O+LvtGnBkpAWol3dm7Gq+/nUDTrSMLLC2VQBsIy1bdOWPWWJTBczejt0I9zC3Nmy7BjzftgU4PHIX2FKhI7V7wLY44L8stJ+FLBjDZRlAuV8Zz7xrFyRyn3UXYgMJk5JMFjbvhYTmIjnMfZXHaLJTnuLK8hpEqSdpvh2AAvN4uRkSMoeApS1AU88IDthMWG/bvPV/eW1reCQBS1u2cvcybusCCEyXNkO+w7ZrkO4RHKRXuZwtD+AqtvIahAYCyjhIEiScbn4MjEKiZDD11zxWUZ5H5RvIMaEtny/lZghylFxkzyjwh/AmALC36mAf/Bn58yOf6lV28Ad//O6QM/jBVvLa9VSwd0liTzC3g785g3ofJvJ5aeb/Us8ZyL9/LIcsqHtw2OXgH+necb+LtwId5W/hmfHEtvQbuFdPRr4B38mdt5Zr53vYXg3iAZlvIg5cvXuFgLrWTry1U8D/0q+m39LF3Nnuj9dniPPvwx0fuf3Xf/40vOvzj/LL6rE8Fq/AsXeOsN/mTz30q0efdn6m/Wq5dSQcm7/K/7d4GbLwbthXxD/Cj31s9Izwk+H1/NHkU69GdOAj7xyhP8my26dp/ip9SfjJ0OGPUv/Ml4Q/fx2Mj9Lf0XqfCOdfgFHDH4X/7tG3+VPXFNmRMaJbMryePzr8FPz+x0ZfEX4yTPNHZ+B3yVPkYR6UnJ8Fk+ZLcHwI31mgX+GPQgzAPiJeOUf9Ao8Kv3Qt9pXEPxzLAnvwbvwBpOfffzdk6PzS/Nq7I7eKf4A2+0NzDqtd+MUdeVxyfmZL/dK9PwsPwc3fdn4Rfj5OCwWLAOynnZ+DSXpCKByLzs/iPLZvPwI1cYk/2Tb+t/Eb7mv8/89VY7/t/DzPL+4nhYIT+A4eIX8PP/bOCXqGZfC7t0ri/Cmvi8LfimIXSrzg3XABkHYhMP+Rd47A/9ahRz3/RXZVDOHn6SfIfxPfhN+gx8nvim/CI/QT5BHxIozgaextvsnzJ6tWOkgZUM49BsXFeFxchOLi5OLq0PYpJb5l/pP3swQJnOzRghIaPPGIg8bpO8TZmr96PhBTp8g/Vu1e+tjueAyTHFqZeWGyOrQ1zXqsYH/O/opxxjwqiEMpTEYX17CIx0W1OrS/pBsIAo1oEyqclpN1ep7bdBvdBV/WZS0ygUqVF5geE1TQV8qo1ugy0m6TV8q2aIuWBMc4xHOcxXqLMoBmK3S0i4q67qJS9YNxGKZ1+RF1QhFVVKOLa6NiJ49iHGfF8WPVaHdtrdiBySweF8eqWTweF0UexdAY51Hraq4OzaN8e3t72zx6e1KIx49VlW17e1H00O8iT5FCiJqj4df1FUwHW/OXzyuYplvzv7Y/omDKhwqmvaa316dJvd7PkmyzNLFNBAgj+oJ6VIh9HvU2SyA080zS7O0T+NuEdIK6VREcrtc75x45gMUBPMD3nOsHGBTV7uxSVV3bLvIoHhe7jTFMLo7yCEajrDh+rJq0Lo7yCEajrIji8Tgej1eHeZ7nx49V1fGqqiq71szo0v57y6Ww07nh3rKTCDgI8b0lCKHuLQWbZPdkpJW1sgHtXchVIKb51vw7z0gxzVcvkPnDwNYCMR1kSkwHnhTTweAm6l1It+av23ogpqkrxTTVF2gnEFPaUWJKt+b/eF6KKS3yPN+9lOe72Efvv8ZxUVQwySEzs3zHe/SPT2+mYnVoO/fdgz9+GGn5Qaw+gEduwXtvxvsD/ICVMP3Q1vxVq27h7hRJDyUzKP4w/XEJU373D8XML249sPwzBe+8p1P9Qdlh/ns2Sj+BO18vIbntbryVj/SBu1eOxj/0M8tssTF6a2Xxrfs+8lajcd8K1ScsWvsLR91ATI+6SkyPkhY6ekYXu3mea7MfN8bF7u9eFDfGhMCf4lsARSrlZkWkVygCL8e8+i0Ix6vqPCW2oS8imcGcG4lTbFzsrQQFhT6/IvAKgHRdJaaukTd9hTZrtMh3cXitd7+6C5PJ6hCrPP9jEPOr5yVOYWt+1UqJ01u8oXy6Nb/6mSuDV9yt+ds2+Ay7EsUVDldwGBTGxG4+2neXXaUMDaXc9YMQmOt57tFSe2iopyghECohpCvdgy7zA4qBOiS35m9/xies6MtiNMrfWFtrjGcmt4L5x3EBk9nxYxVDviXNpdnq8Pixyi7SkLmhY31kjsOeK7WDAXUgRMYPct/BC8ycVhFTVuS74/HFHM0u2DCMtqHjcSszb5g3Voe2O6Y4BiSWPsWgr8QU9ksxhdPERs1DZGt+ZSBoZ56RXsGxUr5066IP5j9bFyn/1qqsIXi0vIcg6QNCHxGLqqigqPLVoY1APHk/JN4TzjBcBFgVH92FyfHG4AFEMBKmjwDlFgUo7euBeWVTOBdFrfSc9XWyWWqHNzZL3tSPEGZF6414XJDw3RwEDjyGruNg4GAGk0k8LkZYvLEzWh3ahYXknL8IsNI9ZxehG/a7j5f9zPd5yDfL0IGJ5TtZoW358cg/NuLxG2urQ/uu+rlWskzdpSUXzlmtc7fZQt1CSVutrJttlstxksSbZZL4XedmF8E1bt+lHnVdn/sY4xSgvYAazhTpJnTpodYb0biIG2NyHssCRf6YsCYUQjdc5mp3s/QwCrUWm0lfOR6PPBRDsJozjkYt84O1ndWhXek81mo08O0/cHvxZtnr+VnWfrzMRIzi5wYlevhWzop8WIEVvrw2y7EP5xYXb86b56zf2btZtjqdoY7jmq6J5ZZDHBHsITeWEK0994vGq8M/Bgd/08ZWu25OFzZRZB4vI+GSZLEeptbj1rTf7sWt59yDj8U8jd3YjaF17oYbpsvnLKR8dOedo83yzjsPBL0Dj5e9ZvD+zTJwMBBEQNMW5dhO49HVWNcHXF6Ec27DmJvzc7YRDx8vdRzv5aQt3nF4Yw3bPc41A7RqHXUBT94vjIqfvF8lHk2f6OlCE701f91UoA0wooum+mh8l5nC71vXGrVCxcfZL7T6KeM9Qa+HtraRuyFliVxV1enQCFPhSFhE8FQr8nz3F8wgwquvHkR0bGpgggBb820rFUxPUKQUGGzNX/6MjZc4ugeGJxkV+QyKUVHlsa5/ZbXgz5WCEHyuJAjclfCnFb+QcSou0FAEGtohzlcPApKZ394BxE8uUAhMEUbY7DZGG7UXYjQ80jW9UdYYrCyvPHn/ctJ/iw6feGQ/7t8fNc/6/k2RtuyzG42LavfSbszL7bSEY+xv/H3oryGFNuomGr6AUEBLBYc7AS+QWQXTev+b4oMKpiyTMA2Aet7ocOnp1Rod0/HhUlNNB3neum1UzmDJLJGALvUH/cPlAAJtYn7HHTfcfEgsiSWxv3Hohu6h/VEMo/DeZjceF40RcyCbEFpZzYriznVmJleTCpnL7VvteAWVXXEcdAV6RsGUuJ4vUQahpkxRhgrRUDRYhwI8jFvzV5/emUpsG1Lb8fN3Txh4PuNSuYGYKhvXDylhXU2opuul1oIid7WSlIRe4Pv8AY4PAvI0gEJGOZC1YiDiRTQq8rwK02uCopiMixxMNjOzlnkpz2dxUC7lmBh5j25vh1keC12+vb03WOUFKCSGQ2JzDHKDhKmbRVG2XkZRE6G5Xko9tF4i9ZpKoKyFaoDmp0926WqajO2kCtlCimm3y08N8JOPpJhGd5Eveeli1CSbmt28GWiegq352+Mw4P8JP2QzLg2L+gAW5OeX8zz3VrPyvLqcj3s/h2jsWiAyERA8QGX1e328G/ADFHUDFfUE4CsFU6pTni8h7Uy/W64jTROSrJckAYmKShm4wXrpMpBDcQUnEqVsGPK5CZmT3ARiysnI8ERxnCBd6s5HXtu8V8tH0UgUgNp2gJ52L1AEioaDx2HuEuMNZ5wNs5MB/TtPVMBnFfCIBZuv2MwLgsjDjHvkCYU8hqb+M/UOvZOU5oFv4gvv2k4PkNsoqOyNwlsvBUGxng+FT9BfLzEmfL0klLnMBQiEPyf3uV/1TyGCDPl3sT22daDk9GiUNNjS8nLICo9EK+MPqglKSojrxC6uly5lDEASMRcXXAyLUw7/nnIYAW1wtSNOISPzmS9OPE6jeq4OrQc+aoaGK4Fx+wFZY73MMhdEv4yWPUn811CjkRopgfGS2BvgMQynUnpzfmg7dkml52mrBmgF6sc8ZjNRxNjbUkf0KFbfLEgw00HtIZeul67g7no+xJjHPhXUg5m6QKDjPYKIvzTGfPcwcNlZnHFWZae4ZSmuSYvxwpIoV9fqZDKRyADPwCnEmFCYTLDYXR3axmPHasSsOJ4L4VJ3vaSJpNzKoeZxOQet5cDBg1N+piGmlJjPvzvl+2FQCAlGQBouviztW0dlOydDPBCOQ3IK8Tq8DYnJVICHTa2QD10p+FRpvWvADw1yrjcxNNQazQlAOIGaSHkQ+5wjwgkBEFeh1FX3bes9A9YFBzHwpH41Ho0KvqDnhBesY2rWQ2YMSL5z3rBVXWVv4iq0E3Lk1fP+yMvnvZd+22Z+7xDnjoxSOAbyX7FagNx0TFPFJ8xLVk0/3cJPJrg3uTkhH6tjnRf5gD2c81uufr2F3AtEHMUxZVKiVie1NIhnJRRmyz+juwmH0o2gOwl0G3AeNqci/q8qEjFFiU0oz/PxWh6P0xynGiGfGzNxDGRVdfStbPCAwo9JfJDgSUSpQnv5EqbaxX3L27ZIh/Hzwjyfeqg13o0wwllHETkUXRduSjGNUsnd87nL3ap7ysM170lbOEcLSuM1jLGjMoLiA+sZgKu7APF6CYlQ66VgHrZ0MpW+ShM+aGPIC/fTYUrStKmv4pprV5+klpqhxqxr25ouC2NGK3e8DnvgfQKJRsUUrJdKURJTuV5S6khvwnHVt3TSrFBBW9sFYXHjmZpCRIR4Aap4iugbI4l/zxA2DwmuUVygz1kdRtLVbSsxLFJqsckSA66bBseDu+tlDAlMdvw6ZPTTo2JkdnLFDbG3vVcjtSFqgoo3Flx3Yb10Xb8ru+ulpOg3vIgmIVOAK1w+GT1E8NOIxOLl3nteh0TMzFGjFz+wEPiUL3flB6KUz32+GzA7edVYM2pzYeNYUIxSh3UeP1Zhdbyy6Qdvwg/cgO8b4Hta+L4Ub8wUTK9jeE3BdL/ZuzBtIghLXxSdsXHeSrLEstUWILRR0XZms+56mTFAlBRXV8V6uZq02ytLRNAS3XwpsHQySXCln6/wFXflpGclpPUq4KHn3YJHilgojMDfJEMEO8fMggmsTO64uE9Fo7Uo8zN9WGxlJY2RC75einfkznYA57t2CSHMISSUH/wr7lSJIMQJJy45ReNgni6q+JR6rpeeGx49lZ9N5FGEQyTr0LySFTfoEnh5WCrtt0r82CfEjV0iGfFi7pehKKeGfpNEqbSU+KUbypXaOZE73Ak5p9jW/B3ruVPO7Oktq4aoZqtvwH9Y4ieY8wnLrflfn1c4ld45F7Tj7ZLEKRsqnLJ+0GAybizxZoafcNDZr3wQOTCuRGwvKB1CKZG88uTW/PsaB22sCbXcr6cQu+B/cweMK2hsweiIMZOePcfbR5Hmi5DHQvShNfTvV0zi8Th3nvlcigPb/sNtfKiFn6rhpwL8uMJPevgwwfZSLLUaVFPItCdlUiyZq7Ok6Nzhg/bdgiHnFRAEy2wOTAtByN8C1lMwhbpFtfmUalP7oh0JcMVVRmUBvjX/vF1ikW7c2kpoapSTzmENmAaphrskPRF15T0Ycp00hC+pX0sEkobn60Y/GsCkWsJVwZdtTcFUExavRYNKgK4sulhVOiKwTObRaPSH5b7Fb2bQbgHJaj22+XCCn47xkwF+QuEnXPykgw8RfBgxmVZGZRr1WwlXIvfgXjFxmSnfZhX5O64w+lrBFI+P6ywCo99Cgku9IBMEohuZJ6mX+rK2gOYBNKSNA8meV+Q7CqB3ojLdoqeJFlX9NoBd/LhA5iFyGgeUU4+YBiecVMkpmvFD27F1a63nwUkALXAMCd7XWBUjhRu/HBktRGtw9/riSOd62FAJZIgG+cAFX92wm+C9QCgksAfobfwDnCje4SucNihHxnC9ZDG4jusk8FKwC8gHI8mLkFNFpXquqUlActJxUCT8xNYLYJnZzHoUOOdbTAJVVWGe2/UAEeHfKAlF8Y0S+wzEFVyZEblU8tUhd8nuS7PYGggeRARXDvOQRcxwW/BvlIIiGdXnCFco/kXqsrTtzRX9phGn6w8JfGgVB2pxn1OHFY84jwv85VExG92pnhnXBywKiKkP89kHKNLTCGRrvn0+MIdIkV+EYnG2l71XGAQPDRPlvS/TPyilHv2eKGUnxpR2eGej5HVtPXVI6yAONsrY9PVQEy177rRyFglT1L9XZe6btvErgIu6ecaVB7kuyStcdJOQrsujHECPRlSYpato5yZu3i5Sfgfm4KMRNMVUpxulrjttr71ReobBCkHpTJZ7sIz+FVi2+R9sK5BlPUHiS3jMYyc+G2t2RFuGEoci99t7JV5zsmJiaMUaqCZWtfffR9HTTU0kpKhobc82ZL26YxthA32FUwDJiIwk3gmJsn9emfTee4bXduInd/M9FR1EG8pX5KKrkGZJp1eHaUSDvVULNKIjS4+0eVt4TyCmYSrTjVIaDVGQmlfOIhda6u2Rq/Y63csw4xnP3OyMqxj3uCGQy8wOl0dNorQBm+7qMIfgZ7SDRojSxLtehoc+RP4Gb+JG2Wwy7bGN0qvr+kapzSMOOnWlB50z7ThwJsGwphQcTvSESgQ8JQVMiVqStJvrfgLdZajPqPpmlMmo7nzK5nTzy2ve6BwwDvqkYyX4x2Dm2/Y2wGbQFIC4igeB2igDHZONMkbHgRGCxRdQoHjo1YF73Kt6Z30rGbcTqvzP1ndLl62nRR0r11SP1oCK8SqHEKDnZOSes0nv3BqfIdUhGrE8tuQCrrAzVqCapP2839HE2ShJx98T7Nkog3pDp92ku1EmhqXNus1TPetxTwWqh4afkfuet4/17877vO/2z5jOJDPw3Gxjin3RBTzeGAEMzQsEigCgBoPjld1PDBKDhmHqpYppNuqfgw9yJOKjWjNz5G27sGiiPK/KWY80KPUOveP9H8MrEnym5fotTOCnX4F7QPzU/RDqwPtJGij6k/OhQCmdDV4hFUwGQWQGEUxiM3ImJ1B37xsJQcOC5KfuD6TGL9jG1e7Uf9L4YH5yPhQNnnrER/8lUv7b+H6rSdVHbufDWvdqBzkLWvNphQ9Ik2L2SR9PISq7SqLOhyPGUl+P+BxTnvpagC8lejSgDzXYcCappQS4yvwKy6mc5QxtoHnFyrwIe1VIREBHVYVb0ERUm38QaHyeK1vHlIytemdMsa3HIXLWlRghjX3mboV3M1zYmr/6rI3mLSLthPqNlV+rSR0V42m9zYIs2Ci7mUm0j/FLua/bzkcw9GP/YC26M494NBydjd3v2lVFwMN52w6ee9b3e+FMvg1wqn1UtL/onx3KNDfPTcVBaAhXbypHc7UxgawYjSaTKJzTGMlnL8fjFeq9ZD+JFgH8ny7i15yXO/Kfd03tjtTMa7Q8sU0ryRTijRLqQm2UwnRG+xkAAqaZBTxki/y2xgAEgrub/OQZrm6vCdqsuYxjruKH2lWmxZcHsMwbG6oPZGmWZWbJ3aRYq9imX56qdfCFBFEoZv9SlcUbo7p9gPyPQc1ftfsandTVAD4JMcljQuwj2cZZ999s6FRyNg/HIWlsf3kX19aKudEnt01nL9I6Uk+hh4zV0LDc5qS4NXTTnvZv3erL9+sFVru+0aw1N8qaATt+QKSSIr2ebpTX1xuN/QtntIb9Z9BJ9BHCfT7khPMhtL0EnSAB1ILy+FhhF2FI7riZ2YEWUJugTZ4ttcreTofEr9ViEltafX3fCYV0HLFROhogiOA8l4EIhHShsdJZhtooBqMqZm23M53M1vK5VlsSjSJzCzro3dx8t8C7hQx6JU5TVAJTqriaGl+H0a5GQT+sUavvOqbovsM2zotjap2EN3addXwAgpMmjSbeI0i6mBK2rJmGygYPaQb/AcRPMQzCfdlKj0oyDwvBuHzTH6p9ykEn2nSAdChJqZbeUlGCjzEFAVMYAiJQZVrk/pzO14Q2IAcdFWh9QfUH2/hADT+l8GEfP4F4q4e3FGqvBTDXzKiQ8o8xIr8bUqJaS6Uyn6AT0JAj11+REma4xVXhFYMfC6XQbmBeuY9b/trukY2WSb11RUToRtIGx5fad+1t99e+HhNydOKNZPTjIT6ktvr4MEX3XUQKKaxrXh3h/hDFdqhgnim1jTA0JbIJzFPCDQl7pnNOyX0QGLgmNNLfgv4XF4qQECYGfdWmEqdURAmTgZZAAklIKiOL258qepq3EOZuE87c8i+zjXF+UEMIUBCsdShfSQREUBJUWdOglTbducugNGykmDD5cDrNQiGpqs2hodo19eD6QN1CYe3suBRQm/KTqYw1DNjQFyiggVQm0I7D8/aH7OFgCGwjkbKNB9fIwKFhAuIvuHzrrURcCH5vKSSIw7WhVEdLSSE7WkI/TrnKspRrN71CMiCcXpwKjIz/1/lfD7E7Hr9gni/WojisjKEx8aIN1qPQgSu/z5iSu+DBhtm9CrIM7i2zhGeHa8MkPlomlIujJe8rD4DGoq7pFW9EAQjc54iHEw+9voFw7ffPQyfDq3+dO2vmi8V1A/8YcP6y3eOpQ7LvqUMepdFzJXVs4DxX1oLaBfAu+Gndh/ltFioawXKGBssvMwFw0oWfpSd6SB7pofpZl99rCucuSjp8L+Q33YR5dVN1k80+tYQPdfGxrQ/7+DA94MOKkZXfHWd0jcURy0fGQivBfoDCiGyspdsh2MelPZT12ccZ/jqiQR9bESKG+rzHF3JGduDWWaCOHu0u9BaXOO/3zR7cTiqU2evt9+P6oT7UO2S97HTqIKPPltKIOmUQN2chVOKGtZkEi7WxgqnrdvYIw7gUt/vQrQY9x0V++VJ+GSazyUWOn+2cwpQDVSgWSS4nV+iqos064TafdrFwW371shJvDRWhd2HY7+fB/CYrERZqMh7gwuFzGXpiHxLYt0i9ASXLQwTXUwYEodvgwYBg67ZT32QliZf6BgZkKXruA0m01DdyQBYPn+OPgcxft95yX9cGZPnb+f+Ikq35K9YvDujagJKV6JnhMey1xHW3vo5dTu65Rf9yrST72l0VD0inJq7XbR/uaBf2X1t7/boeWrgyG1DiH9ij4gEle5/200MQnNABCqA4wXsbvwzj/D+k+2fI1X9EgK8rsH4SEDogaBo3jPPvP6du4scD7FaO/ePyzaYSd5FWK0ZrzSb12puHt0B3oaPz2x6zpuIRfym7d8dSfdn3ttZiL2qvNWy0UYtd054cTtM6izbVLzsg6Cy23WhAcOGVgm2JnrCMzjhNfOpCiKdeCkFdSoMJ+YJ/CFzwDWu98NLaC6tDuwjx10sIhVBfLwWj3sH0657+OtUeNmjWpJ4scY8fq75F+Mmh1aE9yA1SI/RbmNfrjRqpbZackCiOiKJRlCVh8ngpQxISxRaUDGsNRl48wZGElfaOAHrtc6674LiFjWnMdFWRunVhMPBcUeXEKB/to7hvOF7ZMQmRUs++Gxo17rp8s3TdtlZWRZulYgTa0N4sIU7T7JEQQ2gRUXOzx/oMWVGJ2OV31opZFY2VCUbMLLKnGjti6zhe2fbyEu5p44rG3MGVIQ5yHOzFKCah9oRWILahbSU6JFWwp1oBf1+NN8HFkLn53Q8d0yGadjoLzYXNsrkC5MC+2g314BTpWGnwMLHK4OEO6ZAbTg2sVHh4MFiL+6fqbt09cCoudnvFJC3DLvi6FvV6AgrMMbLXEVHgIfAuofRQEFpBvYNeP+ZEF9ULMjj73uq6mjDQ8EqpqSBx2guox12/TbOQtbHXLyhScetN4rddqlxcmbn69adNRCWFtJLcd0PKlwKvdCmINfNa/sUCJiMzHgA1UKgH6iWECA3v42is9ehetWsSpj3P970/KLNlf6M2zMxGmSHSZfoWv1yvpb22B5AEZ9o19NttcWbxoYBV6sXEDqEE/ePJzuRsjQDAa6oGEUCP6iJnJtKMPWbhZCrXuGb58VBZ6+2k12VHmq3mvuUjxcrCkV7aLHq9opmyG/WOpftXuivdD5UrK/1eP7+37PeVUJ8rxf5mrxdD/LkSxkk0PoJsRgjMYNv0KArzxpp5YxSNtkHl+/H8Vfs+Iw0iyxu5pK9HTa+/Pt3/xW431V+g6Rest0Nb+dFSt3qtokU1bbUGcX9wtB7njIX6Ugnxl0oBnysFg8bZVQDQJIhZcbV12QSCoC/848eqHbBOPXu3VrAZ7R8TqbYeJXEUrSP3aBKl9fTDZejXaQhHjiBqRPlWke4Rxnx/LzFhfCRJ0oNpP8GkqPCyyrVXoul5st21UXGsqnZHMOFET2VFYxSlfubxY9WzD14CBE6TopWbg/GQS60LiP9CedtUb5sUNcWUprSZZVBQZew4xRtUg0u4PYxiJAGRrsOooszGRPtvD0faKHSldJ8rlZVImONKFUaxTwMaUOMBB6YsmGk4XZyUG1MY15ZjQigSK4uti5ICxIa9d9RLq8P0mdPYMKEsZiRGYGgKyAlaHMtYFyDFWAgeeeFE5SEPKWQBzfd1kEl+FQfOlg1IGU/oepkkDki1XkoH5Ho+jF3HXS8dygE0dxCMxrLJZhPNthwFRdxEhhEho7FGAIFSms0yNKDiK1r/Rz380RDvC7BLcFCBE7RDFVyc0m/LWLnqte5SE4lURBFOc1FLckAtEWNg+x4rCxJzmYQFSR/kPLhLg+YT8CZvqiadkhueDaqkSzC2tXany3p1oH7AYtetM08yce/4pBhg2ABSUqgxKLNeWDMvrGG7oQcQI8QjQslQ1A80DmUJOTkwVDb90QH+6CLe18b7GliDPQs+b14ISZN1ZRpAo9YH9lyYJUYU1rzHiaQcaBDk3/IGtRRMF/bWQNVjspfsfa0kHdV33f5rpQt0YnOborEo5rlWRkWIW0J0o8Se/4ZkkTX0nCccGlBHK/1cqWINYc7IV2f8YMgzR+gi9rnn2ni8u6a4H2SWQNIlXc45WMZGCjTUeEop+J7/XOnF1Ils0DMifidHb2kIzsc+RZ7P1op8FgYtm521lpi08AnjMssh4U1SdrlhmDCf/0PPIHNptmkNxs8sMffoNkINDcf47fc0MmCxTjRD3YhjvVm6XIah3CwZ6jiMQ68G1IspdULPVweNUn4CoecnB5OEhw3KFsKaeH0f/UFoaIxHRY7mZQW18ixH86/PZwVMJrM4L0F0JawyHCww9DPmUQyHDifajeG0BucQG4/VprNf25p/91m944b+YzlDmCs2gFR1LV0WiejxUtQhLVrzWE1MncBkhkW+Gw+Tu+iboLB4VosWhepAwziPG/Ix7LgA4p7OuVj/Gf3XLm5gM21ulqnRHAPKOXXpZunq3mapk06NWAriRYuY2WEz8t1RPG4aWn5lB9SnGXjURZONHBO4zCdMOMJhDsH/tvK1yPUS2u44yBraAW5zsyfaU9kATpELpcdCTV1137bBKtcOEWHEnkvOEoRUXpuzrA6tDyF/TGt5UOrZDdtkOdbn1bpRT8hmmaAbbJZuRwRA8pUIz+hrr5iqLiQYf32duax/uARpZF9Sj0oZd2CZdHjnwyUf6GEQRdHZvb87mSS957cB/xoQFrVuPu8Wu+PCfLv66O7aWihcsIpFFoduQTJhcrCG9PO/7z3pbXvUa+rP02LXfDt5ymQMhFTZxDJCsy6oJVflPv1gOc9+KyMmlq8+89vtTFXwzM1OMpNLIKWpK/JFcCUOmGFEUsa6/kO47/kndXyAxzqOAyoxqfN4mTKiQtPvfvvxEmLoTYwkNT5wHIr5LNdOSE12rfgXhb6l2OrEi4t5TtXtv/gjTfxQjKWD9/XwPh81zKuPO+FYfWb5tWl5+VOpPwZcXr5F1rrXMTyb57dEkGGWDc9Ewn4AHaGk0UoNlpdho1xeZpnLfpYsq7fr/YV9/X0bZd8kjhpqBspR6LEYtTkH5Tg4a81qigWtHhUItk1HRDlbHRdV7qiIcc1YK6rhKsj/UFU9c18Hf7StACH6OoCCw93aUlO6MTIaJABUW3HKaRc9o9HU6xovdbX6bft+Dccd7ntnPD+Id2QClQmaKtBrv/ToypgZ3xOQGGvqG6UxordRirp2y8PPXKzkULlVXljbfUfjace1C30RtBJZmTBSsJTbdYaOeU2YTSdu98ZbFqvEgQr1/DZ1Mgi8J7SiQNQEOqUagk2uKkFRV4kyG+RXTL46fAovwNb888lIGaDayl6cCZTR50qWdAMiT6z7mCWfoiRINQr5d0OAUubCiRB6fqPkHAEwhslkbNGfRdMGG4zOYd/Kxg8l+FCED3j4AEU/CxmCCo69g0P2PYWeEMzljHpJveGxGGr92rBGfVqrxXHQCVye1OvJRlmvd1stslG2qDQbpaxo62w1WA9y5G7pxugfMGzLq8N8RvlV9cdQp3076pCknnWbpw71+8jd1oUs2zuadexS56VIYQkVXQrgvBgI/jB4MqCKBkvo3LUwOhQcSGsXoLfgXfCvy0E+PR7/C1L9qOPHKrBvMXPpoAk397BLECAo1I5sHIQFgnCuiUcpJxhg8HjZyaat4kxGuY5WFxvVWlLhAwNgVzlxT/u+uCo1b6jP6Np20TIvrl17voBi50EPzzYcSRiFq4yc9sRV/4h7wiUko9hqtrvWenG2uwbF7O57P0Wf8LbmP4iVut+z+/DQhxumun1w8Yl2ezl9QuvBsoqzBQYiKdW1A1wftuwSwh9jVWbQF4ycyyR7IiOcu0jEER72g9GWEc7gFtwCaezDuisiG8FaBDBIGnKUNzIN122cavJeYG2bi541N3/d3hOGJkrabA56j+I93iv2TgYUueGZW0vXQ3OPuLaeD2VnvZTMROuloXxpveQJZOZ8W/Yvqm4hn02TNnLNr1nz7vn7nOASmu/AnNY2MLvCVseHhOic6UZvAJk1aTvRbK1737TtQl0D7GTQRdntrsrGHvqrdPb60BC7PmbbfkjB9PrrV/dFwzL7/Mw+3913JmplJgoyUa8jEtm/OlgXNspulzWWa/1ms79RNo28Topb3PGFa7GX2mzGl/PdXH5j+yfz/Np2rsxBefUMwddKwq5rdaifTSgR563D4GnCnj5dvZMRUVStyy9ehknLezzcu8Urct5SBk+ffoIguR0+AcSwfk6Q4vi30SDVX70/TVWgnisDOAjiq/eDDjCggQwbsTqoXNr4u9i4kTG0A6ZL7pVkb9pxVEy2jmcj6p4OZiVOMXYFBZB0aWK4L3hnkc1md85IjZdDEJYXFAwILqKDCIOy7z+bboMDarz7M0BJzH6UkxbGJSgByRIapmdQ+mekgLUCSQ0GiwuOyMzN0gltp2ln/9jQ4fHwkfD3QiZpGEZ7oGZqRLFarR7VN8vIgYEZEMUGgz1kz2ZJmr1WDWBfs7OwyLqPeUowR4bMm2ExXpE3Rt+emd3GlP5CLn11ljknoK3mXHjTB4fA2vhwFbKpVjYUVLpPjObdpKiqkXSaXB1aLZn2HCEnCLkDiiPagVyMiO7MAdzd/qky3cMs87i7h7Y5bqMMtbeYLvxktrjG+SJf7F48S+Uvb82v8UJe0UtLe30BKuREtM5/z09YZjzeubQT+eyglttmVpqZvluEvMrGLcLxgUqKagcy8NI0ffFotqV/9kQd68d5PV+v7Ed5vd5CXtRxMFmbEPjAZ/s2tjekppbEJBTSeq5DITAB8WmQCi7WS+CRL/310kguuaQBXF0ZFwXs2xHh1rGj0aj1wtpLa2tray9k+ktpehS9J05NkNtd7FMdMIbCTnSPU1ii1pUXQh/qm9i9OCNnjztzPoeQDuLqiEIsJAs7vvPLYe/IaOs2e295W3jjje+7t7yxs3SmkcXa9Av8fnd30lsuvNvId8cpVpBi+u67P9+7E+809HE7oeSbQd3AnXfS3oX8UUYOnKIl+erzJybhnYRz62lC3TWfNwc1cpKSpqtVqiab7SErEvQru7Y1jpVcpMYjM9eEYYfRxey710TJpvjKA4J8URN6F8GMB2vYZa2Dp+kIwmZmYCh6WIkQUNPT5tnvSImGkCJPUCMLzXbkJ3rY5a1Wae+ULSvN7BbNZTHXEQ+aOFa2gDEdcV+wv9GR/jOkn2dbpxpStlz3M4qMZ1/D5wFctjXffmbuuvw0xSNFNhAIN99XSKGxRWWNgM3bth1MZgCpNwuEnTNwvlkGkaXRN0uPQrFjJK6UmR0sWpfjcXEZie11vHoGEMkrJYLtAS8ycEPNNKCkAKEzs0IJepp63yqpjbynlZkXZ89zpuPHqsurw2e9bQriL+6Hr8ZueJVJZA5Kjhh/S5jazIJ3xPtD70mPdai3rWeWCvXZUlgvOCQAos9i52LyAVAeutx68fixqnWZWY0BDZ/GSMFbcLznYazegdSHwHAbEOezZR8EWp4+RExGLxXe/6pG/mVprB8eMmEMk8/mueH2a9S/cPFSvjtc7YGAHUJI9kdB4HQ/GZK5ZOhvMA+AmBAl4rRgB9n5EnxKnNNiPNzxGAMrhD0ibLRwnl9eHdpYS85GjBDkeeWxV0qvCtg1lWvPF34WDG+Kvi2lp0ki0nf4GU8uQ356t2Nz32HTwbkiCu733oKDlJx4QFIbgEu5WE/mkcB6kvF4xzxfrA4fZaC1/zTeyveGS/s9Pb45WRnkN0F+09O4Gh1/L68/vVbo+uVaiVxr1xugmvEq/D4UXYJGYF/kEFrKnIMO68Ak2kQYzYKQ0wrgIDhouAnSRvpwYOv5kKv1klOIrGBPa3DbJU4FxN1DSLk02s9lmjZJwPikcyTAW3mqXeMXdKxFb4uyLawooFfZBvC8L0FKXwiHKx6GmlLCApHlC8Nmbyd9bd+X7tuXDb34EGPNQHmA7Wbb9K1LFjfKpI79k9wIBIHhuOxGabfukOmpYQJmDKuaM8vtZcvyH2gO3vLyvgXbmy/whS0LZ+qZusrU03ydDB41mnGnVsXjHdkePfGLnMB1Tj5SZA2rw0fdbXfbbEH7XworcagjDsJtdFTPFBQawx3qg4tG8ECh9zScKMpVuF4qnqtapt7J6Ae1kKhnG9d5mBVweMmoWMvc5VkM8sAE3RATbU1O/TsC3kieiMXVBHkB1mlbLMy2yjjGluw2hZ6R93DkxA0CwYwPN4s8m0Gz2MNG3vsPg1RWv0iA2uaI0gLJtxYJZH+Z9fpps+p9UZLq5S/qyNC75WH5+fJvl/+w/PEyX5ag+s9mq/rPsA2SLMlO0BX4YgRZnJ1hJy7q9dN14EHK5UOs8f+8L8vYMcyqiQwMFrF/fgwtiKv4n/ernbysLXy/9EWeD2QTsNnsTf/v42/N53ExzXMzdtrnlXujR8hcBsn6hzBytuEj0S6n2zSisRHjfUFQkWqM91UJqeNuT5LH+xJGlqZJko0BEFQ522JwqoccPvODgbFDx7HsoS1DfykEK/uDJ+sqPCxVRW9Ypm9QtK+dKnCjWKRK2M4YsvZR+fQCJl9D8Gv7CHQiS5Lv8Lkv3VSrI6/M/ecrHI8YH+qac9miZteLx+WApgVQV/Rf21cM3pbvPRCAmWWdmuKFH/QK/TFPr2nZ8/L0xj10D12iH5RscnmqW2bX6a7y21AUeIOinitUbbd7qTck8e7G+fj8dD8uldOCXyuXaz3zJWy3qq3H3Vb0vVZntzPd3/XCht2oq6YoYLyvKBhhecr52SFrY+PSB7vdy63hB3u9y15YrZYL9aOc511GeplJtbBPHuj6ZaWQD8v3cOUgTwUVnk4QXv+X/zsYPGGzwwtO5yy1sKjURTmmaTLirePdn67Hd3yme5yz7n4mpKcYwR0DViGDWMKEQ1Bp5bBuw3dQkFwoYmlbe2ek/LPouKo1B+yVOxAFXb0n/q19oFO9pmMJ61ZarxhDS38qw6paSMKW5fH5olf8rX2P8Nxv7fMWqF7JwRzPh4ZVqZPYr/95IipUVTLqWgrrfmtG55Hs4oqT0cm8wWFsbqpLOzrRxXFaTlUU9EWNlzxJSLdz27zCP+QRT+AxvJ0aKm9oVQ1pGtLlFmqDJBGHbhjFcRZBNjqej0fZN95+OkS8pFHHL4rEggJJA/Kp/UC3LBHkIxiWB0BeF5X0xtlK/pOhEu6EYaf6SUWylvJGzZHV6357Rj/PZoB9uwPQnR/lymzdngFpJtvC1zXz643MDWffzOaQnZ60AM+6mipXFaQo0lSnV+Ar8D7EEOKp45kf5HlfAXpAk6cgySI2cpyDfi9dLY8RqoBwkgYVEEzavfqkUlFbE0DtiUoMoxycO4RQaNYA6OQOBYKH9dQbovgx64/P5qzeGzJF2uSMsyk3KsVyLQhJUe8Pt0niQpdOijYR5BX17HP9OL2gGnvKphZtJWSTW92cwGgr0YjSH27rxGMrkAhECYNamXhtjq/gKmis4mZb8bwddtAmZTKmJ34082XyI8F9ptQGwLJFZPrxmlITfpyczUci5OdF/zLqpd75zSFA0+H6etVdExIDGvLEtcOVip6PsRcuTarkPNgUjuFqqqytFUBIacoOCmFmvi+eRpqjS2fzrufG4/ynT87mZlwTvLD2qO1h69wqdC2+ttI11ClsNvJTeI7WjRXPXXVXvFXXpgZ0ADSoTZxVAHjHrXW7vnlkWTX+iON6jepRjZ1G1pDBtP+N/4LReUQfs4hxh0oQHUN3+o99nzNPZ1FEs/l0n4rjOV1wyx/q5Wa41CUuMuwOVks17E9ySrWBibiKixMG4K+CPwCPwV+Lcv7kyHR5hK16wMiS2SlVCcHNou/moauKsh5W7NoSdrBr8g8pjZ2Hrig4B/gn/DiK5tH08AvpfGwkc+FUEg8dbByNzvzYj76cuUa0bcdavnxt49WtB1to6+J0Y2NDEIMc2IVY0veCcHrNc+zcmONEKPhjEQf9rRd2Dvv9VsW2dQiAflCpCK3DF164neP58XBKrTxhER1Fm8FO6YzO+yDJqFjKBoP8yotjdjbX2/pvoN9LXyuUKxDlkX8u3BrkBsNmy3PXXNJZurSDd9Jum+MT3g7qUd/pW41avGwuG6oiClRYZRubRKCQi4ekUmu2iTSRy41Wl1heIb3EaRNdp1jIORSTpUv4Ah42Wx5xN7fCcz7JbcBKuUDyiGt3U3KRj+qBTRxmNWoxMVdF1cBUcB2+BJAmCSYVcnm8sZknCL1eMCm/yigRmB+z2LQG7i7dc3d8kfq3aMtcGX7f1M8tXJH2Frn+WP1e2sjDT+l61ah8ijcNsDAMmnuSz1P+CRMSAQlCvbqgDffL6B4d++5HGZUH/Sk1687mLKZn0sJ/SBz/2hoH0cqU88zG1KClvPNrhlt1mYtdH5hYXgdrjlzMW14ZwyMANtsflP36fD+K53Q2W/9kCki+PMriKMnimm2RfrkSWh/keY/Kk3kSOxIdDXPUyxNfhMDxXbcoG6pwKLLTOHpFXjCP+fcw7y5ncRzJwD5vKHISUT6a0J8ZeIava7JErmKIgQbu+w995PuW4JpjC8u6KWDfQ7yhCI6T5yvL4coJ6+YRPZlHfGm0UPEjLhb0y6PFtxZ0YQ6Wdx2x5wvuhcr2L6rEyHei5saVv2c//i/7D9714PpbHn7DyFfzKP9zr/t74S3Cz33DUCtNtrF95RdF4ERxDDpLzs13vus95N3gz597zvmhf79371eP/t9hp1YZefnpzHdWkwwjm9F8eprRk1FGszk9yVgWR4sXzS5FEAnF9eFzAjC74RbY+YIJnhMuovWih7bA5T1VvQja7d7Fmdd7XKtdhcMLGDA/CuqjJ6f0cUm8cB5FsCuPF335pG7a8Nyy1TRKk7IY4iHKZZxryEwAkzlUf1oI8co4l8P51THGgmxYRA3Cbo/UmisM50GpUEEFKtUOVHU9f1gxX346j2qg4UDhKT8O9JDNN5Oj7OyaOQsZ+zgqQH+AoYETjDACCm491IPb1mv+YKUdrA5Kx/DFDzW8gXEM+Vzrdr9Zv5e+yGPke4LXCOqFvCSWxHKlWivmZKW0rvRfFBXNiV9zeFmb4ByglL6PYkqdEnaxqELO1nXXK3OcKgihOtkiJ5N+lEWJ37Y4FTHXTS0U3S0fePhwdPkx/hyyY8h95BnWgz3pHP6l0l3+r1vfbaFWXV/fbfX4pHTxwtY4IT7wqFfzsGeOS/YFiYfPkF09bK/2L3Drdc/bFQHYPVhff3av19IP6ux0FplWszFZZqESmWOfdzYfRclZaelZ46dz7KjfS1fsmjvWft/4UwMZlNRyMFf1xtyr+EEiP7lNPfyLWpUQyQagUTyU3qa5z9heGySLUXwWzUfunEz8Tylp1fFys1nrNsbc+zDEEJdrY8cD0kGnXFKXOc79xXqIsNfxAD0oFFizdgheB9mNPe3HmR8JrNfN4yxK5oRmiP8JskHU7z3aLTx3zMmPkvPNj3EyuMvJH6nfuVO/efPGJYmTQczJoAcoJwMNYE5O/UJS72mFgtarJ9wb3/Dyy+KtW6K4f/uYPE2Vuzdu3LzpunfunN86Jk9T5Xr1CruCruzGUeVj5CnocPhRQweAMZZkjDE2ivN4KWLxPg9zttJHmGlB3dSeKY6NafaPV9boP2YDukrsH+QTwOFk0AbbnPIoSbY+zqlgCCJOThWuPeS4YRu/boeG3+zDF5N0s/lJ8hQUOQxWyFOgApYlWfTlBcsCykAuGDAFtT9+z5BKRVM/hEsOFKUihEUJrzSB6DQmTbM70QEATdpEzaZYshRhIuICkcUqEzQbHT1sFHV+L5nW4GTKwLIl+vgKQIciBzROxVhTITceruyRsvzyWMJYxWBYPPtoYPnlzBqMzTh7/I/OzPZRB3RqzSNLDjthEIQdXOgWWo3udFkuykW+Zi4bYcctT3NQm/Kg+72UxEnrrB/EcRxFUI00I+ysgV6RfLpbGxXxSNKkiBxVfU7iJA4qHXAEl6ch/LPO4853O9jv+B21MLWBgJVpVFENDkruq9OEWbtefs+azp+E7GzGgrxRKNtkHfvIyTmKcbQUUIdqGnUw9ObE/ntNezAI/HBaAZbuTTuKb1DoeN+zf3ebUb975z/gwR+W4Vsk+G7hxwVUKFdzxUMIcMBBGOrqoWHqRjUYwxLicuMiMpCBapY4dkn6DCldfzaj35qdzQSUwwKxbjb79oyeuUaqkFObhnAkqqLtHxG69OQyAbJL8XRentqGYohuYYo8T4dU97P8H6ZDR+oIU/78SvcYkkfS8roz7j5zbvsfvua2tuvHkKR6sBcs320FQevuMgG3Tp/ztEfLB+Du9pW9a9z1Z8Lr8c5wGD+/uVkGg/WVpVqjLYXUlXAcppK5Z8TVmMU4jMNYawXLljXW4jnK//Goa3YBpsbsc2bMPkc/Rz9nKvJccTZj6t8dqV0Cr9CMzr6vGRZBARZwDr1iczB/dj7v+sTjPEdweV7q1q05EQXD2h6Cr7oPXKS5ELoatktYHNsWJcNg5ka5vFSn+dpHjt48dbk1GOjC7lK6/sMu3A/eFfxcgAO3w8GSpCm8IWAkI6VQ1ssM3UcP0acRYWWIyqjMtQyeWxH6yCKiSyMzbvKlI4vglL+MFlFEv70YjYROs94RQmCFtl2RjcbYH6dTfKVyv/IrlT+tkMqPmj9rIvMNDtxynnOQA8LQbvElyc7xYlaSpxejUTQSsK/Qb48WJxcj4PUueFubv5lGrVX88pUueO657m/duhX81j3hGD58dP/+88fwYSrn7uXu5cxhmv+hj8IDYFY+C4Wyj6uc0zHLIkb32B9Q+djPb231Qc/DjJik3yqkuXFxeSt4BXIvd95ekDdTRZMtlDPKlKlceVeZUqU/4P4TmJZd87n//NUjodpjsgbMq+Y9rjZv0wPdqjSLrHv9JCbNW2WM+miZPfsnCPz3OgKxbmRdZH5M2pUb/rfslDVF/hrGIfzutoIqDaoBi3Ve/peV5Baf/9wv8N0BTHCO8r8azBdqMHaq29PMTOKaE6agLss3TpiROoe9JD7txcddhpVgiS+hMqL0Lp377s/k88tmkpPoV25b1D/xvhditilMuvxEWB7R3fxh3hBLWF97B/Mm3c3cn6ByE1YnSZWQeQe9ibBX8qB59V5ugO4SnNv+e5NaTJLSFDZvM1OekexNIossJ4sMJVm+IbcazDYdsFfML1veTOKKbg0qP60lmc6ymKl6IT1lKT2lpFlR71L+ePbHTHXu8Y1zz1bRL8wlU91LyGvLMp+ez+a9B9W2s9T9GKiWUlQ+5ht9mHizjUx6Nln0WeL1XzS8satzg9mlTr8/7rlPZLwX4tXFIem6uX1H512UxKHt/I6Yt7fKwePb6btJfNjHfLOphlJaGCo+y00/OE+m6lqE9EzaSmem5vWjezmdSl5O/nNL0kzV4WNtNr5pglxzLxBN74r7Ka3z9EhwvwXxqSd/MVUa0ULuUtYN4DdpxRqdl9Z6NC3caPq60+ks8ymtf+JrHuz8sSwPPVp3E2S/KURZiaWrxJqPmdN8kV4Z7rW90XT3htJTPtD/42phsBaGO4cZ7BxmuH/LMouhaZ/5P9XpHdkmPv3Vx3Tdv0pGUj7ToOPNWYfpqIWOUXPx8yTzY+TO/StUbibO21dz90+RNe4jZH4tIPlj5+oZXdVC8qogNdRw8jt/MFTVoLUToqz6hVrOtfXP6K9Kk86zyTfJn8kjyR9vMH+QTfqetHdxWAoS5rNRudlZrNqLr+4wUN3hXW80vlcL3/uLd/U1svFS8kjydsYtseLc4yueeKZvyC2/0itwgbA6zPtmyWdwOu5I7aWkjKYvRNaBba9301kijBWf8fvk+yc0RcjrniBsHpEqFelbRp4bFNE/UTgKiukQpWQJBYzL16vp0oq2W4ktg0r7Y2H6Z6q9vB3r8rvMoXx+X+rzvn3PivKC8l6OqTKDvuJTVH6lDD9eLT5tMK2Wm4ky8oBCZvxfA8o67h3zHsMxTzM91+iYHRja2d0Y2ts1GC7aNUSfJZroXDRnK9eJI5/tTBzFbX/iaGB/gw1dNKIJrWkbM2zH9hSrCSy2pcESlpZlJl2rqGjVkaio+Nzq5CPOvo1IoB45ooC9TJEoTnfLHEdFO4xKUdl+HlXs0qhm+0Z1qtrhjuhkD9sZ0dWejC/tb7HY9o8ltiZLWRYr7XpX+cUlr8Mbz/vEPtZrqpKfijZEfqrZNdZVrthkF7L5g6/bNRQgDyoK2O0UyThUWG6zLxgQE8jud4iZdi/znA/XnGUf+z2A8uSNBUmwb5MU+ezZpK8iqtqdUd3utfc1+yC+tUud/QxznItYZZ/EJvs5m90Kt8NLfrXXeGMh8hEdxakXFZGoQvaoSsDed9gHMYFk5xw7F2wt299YmATbn6TIZ4NRvIcoE3V0KupxZegopfkZ7ffpsLEDNTFJ64z4QtQYIksWFPecdR887vtXlimFe1FPR9Aatwp6+aQU3qiBioKoo4p+Sfoq1N2h/awOaz8cAIMMMcxITNKUIRjxl6gxG1naonKNPexrZbu6AirUWCqjmt7h3tCgW+2xLJI3K2y9W8PzGi0mLHDYooNy0UXp6KYD0UtvhZOCuvzVbfHgxacfsZWOuCNUeAREJGQDPhq3Jlwm4SehRhY6FevRO8yBeU+GYeFui5sl21+4dpJhsNWVuIJWYyXuoCBWogrNWIlqysB7XaGBM7T0CWzU00vRQCeyHqmoaEdQ0caQYGX9ELvqtbuu6KWUTnRhXy2+4Gcg17hFIlLkd6YN02ln8ZO6/LRk9p+VFY6aU+b9pg2/tfjOk/GZVwoWyXNTaKEaa6G2oopOhYaK1udGM/0SLXQmzw4V7X46LCMYVWJ+Wj6ytC4UmnLPMvepJ2sxX2O5cOYaqC5+gjVQW1FF9navVEJDY9GEmmimr0NHmTBQCiMmLHBho7T2unRgf0kHYJAhhhnRrXjw6gM/PAIiEnJMXswbwkhPiBoTk2J2WSgXY+xxn1iSvlx+gmEoBXZ7FLaNaSK7JWAL24qSwMJWjJQhmgJbqbQpElhY2Ip5v5QnqkUlONSimk6gFvdaoUFjaOk32KinA9FCP2lIayRMtAdLcKRoWxZOOqWrfLgpo0fw4sMvX1IBRCRkA7UYh4TJZX7aBkfN4byaj9JiT/oSmzAMKahDB2U0uuhIXuMrlZbDT5bl9Zi6SilYf6Us9bPWoR4VlEc9Kq2ooi1RTW9xb2joJbVpWfr66+rVaMR92KTRTOVoQcWijnLDQBqNginMFNJCbKINbkYOrNrStNkejZ3keadit9oTt73iYz3RLjosnejC/mgcgEGGYpgedCQdbrpZT9t6BR9+t66X2I7VsQNud8Yk76GgiEjIjvo5BuNMxAvgYpIuNxAlIT/oYYTpCBGj/TGmxjGByTacWe/Oip+sCzO1MBdZul5F3IP78CjmYN4Tyzy1Hs1vPws1WhRLYpn+fB8WGUbmmQXnogFV9AMaMEnPoQFZegcNUOgdNEJFa9AINd2MRlTRc2hENX2HRtxrhYY+CS39J5ub9zeV3KsqoaPhMNCYRgsTlthEKTbLgVVbmra8a6/QqT0CHVY46Ziutu1vyQFhkCGGGdEtePSCD39sR0XsQLc7kV+mIIhIyI76OQbjTOQ+Uak0HQbiIxS7aFve+1aMrE2ixizj3iYw2YYZiSz5VXLdg/ssj2IO5j2+3j2xvixuCUtiOYL+fHyLDCPzzIJLm6ASm87dpWmcRtM2K03pUWlH0GhhwgKHTXtJHdiPAzDIEMOM6EYPePHhz2OyUmlO5HMVQERCjkkKGqo3dtFbfGC4D0Z6RdSYmhQyzvmRVVkL7sF9WKIvM88wNo/WJpuhRiOarzqlOfJoTqvSnkRtWpaox+060YU7ShIwUpdxNYHZNlT8OGoO5luR2S1Q0Sa0QE2taLnnOLMF1fQNWnCvlXftFbVpWfIIpKVSaY1U2jowYtLspyUdm8jvZpETrYKNtmgnkU7tcejQcNIhXW3b354DwmAM0VgM0xZHcnXXq0fw4sOfR2DFnS3J5yoIIhKyo36OwTgTMUkPGoiJUOyim3MvqRhZj0SNWcYxgcna88xbiSwtU1H3eLsPj2IO5vPYq3hiHVnMtVSX5Qj685EtMozOZBaQH63QgEPrFlptRS8dIHbAQDiv7hXn/NYKdAAPzFOoH5VtpoeZitCjh85ogh49evToK4T8oqRfWjniWjVAAwNRT8FooVTJv9GExTRVLn2jGZfjhbyrqMRyCqpORwU4K4k78IgPeYceV7mW6MBd0YUauu1ZFr243SfLxzZo3E7sAB8v4BXDZYy0Fyk8zozpNLPO+UWWEiqWhdo3+w1XwYL1WIn1vPOd2AAVuFhO21SnrYDKMNAPOYasaFItwKVWKu0vdKf1LNMr+PDDIyAiIRtpj2RfYp5h3LzG2bzKYTG54dLc3pVK+4UEDg4ODg4OrhIp+jBmSI40ZZxN+0Vdfim5H2htCStWrFixYsWKFWuxtgNSac9AmtkEK9bNbFiPLWiDiuzEchoLNbXnlqCtUmmnSCqYwowaLenYROfdjFyuNqIdV0YHmu2qy27sUXp9THDrEbz48MMjICIhG4nYpEYKb8UMeNNpZs32UMXyRGSeatsCfYluDP/OHVhOL6FjfAAdPaejdKz9hQ5YLDhs0YMK3X548OLDLw8CIhJyHlEVk+pcOmMqHZ/7FzqxmDJaLrXrnoCuSujolzDQf82oFU1pLcBpW2a/twPCIEMMM6K7jB7w4sMPj4CIhGyoFiORmcRsrCiW6Mt+JxmGyW6o6B10z2o9UTcMVEY3jFREN0yWllw5tIFbT1ov+sAv76FgISIhG2mJZGQppUJfYp5hVntgoL/AiAkLHDbcePDiww+PgIiETHJPqduuc70nUQGXVlqQSpsg7qBUpRXBiCnMWKQlLQe26MAS3egBLz788AiISMhG2jYpMYfLI0svqEhfWnaSYZh8HOtxAPYZ8ErOfVdyxqpSaQkqzUnJ6/DDgaNSaWkSHDrno3EWZ0pSKcXJp6FBK1yzFbhwVXKeosLJckH+LFmptDPYk+YLvyTPcQp+CAgICAiIiIiIiIhISEhISEjIyMjIyMiTk9DgSgR6SIAAAQIEmGaaaaaZZnp1F1ooqLEen83KUxBvYT1CeP9JRiVeoKl80lCptFaSSmXcig/udfxgDrr/YOywgg/QakUvLvdkmkK5YNh7HEaj0JQRGG7byDMVIkSIGN0niBIlSpSoMT9ixIgRI2Yc4sSJEyd+foIVVCDxVICEiecBZ6agoimkoLaiiu4KDdl7D1Ovyd3ol3zyS35bKTFG/RDHP+31q/J+yM2RmwVHbylIK2dwLKixFLTXUmkzoB8DGOGY8nFcNeIrP8iaV71GYXwWzhpPFiJaLUVhvRZGaSEWUgrTYkTGaqGuFqJQjZKUinZdGTFFFJWiNkFyLVBUiV7qXPRRWfZdZj8YwIgYpZbGGHUwjqsG2YdKFKlRXqrFDx5661r7V51D6RmNUkotPZdRSqml5xrLxk6lLN6jLC0SIkndzlFTBfeard6jcg+mslJpXUiopJJKKktVu0BCFVVUrV5Cd/UDEY3F+TyjEqkqPtKUHYZaGelqa58x7r8amaoBMQJBMV4ddILHGqsGuPx0xMs1lsvtB024XKm0rVTaQSqtC5WWheNzneDRGK8eG1zlKle5ylWvnTG97s11rnOd61znhjct7x1R3OMe97jHPe/7cZ/73Oc+93nAAx7wgAc80D1Pihs3bty4cePWs3WbR8dd4BmD4cGDBw8ezVGQ5r2R5tNHTExMTExMTExMTExMTExMTHnMD8MwDMMwDMMwDMMwDMMwDMMwDMMwDMMwDMMwDMMwDMMwDMMwDMMwDMMwDMMwDMMwDMMwDMMwDMMwrLgnQyAQCAQCgUAgEAgEAoFAIBAIBAKBQCAQCITyKRcSiUQikUgkEolEIpFIJBKJRCKRSCQSiUQikUgkEolEIpFIJBKJRGrdLRUrbFhjE9ZoGQsLCwsLS2v+BQtL+w4Vu9iZm1SY5Vwr31oCGxsbGxsbGxtb7/wOXrx4+Z//9Z0H8eHDhw8fvj2+RaIZigHRgGhANCAaEA2IBkQDogHRgGhANCAaEA2IBkQDogHRgGiRHKPTF5Ej/2q2nzURR1EfWdDgQAvEYg/g36zRpP/V0qUGmJNa1hoCb780+v5WQgvMeqsDzbDqrX7QseOOmt9b/RGIz95aD81Q+tj1sQLX8Dl0JCAO8UjWrQ3GfMzECizFSizFHKyCjp6v8Qoss1anYxXmM30JYqAjF4uwCPpczhmYi3lYhZU5XzkbKzEbK7BGVmchBiOJuViqPg+SXt/7XKzGIkzHCo+70j86pr6jK9v+zjqSEYNExJfNDzeqyfmxrE2HjlVxt1m4uL7xQuh9y6XO87/ZXjs378rVWFaizaQsXpuOJZjfR2P+p1i/LwBqCNbil6cpgU7Z+Q0DaYBeTJmJ/Un7E/bH7o/ZH7W/yX5tv9+YXP+9V1l84n/+4Dd+5Rd+QvCKFzzjIbe5xQ2uc40rXKKWaiqG0fk9fMshDnKA/aSRyi52spUtbGYGw+i3p9kmsZXaTyAM1azX78elSdf0hk2Nt++cAaGPHjsDQjducoZs3BR0/4EzIHTNWmdA6OJlOr9o6dYWLnGGLFyydUXwqtVt2obOXdCmbeic+a9zNntem5DZ83YvDw5a6dzQM6jd+p5B7TIMRKYbiDRO94uILdc+ItbfDw5/v7zWKuJdpeYF4R2/D137Na9pS8NVrIkfGrcxSlS19kteSHsjJ7ep9icIR7U/Xvvi/CXu6T/mNW5hxFXQaBC28SehUXmnO0bkVFEPEJpTLi5SLhzqXf5v3SINVzG58rJ62oOOXV+TkxcVOwgI3X6Wy9k50vho+kW6zKgYw2WGhBquURERxtu6757zZocOhut5t+7GyBGOyBFuR6T+XeOmRgk5iFwhjkjf/40i//vWP/J3t8NDfvJpjVMflJTZH36h8Z/6G3/R3VPRK/K/qKp+h3dKSuyvHzn4yB0P4sNbuz3MPvaae/fsbHfKvD3Md94e5tvv0PiOm9ex//9nR78rKrZvuF5PP04q+kthsf3NzQG+/uaGeOaDRXaVltmn7cItN2tOP+nmxhY7OUg86P3/2hJwZFnjfz4M8/1YD2dN45SvL4832G/oWlvW+eWdB70Zr/loP4zUeyVlQb8i9FRdY3kiu3LeY+UV648+lldgv/xSLGc8dvT5+nr7hefSP2Wq+IdIrv3VisbdO6PR4MbsAY0PrKyF8940C57LwYebW+yHcAldDiLG6toV4dKPUXlVdbV9+RUBvsIL85X6IHt3g5dXArzidfl/xCM7S8vsnR74Mg98qQde9cD7vQB/6f3paWd6aPZQMWiVJixrwCrot8w+K9prhXqsYLeld1nUaY004QS4ZNE4TiTQBTiBgCEMk4kkbIohgUGKUQRJGkaSXCTpRSQpQBEkaBgJ2oQE6ZSHIQKCa/r/8ZFahBEhEwZCFEMQORSjs2EQKAKDhmGQC4MehEFfw6C/YVCQIgjTJoTpSoRJRzBVp/8fb2qOtTSbA4lYX8Js41g7m3X1sYZ6szoeq4mb9Ch6KA89VIMe0onQndqDC9o+a9PIQV5DquGChvsaAmZefjQUjkSDOUZUD6yLErRoU7AyHtRL46a+Qf9U1++lT0kzS+IlXSW6WRQv6irSK1CVW5pTnmvlleQWBIpyuyrQ7rQ5LU6T0+DUOTVOtVPhlDqWU+CYTsgJOrpDznjfNFSBS+50WhXCJXcqrfrY9fWaSdXLrgqNb5rPAtcsqD5W2mU+aFoFLvM1mlYFGxc3zfsoywLXrFbcTwApd/vq1QvMVUrcqXm1p2pB9bpT8+q6qgVyVe+EqqhPMzMzM/9uxrgik8nk3TD9BJxtaRpTbWM7VPvY9lGHn2rJR3DsTB/hsTN3+AjXj/ow5Au2+zDqR6tZ8jG0ZH1y7MztPpKenZIw8fUGLeXf3v61Z5Yu5l8Ol7gjpW+VfDqT4cxSDzPVLfn6VKna4E6lS/wS2VAvu2p8Mu0qY9JVxvgmVV6fdtVzk0wmxjepaH36/81tMasZJfh/QDdtmh+xsJ4EDgn6SdBLgi4SdJKgnQRREgRIoJMAqVPkf/lP/pGf5Uf5Qb6Xb+Ur+Ug+kPfkTXlZXpIX5Hl5Tp6Rp+QJeUwelkOSlQNylVwpV8jl4sl+2S0rsiw7ZVyOk5gw//rVXuBfAAA=)format("woff2")}*,::after,::before{-webkit-box-sizing:border-box;box-sizing:border-box}html{-ms-text-size-adjust:100%;-webkit-text-size-adjust:100%;font-family:sans-serif;line-height:1.15;-webkit-text-size-adjust:100%;-ms-text-size-adjust:100%;-ms-overflow-style:scrollbar;-webkit-tap-highlight-color:transparent}@-ms-viewport{width:device-width}body{font:1.0625rem/1.5 Segoe UI,"Segoe UI Web Regular","Segoe UI Regular WestEuropean","Segoe UI",Tahoma,Arial,Roboto,"Helvetica Neue",sans-serif,"Apple Color Emoji","Segoe UI Emoji","Segoe UI Symbol";color:#333;text-align:left}.entry-content button:focus,[tabindex="-1"]:focus,a:not([href]):not([tabindex]):focus{outline:0}h2{margin-top:0;margin-bottom:.5rem}p{margin-top:0;margin-bottom:1rem}a{color:#005da6;text-decoration:underline}a:hover{text-decoration:underline}a:not([href]):not([tabindex]),a:not([href]):not([tabindex]):focus,a:not([href]):not([tabindex]):hover{color:inherit;text-decoration:none}code,pre{font:1em monospace,monospace}pre{margin-top:0;margin-bottom:1rem;-ms-overflow-style:scrollbar;display:block;font-size:87.5%;color:#212529}img{vertical-align:middle;border-style:none}svg:not(:root){overflow:hidden}th{text-align:inherit}button{border-radius:0}button:focus{outline:5px}button{font-family:inherit;line-height:inherit}code,pre{font-family:SFMono-Regular,Menlo,Monaco,Consolas,"Liberation Mono","Courier New",monospace}@media (min-width:768px){}@media (max-width:575.98px){}@media (max-width:767.98px){}@media (max-width:991.98px){}@media (max-width:1199.98px){}.table-responsive{margin-bottom:12px}@media screen and (prefers-reduced-motion:reduce){}.wrapper{padding:30px 0}article img{max-width:100%;height:auto}@media screen and (max-width:567px){.entry-content{margin-top:14px}}@media screen and (max-width:320px){}@media screen and (max-width:667px){}@media screen and (max-width:736px){}@-webkit-keyframes hvr-pop{50%{-webkit-transform:scale(1.2);transform:scale(1.2)}}@keyframes hvr-pop{50%{-webkit-transform:scale(1.2);transform:scale(1.2)}}.hvr-pop{display:inline-block;vertical-align:middle;-webkit-transform:perspective(1px) translateZ(0);transform:perspective(1px) translateZ(0);box-shadow:0 0 1px transparent}.hvr-pop:active,.hvr-pop:focus,.hvr-pop:hover{-webkit-animation-name:hvr-pop;animation-name:hvr-pop;-webkit-animation-duration:.3s;animation-duration:.3s;-webkit-animation-timing-function:linear;animation-timing-function:linear;-webkit-animation-iteration-count:1;animation-iteration-count:1}#single-wrapper article.addtoanyshare{position:relative}#single-wrapper article.addtoanyshare:before{position:absolute;content:"";float:left;height:100%;left:-15px;width:calc(100% + 30px);z-index:-1;box-shadow:2px 2px 8px rgba(0,0,0,.1);border-radius:4px}.postcontent{margin-bottom:2px;padding-top:60px;padding-left:16%;padding-right:16%;background-color:#fff;border-radius:4px 4px 0 0}@media screen and (max-width:800px){.postcontent{padding:0 30px}}@media screen and (max-width:768px){.entry-content{margin-top:14px;word-break:break-word}}@media screen and (max-width:414px){}@media screen and (max-width:850px) and (orientation:landscape){}::-webkit-input-placeholder{color:#005da6}@media screen and (min-width:767px){}@media screen and (min-width:768px){}::-webkit-scrollbar{width:10px}::-webkit-scrollbar-track{background:#f1f1f1;border-radius:12px}::-webkit-scrollbar-thumb{background:#888;border-radius:10px}::-webkit-scrollbar-thumb:hover{background:#555}@media (max-width:767px){}@media only screen and (max-width:991px){}@media screen and (max-width:479px){}@media screen and (max-width:400px){}.related-articles .post-comments .comment-icon svg{vertical-align:middle;margin-right:9px!important;width:24px}#single-wrapper .postcontent .linkicon{font-size:16px;margin-left:10px;opacity:0;text-decoration:none;border:none;background:0 0;color:#005da6;position:relative;display:inline}#single-wrapper .postcontent .linkicon:focus,#single-wrapper .postcontent .linkicon:hover,#single-wrapper .postcontent :focus+.linkicon,#single-wrapper .postcontent :hover+.linkicon{opacity:1}#single-wrapper .postcontent .linkicon:focus,#single-wrapper .postcontent :focus+.linkicon{border:2px solid #000}#single-wrapper .postcontent .linkicon:hover,#single-wrapper .postcontent :hover+.linkicon{cursor:pointer}#single-wrapper .postcontent .linkicon .screenreader-text{position:absolute;height:1px;width:1px;padding:0;margin:-1px;overflow:hidden;clip:rect(0,0,0,0);border:0}.postcontent .entry-content a,.postcontent .entry-content p{word-break:break-word}.entry-content h1:hover .linkicon,.entry-content h2:hover .linkicon,.entry-content h3:hover .linkicon,.entry-content h4:hover .linkicon,.entry-content h5:hover .linkicon{display:inline-block;text-decoration:none}table,td,th{border:1px solid #d3d3d3;border-collapse:collapse}td,th{padding:5px;min-width:150px}thead tr,thead+tbody tr:nth-child(2n),tr:nth-child(odd){background-color:#f9f9f9}table.default tr:nth-child(2n),thead+tbody tr:nth-child(odd){background-color:#fff}.table-responsive::-webkit-scrollbar{height:15px}.table-responsive::-webkit-scrollbar-track{background-color:#dadada}.table-responsive::-webkit-scrollbar-thumb{background-color:#969696}body pre{background-color:#f0f0f0!important;padding:10px!important;border-radius:10px;border:0!important;position:relative;overflow:auto;border-top-left-radius:0!important;border-top-right-radius:0!important}#single-wrapper .postcontent button{max-width:100%;height:auto!important;display:block}@media (max-width:859px){}@media (max-width:520px){}@media screen and (max-width:1024px){}@media screen and (max-width:767px){}@media screen and (max-width:1024px){}@media only screen and (max-width:859px){}@media all and (max-width:420px){}.entry-meta-comment .post-like .icon-like-dislike svg{width:.875rem;vertical-align:-2px;fill:#005da6;margin-right:.2rem;margin-left:.3rem}@media screen{}@media all and (max-width:700px){}@media all and (max-width:1084px){}@page{size:A4;margin:2cm}@media (min-width:768px){}@media screen and (max-height:450px){}@media screen and (max-height:300px){}@media screen and (max-width:479px){}.code-header{background-color:#e6e6e6;position:relative;height:30px;border:1px solid #e6e6e6;border-top-left-radius:10px;border-top-right-radius:10px}.code-header button{position:absolute;top:0;right:10px;font-size:.85rem;padding:.15rem;border:0;background-color:transparent!important;cursor:pointer}.code-header button i{position:relative;top:2px}@media screen and (max-width:1024px){}@media screen and (max-width:480px){}.social-icon-bar a:hover .sd-twitter-x{fill:#999}a.stayinformedsite:hover .f-twitter-x{fill:#000000}@media screen and (max-width:992px){}</style>
<style>@media all and (max-width:480px){}@media all and (max-width:525px){}</style>
<style>@font-face{font-family:"FabricIcons";src:url(data:font/woff;base64,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)format("woff");font-style:normal;font-weight:normal}.fabric-icon:before{font-family:"FabricIcons";-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale;font-style:normal;font-variant:normal;font-weight:normal;text-decoration:none;text-transform:none}.fabric-icon--Link:before{content:""}.fabric-icon--Copy:before{content:""}</style>
<style>@media screen and (max-width:767px){}@media screen and (max-width:480px){}.icon-like-dislike svg{width:20px;vertical-align:middle;margin-left:10px;fill:#005da6}</style>
<style>@media screen and (min-width:980px){}[data-featherlight] img{cursor:-webkit-zoom-in;cursor:-moz-zoom-in;cursor:zoom-in}@-webkit-keyframes featherlightLoader{0%{-webkit-transform:rotate(0);transform:rotate(0)}100%{-webkit-transform:rotate(360deg);transform:rotate(360deg)}}@keyframes featherlightLoader{0%{-webkit-transform:rotate(0);transform:rotate(0)}100%{-webkit-transform:rotate(360deg);transform:rotate(360deg)}}@-webkit-keyframes fadein{from{opacity:0}to{opacity:1}}@keyframes fadein{from{opacity:0}to{opacity:1}}</style>
<style>@media (max-width:991px){}</style>
<link rel=https://api.w.org/ href=https://devblogs.microsoft.com/dotnet/wp-json/><link rel=alternate type=application/json href=https://devblogs.microsoft.com/dotnet/wp-json/wp/v2/posts/47452><link rel=EditURI type=application/rsd+xml title=RSD href=https://devblogs.microsoft.com/dotnet/xmlrpc.php?rsd>
<link rel=shortlink href="https://devblogs.microsoft.com/dotnet/?p=47452">
<link rel=alternate type=application/json+oembed href="https://devblogs.microsoft.com/dotnet/wp-json/oembed/1.0/embed?url=https%3A%2F%2Fdevblogs.microsoft.com%2Fdotnet%2Fperformance-improvements-in-net-8%2F">
<link rel=alternate type=text/xml+oembed href="https://devblogs.microsoft.com/dotnet/wp-json/oembed/1.0/embed?url=https%3A%2F%2Fdevblogs.microsoft.com%2Fdotnet%2Fperformance-improvements-in-net-8%2F&amp;format=xml">
<style id=custom-background-css>body.custom-background{background-color:#f4f4f4}</style>
<link rel=icon href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABIAAAASBAMAAACk4JNkAAAAMFBMVEUApO9fxvVvzPZ/ugCl3/m32G+/3H/b7LfyUCL3kXT4nIL6wbH/uQD/12//3H//67cLnuJJAAAAKElEQVQI12PoAIJpxkDAQB3WKiDYHgoEDEpA4H8XCBhAQO4MEFCHBQB+Zj9/rBzZFQAAAABJRU5ErkJggg==" sizes=192x192>
<meta name=msapplication-TileImage content=https://devblogs.microsoft.com/dotnet/wp-content/uploads/sites/10/2018/10/Microsoft-Favicon.png>
<style>@media only screen and (min-width:650px){}@keyframes nsl-loader-spin{0%{transform:rotate(0deg)}to{transform:rotate(360deg)}}</style>

<style data-id=immersive-translate-input-injected-css>@-webkit-keyframes immersive-translate-loading-animation{from{-webkit-transform:rotate(0deg)}to{-webkit-transform:rotate(359deg)}}@keyframes immersive-translate-loading-animation{from{transform:rotate(0deg)}to{transform:rotate(359deg)}}@keyframes immersiveTranslateShadowRolling{0%{box-shadow:0px 0 rgba(255,255,255,0),0px 0 rgba(255,255,255,0),0px 0 rgba(255,255,255,0),0px 0 rgba(255,255,255,0)}12%{box-shadow:100px 0 var(--loading-color),0px 0 rgba(255,255,255,0),0px 0 rgba(255,255,255,0),0px 0 rgba(255,255,255,0)}25%{box-shadow:110px 0 var(--loading-color),100px 0 var(--loading-color),0px 0 rgba(255,255,255,0),0px 0 rgba(255,255,255,0)}36%{box-shadow:120px 0 var(--loading-color),110px 0 var(--loading-color),100px 0 var(--loading-color),0px 0 rgba(255,255,255,0)}50%{box-shadow:130px 0 var(--loading-color),120px 0 var(--loading-color),110px 0 var(--loading-color),100px 0 var(--loading-color)}62%{box-shadow:200px 0 rgba(255,255,255,0),130px 0 var(--loading-color),120px 0 var(--loading-color),110px 0 var(--loading-color)}75%{box-shadow:200px 0 rgba(255,255,255,0),200px 0 rgba(255,255,255,0),130px 0 var(--loading-color),120px 0 var(--loading-color)}87%{box-shadow:200px 0 rgba(255,255,255,0),200px 0 rgba(255,255,255,0),200px 0 rgba(255,255,255,0),130px 0 var(--loading-color)}100%{box-shadow:200px 0 rgba(255,255,255,0),200px 0 rgba(255,255,255,0),200px 0 rgba(255,255,255,0),200px 0 rgba(255,255,255,0)}}@media (prefers-color-scheme:dark){}@media screen and (max-width:768px){}</style><meta name=referrer content=no-referrer><meta http-equiv=content-security-policy content="default-src 'none'; font-src 'self' data:; img-src 'self' data:; style-src 'unsafe-inline'; media-src 'self' data:; script-src 'unsafe-inline' data:; object-src 'self' data:; frame-src 'self' data:;"><style>img[src="data:,"],source[src="data:,"]{display:none!important}</style><noscript>
		<style>
			body {
			visibility: visible;
			opacity: 1;
			}
		</style>
	</noscript></head>
<body class="post-template-default single single-post postid-47452 single-format-standard custom-background wp-featherlight-captions group-blog" style=visibility:visible;opacity:1><div style=display:none!important id=lightningjs-usabilla_live></div>
 <div id=cookie-banner style=display:none!important></div>
 
<div id=headerArea class=uhf data-m='{"cN":"headerArea","cT":"Area_coreuiArea","id":"a1Body","sN":1,"aN":"Body"}' style=display:none!important>
 
 </div><style>/*!  | Copyright 2017 Microsoft Corporation | This software is based on or incorporates material from the files listed below (collectively, "Third Party Code"). Microsoft is not the original author of the Third Party Code. The original copyright notice and the license under which Microsoft received Third Party Code are set forth below together with the full text of such license. Such notices and license are provided solely for your information. Microsoft, not the third party, licenses this Third Party Code to you under the terms in which you received the Microsoft software or the services, unless Microsoft clearly states that such Microsoft terms do NOT apply for a particular Third Party Code. Unless applicable law gives you more rights, Microsoft reserves all other rights not expressly granted under such agreement(s), whether by implication, estoppel or otherwise.*//*! normalize.css v3.0.3 | MIT License | github.com/necolas/normalize.css */body{margin:0}@media (max-width:767px){}.context-uhf *,.context-uhf *:before,.context-uhf *:after{box-sizing:inherit}@keyframes fadeIn{0%{opacity:0}1%{opacity:0}100%{opacity:1}}@keyframes fadeOut{0%{opacity:1}1%{opacity:1}100%{opacity:0}}@media all and (max-width:539px){}@media all and (min-width:540px) and (max-width:767px){}@media all and (min-width:768px) and (max-width:1083px){}@media all and (min-width:1084px) and (max-width:1399px){}@media all and (min-width:1400px){}@media only screen and (max-width:539px){}@media only screen and (min-width:320px){}@media only screen and (min-width:540px){}@media screen and (-ms-high-contrast){}@media screen and (-ms-high-contrast){}@media screen and (-ms-high-contrast){}@media screen and (-ms-high-contrast){}@media screen and (-ms-high-contrast){}@media screen and (-ms-high-contrast){}@media screen and (-ms-high-contrast){}@media screen and (-ms-high-contrast){}@media (max-width:767px){}@media (max-width:767px){}@media only screen and (max-width:767px){}@media only screen and (min-width:768px){}@media screen and (min-width:320px){}@media screen and (min-width:540px){}@media only screen and (max-width:767px){}@media only screen and (max-width:767px){}@media only screen and (max-width:767px){}@media only screen and (max-width:767px){}@media only screen and (max-width:767px){}@media only screen and (max-width:767px){}@media only screen and (max-width:767px){}@media only screen and (max-width:767px){}@media only screen and (max-width:767px){}@media only screen and (max-width:767px){}@media screen and (-ms-high-contrast:active){}@media screen and (-ms-high-contrast:active),(forced-colors:active){}@media only screen and (min-width:860px){}@media only screen and (min-width:860px) and (max-width:1399px){}@media only screen and (max-width:859px){}@media only screen and (max-width:1399px){}@media only screen and (min-width:860px) and (max-width:1083px){}@media only screen and (min-width:860px) and (max-width:1399px){}@media only screen and (max-width:1399px){}@media only screen and (max-width:859px){}@media only screen and (min-width:860px) and (max-width:1083px){}@media (min-width:1083px){}@media (min-width:1084px){}@keyframes slideup{from{height:50px}to{height:0}}@keyframes slidedown{from{height:0}to{height:54px}}@media screen and (min-width:860px){}@media only screen and (min-width:860px) and (min-width:615px) and (max-width:819px){}@media only screen and (min-width:860px) and (min-width:820px) and (max-width:1024px){}@media only screen and (min-width:860px) and (min-width:1025px) and (max-width:1229px){}@media only screen and (min-width:860px) and (min-width:1230px){}@media only screen and (min-width:860px) and (min-width:1230px) and (max-width:1300px){}@media screen and (min-width:860px){}@media only screen and (min-width:860px) and (min-width:1400px) and (max-width:1778px){}@media only screen and (min-width:860px) and (min-width:1779px){}@media screen and (min-width:860px){}@media only screen and (min-width:1400px){}@media only screen and (min-width:1779px){}@media only screen and (min-width:1084px) and (max-width:1399px){}@media only screen and (max-width:939px) and (min-width:859px){}.c-uhff-base .c-uhff-ccpa svg{padding-right:8px;height:16px}@media only screen and (max-width:1083px){}@media only screen and (max-width:767px){}@media only screen and (max-width:539px){}@supports (-ms-ime-align:auto){a.c-uhff-link{display:inline-block}}</style>
<div class="hfeed site" id=page>
<main class=site-main id=main role=main>
<div class=wrapper id=single-wrapper>
 <div class=container id=content tabindex=-1>
 <div class=row id=mainContent>
 
 
<div class="col-md content-area" id=primary>
 
 <article data-clarity-region=article class=addtoanyshare id=post-47452 data-bi-id=body>
<div class="row justify-content-center postcontent" id=featured>
 <div class="entry-content col-12 sharepostcontent">
 <h1 class=entry-title style=margin-bottom:15px;display:none!important>Performance Improvements in .NET 8</h1> <div class="row justify-content-center author-header" style=display:none!important></div><div style=clear:both;padding-bottom:10px;display:none!important></div> <div class="entry-meta entry-meta-layout" style=text-align:center;display:none!important>
 <p style="text-align:center;font-size:14px;color:rgb(97,97,97);margin-top:20px;padding-top:6px;border-top:2px solid rgb(151,149,147);display:none!important">
 September 13th, 2023<span class=entry-meta-comment style=display:none!important><span class=post-like id=postLike-47452 style=display:none!important><span class=icon-like-dislike style=display:none!important><a class=x-hidden-focus aria-label="Login to like, vote count 138" title data-toggle=tooltip href="https://devblogs.microsoft.com/dotnet/wp-login.php?redirect_to=https%3A%2F%2Fdevblogs.microsoft.com%2Fdotnet%2Fperformance-improvements-in-net-8%2F" data-bi-id=body data-bi-name="Login to like" data-original-title="Login to like" style=display:none!important><svg xmlns=http://www.w3.org/2000/svg viewBox="0 0 2048 2048" class="svg_dd790ee3 x-hidden-focus" focusable=false><path d="M1504 128q113 0 212 43t173 116 116 173 43 212q0 109-41 209t-118 176l-865 864-865-864Q83 981 42 881T0 672q0-112 42-211t117-173 173-117 212-43q83 0 148 19t120 52 106 81 106 103q55-56 105-103t106-80 121-53 148-19zm294 838q59-59 90-135t31-159q0-87-32-162t-88-131-132-87-163-32q-84 0-149 26t-120 70-105 97-106 111q-54-54-105-109t-106-99-121-72-148-28q-86 0-162 32t-132 89-89 133-33 162q0 83 31 159t91 135l774 774 774-774z"></path></svg></a></span></span></span></p>
 </div>
 <p style=display:none!important>I look forward to summer every year. Sun, beach, warm nights, and putting the finishing touches on the next version of .NET. It’s also the time I get to continue a tradition I started for myself back in 2017 of writing about the performance improvements that have gone into the latest .NET incarnation. A year ago that was , which followed similar posts for , , , , and .</p>
<p style=display:none!important>Since was released a year ago, you’ve likely been inundated with news about AI and ChatGPT. You may have even invested effort in using AI and/or . And I got to wondering: could AI write this blog post for me? So I issued the following request to :</p>
<blockquote style=display:none!important></blockquote>
<p style=display:none!important>And the response?</p>
<blockquote style=display:none!important>
</blockquote>
<p style=display:none!important>Fair enough (especially since, after writing this post and measuring the token count, it’s north of 300,000). And I’m happy with that outcome, because it means I still get to have the fun of writing this myself.</p>
<p style=display:none!important>Throughout the past year, as I was reviewing PRs in various .NET repos, I maintained a list of all the PRs that I might want to cover in this post, which is focused on the core runtime and libraries ( provides an in-depth focus on ASP.NET). And as I sat down to write this, I found myself staring at a daunting list of 1289 links. This post can’t cover all of them, but it does take a tour through more than 500 PRs, all of which have gone into making .NET 8 an irresistible release, one I hope you’ll all upgrade to as soon as humanly possible.</p>
<p style=display:none!important>.NET 7 was super fast. .NET 8 is faster.</p>
<h2 id=table-of-contents style=display:none!important>Table of Contents</h2>
<ul style=display:none!important>
</ul>
<h2 id=benchmarking-setup style=display:none!important>Benchmarking Setup</h2>
<p style=display:none!important>Throughout this post, I include microbenchmarks to highlight various aspects of the improvements being discussed. Most of those benchmarks are implemented using , and, unless otherwise noted, there is a simple setup for each of these benchmarks.</p>
<p style=display:none!important>To follow along, first make sure you have and installed. For this post, I’ve used the .NET 8 Release Candidate (8.0.0-rc.1.23419.4).</p>
<p style=display:none!important>With those prerequisites taken care of, create a new C# project in a new directory:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>That directory will contain two files: (the project file with information about how the application should be built) and (the code for the application). Replace the entire contents of with this:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>The preceding project file tells the build system we want:</p>
<ul style=display:none!important>
</ul>
<p style=display:none!important>The at the end pulls in BenchmarkDotNet from so that we’re able to use the library in . (A handful of benchmarks require additional packages be added; I’ve noted those where applicable.)</p>
<p style=display:none!important>For each benchmark, I’ve then included the full source; just copy and paste that code into , replacing its entire contents. In each test, you’ll notice several attributes may be applied to the class. The attribute indicates I want it to track managed allocation, the attribute indicates I want it to report on the actual assembly code generated for the test (and by default one level deep of functions invoked by the test), and the attribute simply suppresses some columns of data BenchmarkDotNet might otherwise emit by default but are unnecessary for our purposes here.</p>
<p style=display:none!important>Running the benchmarks is then straightforward. Each shown test also includes a comment at the beginning for the command to run the benchmark. Typically, it’s something like this:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>The preceding command:</p>
<ul style=display:none!important>
</ul>
<p style=display:none!important>Throughout the post, I’ve shown many benchmarks and the results I received from running them. All of the code works well on all supported operating systems and architectures. Unless otherwise stated, the results shown for benchmarks are from running them on Linux (Ubuntu 22.04) on an x64 processor (the one bulk exception to this is when I’ve used to show assembly code, in which case I’ve run them on Windows 11 due to a sporadic issue on Unix with on .NET 7 not always producing the requested assembly). My standard caveat: these are , often measuring operations that take very short periods of time, but where improvements to those times add up to be impactful when executed over and over and over. Different hardware, different operating systems, what else is running on your machine, your current mood, and what you ate for breakfast can all affect the numbers involved. In short, don’t expect the numbers you see to match exactly the numbers I report here, though I have chosen examples where the of differences cited is expected to be fully repeatable.</p>
<p style=display:none!important>With all that out of the way, let’s dive in…</p>
<h2 id=jit style=display:none!important>JIT</h2>
<p style=display:none!important>Code generation permeates every single line of code we write, and it’s critical to the end-to-end performance of applications that the compiler doing that code generation achieves high code quality. In .NET, that’s the job of the Just-In-Time (JIT) compiler, which is used both “just in time” as an application executes as well as in Ahead-Of-Time (AOT) scenarios as the workhorse to perform the codegen at build-time. Every release of .NET has seen significant improvements in the JIT, and .NET 8 is no exception. In fact, I dare say the improvements in .NET 8 in the JIT are an incredible leap beyond what was achieved in the past, in large part due to dynamic PGO…</p>
<h3 id=tiering-and-dynamic-pgo style=display:none!important>Tiering and Dynamic PGO</h3>
<p style=display:none!important>To understand dynamic PGO, we first need to understand “tiering.” For many years, a .NET method was only ever compiled once: on first invocation of the method, the JIT would kick in to generate code for that method, and then that invocation and every subsequent one would use that generated code. It was a simple time, but also one frought with conflict… in particular, a conflict between how much the JIT should invest in code quality for the method and how much benefit would be gained from that enhanced code quality. Optimization is one of the most expensive things a compiler does; a compiler can spend an untold amount of time searching for additional ways to shave off an instruction here or improve the instruction sequence there. But none of us has an infinite amount of time to wait for the compiler to finish, especially in a “just in time” scenario where the compilation is happening as the application is running. As such, in a world where a method is compiled once for that process, the JIT has to either pessimize code quality or pessimize how long it takes to run, which means a tradeoff between steady-state throughput and startup time.</p>
<p style=display:none!important>As it turns out, however, the vast majority of methods invoked in an application are only ever invoked once or a small number of times. Spending a lot of time optimizing such methods would actually be a deoptimization, as likely it would take much more time to optimize them than those optimizations would gain. So, .NET Core 3.0 introduced a new feature of the JIT known as “tiered compilation.” With tiering, a method could end up being compiled multiple times. On first invocation, the method would be compiled in “tier 0,” in which the JIT prioritizes speed of compilation over code quality; in fact, the mode the JIT uses is often referred to as “min opts,” or minimal optimization, because it does as little optimization as it can muster (it still maintains a few optimizations, primarily the ones that result in less code to be compiled such that the JIT actually runs faster). In addition to minimizing optimizations, however, it also employs call counting “stubs”; when you invoke the method, the call goes through a little piece of code (the stub) that counts how many times the method was invoked, and once that count crosses a predetermined threshold (e.g. 30 calls), the method gets queued for re-compilation, this time at “tier 1,” in which the JIT throws every optimization it’s capable of at the method. Only a small subset of methods make it to tier 1, and those that do are the ones worthy of additional investment in code quality. Interestingly, there are things the JIT can learn about the method from tier 0 that can lead to even better tier 1 code quality than if the method had been compiled to tier 1 directly. For example, the JIT knows that a method “tiering up” from tier 0 to tier 1 has already been executed, and if it’s already been executed, then any fields it accesses are now already initialized, which means the JIT can look at the values of those fields and base the tier 1 code gen on what’s actually in the field (e.g. if it’s a , the JIT can now treat the value of that field as if it were ). If the method were instead compiled directly to tier 1, the JIT might not be able to make the same optimizations. Thus, with tiering, we can “have our cake and eat it, too.” We get both good startup and good throughput. Mostly…</p>
<p style=display:none!important>One wrinkle to this scheme, however, is the presence of longer-running methods. Methods might be important because they’re invoked many times, but they might also be important because they’re invoked only a few times but end up running forever, in particular due to looping. As such, tiering was disabled by default for methods containing backward branches, such that those methods would go straight to tier 1. To address that, .NET 7 introduced On-Stack Replacement (OSR). With OSR, the code generated for loops also included a counting mechanism, and after a loop iterated to a certain threshold, the JIT would compile a new optimized version of the method and jump from the minimally-optimized code to continue execution in the optimized variant. Pretty slick, and with that, in .NET 7 tiering was also enabled for methods with loops.</p>
<p style=display:none!important>But why is OSR important? If there are only a few such long-running methods, what’s the big deal if they just go straight to tier 1? Surely startup isn’t significantly negatively impacted? First, it can be: if you’re trying to trim milliseconds off startup time, every method counts. But second, as noted before, there are throughput benefits to going through tier 0, in that there are things the JIT can learn about a method from tier 0 which can then improve its tier 1 compilation. And the list of things the JIT can learn gets a whole lot bigger with dynamic PGO.</p>
<p style=display:none!important>Profile-Guided Optimization (PGO) has been around for decades, for many languages and environments, including in .NET world. The typical flow is you build your application with some additional instrumentation, you then run your application on key scenarios, you gather up the results of that instrumentation, and then you rebuild your application, feeding that instrumentation data into the optimizer, allowing it to use the knowledge about how the code executed to impact how it’s optimized. This approach is often referred to as “static PGO.” “Dynamic PGO” is similar, except there’s no effort required around how the application is built, scenarios it’s run on, or any of that. With tiering, the JIT is already generating a tier 0 version of the code and then a tier 1 version of the code… why not sprinkle some instrumentation into the tier 0 code as well? Then the JIT can use the results of that instrumentation to better optimize tier 1. It’s the same basic “build, run and collect, re-build” flow as with static PGO, but now on a per-method basis, entirely within the execution of the application, and handled automatically for you by the JIT, with zero additional dev effort required and zero additional investment needed in build automation or infrastructure.</p>
<p style=display:none!important>Dynamic PGO first previewed in .NET 6, off by default. It was improved in .NET 7, but remained off by default. Now, in .NET 8, I’m thrilled to say it’s not only been significantly improved, it’s now on by default. This one-character PR to enable it might be the most valuable PR in all of .NET 8: .</p>
<p style=display:none!important>There have been a multitude of PRs to make all of this work better in .NET 8, both on tiering in general and then on dynamic PGO in particular. One of the more interesting changes is , which added more tiers, though we still refer to the unoptimized as “tier 0” and the optimized as “tier 1.” This was done primarily for two reasons. First, instrumentation isn’t free; if the goal of tier 0 is to make compilation as cheap as possible, then we want to avoid adding yet more code to be compiled. So, the PR adds a new tier to address that. Most code first gets compiled to an unoptimized and uninstrumented tier (though methods with loops currently skip this tier). Then after a certain number of invocations, it gets recompiled unoptimized but instrumented. And then after a certain number of invocations, it gets compiled as optimized using the resulting instrumentation data. Second, / (R2R) images were previously unable to participate in dynamic PGO. This was a problem for taking full advantage of all that dynamic PGO offers, in particular because there’s a significant amount of code that every .NET application uses that’s already R2R’d: the core libraries. is an AOT technology that enables most of the code generation work to be done at build-time, with just some minimal fix-ups applied when that precompiled code is prepared for execution. That code is optimized and not instrumented, or else the instrumentation would slow it down. So, this PR also adds a new tier for R2R. After an R2R method has been invoked some number of times, it’s recompiled, again with optimizations but this time also with instrumentation, and then when that’s been invoked sufficiently, it’s promoted again, this time to an optimized implementation utilizing the instrumentation data gathered in the previous tier.
</p>
<p style=display:none!important>There have also been multiple changes focused on doing more optimization in tier 0. As noted previously, the JIT wants to be able to compile tier 0 as quickly as possible, however some optimizations in code quality actually help it to do that. For example, teaches it to do some amount of constant folding (evaluating constant expressions at compile time rather than at execution time), as that can enable it to generate much less code. Much of the time the JIT spends compiling in tier 0 is for interactions with the Virtual Machine (VM) layer of the .NET runtime, such as resolving types, and so if it can significantly trim away branches that won’t ever be used, it can actually speed up tier 0 compilation while also getting better code quality. We can see this with a simple repro app like the following:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>I can set the environment variable to ; that will result in the JIT printing out to the console the code it emits for this method. On .NET 7, when I run this (), I get the following tier 0 code:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>The important thing to note here is that all of the code associated with the had to be emitted, including the JIT needing to resolve the method tokens involved (which is how it knew to print “System.Console:WriteLine”), even though that branch will provably never be taken (it’s only taken when and the JIT can see that is a ). Now in .NET 8, it applies the previously-reserved-for-tier-1 constant folding optimizations that recognize the value is not an and generates tier 0 code accordingly ():</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important> and also enable some JIT intrinsics to be employed in tier 0 (a JIT intrinsic is a method the JIT has some special knowledge of, either knowing about its behavior so it can optimize around it accordingly, or in many cases actually supplying its own implementation to replace the one in the method’s body). This is in part for the same reason; many intrinsics can result in better dead code elimination (e.g. ). But more so, without recognizing intrinsics as being special, we might end up generating code for an intrinsic method that we would never otherwise need to generate code for, even in tier 1. also eliminates some forms of boxing in tier 0.</p>
<p style=display:none!important>Collecting all of this instrumentation in tier 0 instrumented code brings with it some of its own challenges. The JIT is augmenting a bunch of methods to track a lot of additional data; where and how does it track it? And how does it do so safely and correctly when multiple threads are potentially accessing all of this at the same time? For example, one of the things the JIT tracks in an instrumented method is which branches are followed and how frequently; that requires it to count each time code traverses that branch. You can imagine that happens, well, a lot. How can it do the counting in a thread-safe yet efficient way?</p>
<p style=display:none!important>The answer previously was, it didn’t. It used racy, non-synchronized updates to a shared value, e.g. . This means that some updates might get lost in the presence of multithreaded access, but as the answer here only needs to be approximate, that was deemed ok. As it turns out, however, in some cases it was resulting in of lost counts, which in turn caused the JIT to optimize for the wrong things. Another approach tried for comparison purposes in was to use interlocked operations (e.g. if this were C#, ); that results in perfect accuracy, but that explicit synchronization represents a huge potential bottleneck when heavily contended. provides the approach that’s now enabled by default in .NET 8. It’s an implementation of a scalable approximate counter that employs some amount of pseudo-randomness to decide how often to synchronize and by how much to increment the shared count. There’s a of all of this in the repo; here is a C# implementation of the counting logic based on that discussion:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>For current count values less than 8192, it ends up just doing the equivalent of an . However, as the count increases to beyond that threshold, it starts only doing the add randomly half the time, and when it does, it adds 2. Then randomly a quarter of the time it adds 4. Then an eighth of the time it adds 8. And so on. In this way, as more and more increments are performed, it requires writing to the shared counter less and less frequently.</p>
<p style=display:none!important>We can test this out with a little app like the following (if you want to try running it, just copy the above into the program as well):</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>When I run that, I get results like this:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>I find these results fascinating. The interlocked approach gets the exact right count, but it’s super slow, ~20x slower than the other approaches. The fastest is the racy additions one, but its count is also wildly inaccurate: it was off by a factor of 8x! The scalable counters solution was only a hair slower than the racy solution, but its count was only off the expected value by 0.5%. This scalable approach then enables the JIT to track what it needs with the efficiency and approximate accuracy it needs. Other PRs like , , and also went into improving the JIT’s efficiency around tracking this information.</p>
<p style=display:none!important>As it turns out, this isn’t the only use of randomness in dynamic PGO. Another is used as part of determining which types are the most common targets of virtual and interface method calls. At a given call site, the JIT wants to know which type is most commonly used and by what percentage; if there’s a clear winner, it can then generate a fast path specific to that type. As in the previous example, tracking a count for every possible type that might come through is expensive. Instead, it uses an algorithm known as . Let’s say I have a containing ~60% s, ~30% s, and ~10% s, and I want to know which is the most common. With reservoir sampling, I might do so like this:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>When I run this, I get results like the following:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>Note that in the above example, I actually had all the data in advance; in contrast, the JIT likely has multiple threads all running instrumented code and overwriting elements in the reservoir. I also happened to choose the same size reservoir the JIT is using as of , which highlights how that value was chosen for its use case and why it needed to be tweaked.</p>
<p style=display:none!important>On all five runs above, it correctly found there to be more s than s and more s than s, and it was often reasonably close to the actual percentages. But, importantly, randomness is involved here, and every run produced slightly different results. I mention this because that means the JIT compiler now incorporates randomness, which means that the produced dynamic PGO instrumentation data is very likely to be slightly different from run to run. However, even without explicit use of randomness, there’s already non-determinism in such code, and in general there’s enough data produced that the overall behavior is quite stable and repeatable.</p>
<p style=display:none!important>Interestingly, the JIT’s PGO-based optimizations aren’t just based on the data gathered during instrumented tier 0 execution. With (and a handful of follow-on PRs like , , , and ), the JIT will now create a synthetic profile based on statically analyzing the code and estimating a profile, such as with various approaches to static branch prediction. The JIT can then blend this data together with the instrumentation data, helping to fill in data where there are gaps (think “Jurassic Park” and using modern reptile DNA to plug the gaps in the recovered dinosaur DNA).</p>
<p style=display:none!important>Beyond the mechanisms used to enable tiering and dynamic PGO getting better (and, did I mention, being on by default?!) in .NET 8, the optimizations it performs also get better. One of the main optimizations dynamic PGO feeds is the ability to devirtualize virtual and interface calls per call site. As noted, the JIT tracks what concrete types are used, and then can generate a fast path for the most common type; this is known as guarded devirtualization (GDV). Consider this benchmark:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>The method is doing:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>Without PGO, that’s just a normal interface dispatch. With PGO, however, the JIT will end up seeing that the actual type of is most commonly , and it will end up generating tier 1 code closer to if my benchmark was instead:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>It can then in turn see that the method is really simple, and so not only is the call devirtualized, it’s also inlined, such that the code effectively becomes:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>We can confirm this by running the above benchmark. The resulting numbers certainly show something going on:</p>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important>We see it’s both faster (which we expected) and more code (which we also expected). Now for the assembly. On .NET 7, we get this:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>We can see it’s performing the interface call (the three s followed by the ) and then multiplying the result by (). Now on .NET 8, we get this:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>We still see the , but it’s buried in a cold section at the end. Instead, we see the type of the object being compared against , and if it matches (the followed by the ), we store into ; is the hex representation of , so this is the entirety of the inlined body of the devirtualized call. .NET 8 is also capable of doing multiple GDVs, meaning it can generate fast paths for more than 1 type, thanks in large part to and . However, this is off by default and for now needs to be opted-into with a configuration setting (setting the environment variable to the desired maximum number of types for which to test). We can see the impact of that with this benchmark (note that because I’ve explicitly specified the configs to use in the code itself, I’ve omitted the argument in the command):</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important>And in the assembly code with the environment variable set, we can indeed see it doing multiple checks for three types before falling back to the general interface dispatch:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>(Interestingly, this optimization gets a bit better in Native AOT. There, with , there can be no need for the fallback path. The compiler can see the entire program being optimized and can generate fast paths for all of the types that implement the target abstraction if it’s a small number.)</p>
<p style=display:none!important> provides another really nice optimization, still related to GDV, but now for delegates and in relation to loop cloning. Take the following benchmark:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>Dynamic PGO is capable of doing GDV with delegates just as it is with virtual and interface methods. The JIT’s profiling of this method will highlight that the function being invoked is always the same lambda, and as we saw, that can then be transformed into a method something like the following pseudo-code:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>It’s not very visible that inside our loop we’re performing the same check over and over and over. We’re also branching based on it. One common compiler optimization is “hoisting,” where a computation that’s “loop invariant” (meaning it doesn’t change per iteration) can be pulled out of the loop to be above it, e.g.</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>but even with that, we still have the branch on each iteration. Wouldn’t it be nice if we could hoist that as well? What if we could “clone” the loop, duplicating it once for when the method is the known target and once for when it’s not. That’s “loop cloning,” an optimization the JIT is already capable of for other reasons, and now in .NET 8 the JIT is capable of that with this exact scenario, too. The code it’ll produce ends up then being very similar to this:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>Looking at the generated assembly on .NET 8 confirms this:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>Focus just on the block: you can see it ends with a to loop back around to if (which is storing ) is less than 0x2710, or 10,000 decimal, aka our loop’s upper bound. Note that there are just a few instructions in the middle, nothing at all resembling a … this is the optimized cloned loop, where our lambda has been inlined. There’s another loop that alternates between , , and , and that one does have a … that’s the fallback loop. And if we run the benchmark, we see a huge resulting improvement:</p>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important>As long as we’re discussing hoisting, it’s worth noting other improvements have also contributed. In particular, enables the JIT to hoist more code used in generic method dispatch. We can see that in action with a benchmark like this:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important>Before moving on, one word of warning about dynamic PGO: it’s good at what it does, really good. Why is that a “warning?” Dynamic PGO is very good about seeing what your code is doing and optimizing for it, which is awesome when you’re talking about your production applications. But there’s a particular kind of coding where you might not want that to happen, or at least you need to be acutely aware of it happening, and you’re currently looking at it: benchmarks. Microbenchmarks are all about isolating a particular piece of functionality and running that over and over and over and over in order to get good measurements about its overhead. With dynamic PGO, however, the JIT will then optimize for the exact thing you’re testing. If the thing you’re testing is exactly how the code will execute in production, then awesome. But if your test isn’t fully representative, you can get a skewed understanding of the costs involved, which can lead to making less-than-ideal assumptions and decisions.</p>
<p style=display:none!important>For example, consider this benchmark:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>This runs a benchmark with two different “Probability” values. Regardless of that value, the code that’s executed for the benchmark does exactly the same thing and should result in exactly the same assembly code (other than one path checking for the value and the other for ). In a world without PGO, there should be close to zero difference in performance between the runs, and if we set the environment variable to (to disable PGO), that’s exactly what we see, but with PGO, we observe a larger difference:</p>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important>When all of the calls use (because we set the probability to 1, all of the random values are less than that, and we always take the first branch), we see throughput ends up being 25% faster than when half of the calls use and half use . If your benchmark was only trying to measure the overhead of using , you might not realize that the resulting code was being optimized for calling with the same delegate every time, in which case you get different results than if is called with multiple delegates and all with reasonably equal chances of being used. (As an aside, the nice overall improvement between dynamic PGO being disabled and enabled comes in part from the use of , which internally makes a virtual call that can help elide.)</p>
<p style=display:none!important>Throughout the rest of this post, I’ve kept this in mind and tried hard to show benchmarks where the resulting wins are due primarily to the cited improvements in the relevant code; where dynamic PGO plays a larger role in the improvements, I’ve called that out, often showing the results with and without dynamic PGO. There are many more benchmarks I could have shown but have avoided where it would look like a particular method had massive improvements, yet in reality it’d all be due to dynamic PGO being its awesome self rather than some explicit change made to the method’s C# code.</p>
<p style=display:none!important>One final note about dynamic PGO: it’s awesome, but it doesn’t obviate the need for thoughtful coding. If you know and can use something’s concrete type rather than an abstraction, from a performance perspective it’s better to do so rather than hoping the JIT will be able to see through it and devirtualize. To help with this, a new analyzer, , was added to the .NET SDK in . The analyzer looks for places where interfaces or base classes could be replaced by derived types in order to avoid interface and virtual dispatch.
 and rolled this out across . As you can see from the first PR in particular, there were hundreds of places identified that with just an edit of one character (e.g. replacing with ), we could possibly reduce overheads.</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<h2 id=vectorization style=display:none!important>Vectorization</h2>
<p style=display:none!important>Another huge area of investment in code generation in .NET 8 is around vectorization. This is a continuation of a theme that’s been going for multiple .NET releases. Almost a decade ago, .NET gained the type. .NET Core 3.0 and .NET 5 added thousands of intrinsic methods for directly targeting specific hardware instructions. .NET 7 provided hundreds of cross-platform operations for to enable SIMD algorithms on fixed-width vectors. And now in .NET 8, .NET gains support for AVX512, both with new hardware intrinsics directly exposing AVX512 instructions and with the new and types.</p>
<p style=display:none!important>There were a plethora of changes that went into improving existing SIMD support, such as that improves the handling of when it’s not hardware accelerated by lowering it as two operations. Or like , which removed the generic constraint on the in all of the vector types in order to make them easier to use in a larger set of contexts. But the bulk of the work in this area in this release is focused on AVX512.</p>
<p style=display:none!important>Wikipedia has a good overview of , which provides instructions for processing 512-bits at a time. In addition to providing wider versions of the 256-bit instructions seen in previous instruction sets, it also adds a variety of new operations, almost all of which are exposed via one of the new types in , like , , , , and . kicked things off by stubbing out the various files, followed by dozens of PRs that filled in the functionality, for example that added the 512-bit variants of the SSE through SSE4.2 intrinsics that already exist; like from and from that added support for the EVEX encoding used by AVX512 instructions; like from that added the logic for detecting AVX512 support; like from and from that enlightened the register allocator and emitter about AVX512’s additional registers; and like from and from that plumbed through knowledge of various intrinsics.</p>
<p style=display:none!important>Let’s take it for a spin. The machine on which I’m writing this doesn’t have AVX512 support, but my does, so I’m using that for AVX512 comparisons (using with Ubuntu). In last year’s , we wrote a method that used if there was sufficient data available and it was accelerated, or else if there was sufficient data available and it was accelerated, or else a scalar fallback. Tweaking that to also “light up” with AVX512 took me literally less than 30 seconds: copy/paste the code block for and then search and replace in that copy from “Vector256” to “Vector512″… boom, done. Here it is in a benchmark, using environment variables to disable the JIT’s ability to use the various instruction sets so that we can try out this method with each acceleration path:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important>Numerous PRs elsewhere in the JIT then take advantage of AVX512 support when it’s available. For example, separate from AVX512, and taught the JIT how to unroll operations, such that the JIT can emit optimized, vectorized replacements when it can see a constant length for at least one of the inputs. “Unrolling” means that rather than emitting a loop for N iterations, each of which does the loop body once, a loop is emitted for N / M iterations, where every iteration does the loop body M times (and if N == M, there is no loop at all). So for a benchmark like this:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>we now get results like this:</p>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important>For .NET 7, we see assembly code like this (note the instruction to the underlying helper):</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>And now for .NET 8, we get assembly code like this:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>Now there’s no , with the entire implementation provided by the JIT; we can see it making liberal use of the 128-bit SIMD registers. However, those PRs only enabled the JIT to handle up to 64 bytes being compared (unrolling results in larger code, so at some length it no longer makes sense to unroll). With AVX512 support in the JIT, then extends that up to 128 bytes. This is easily visible in a benchmark like this, which is similar to the previous example, but with larger data:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>On my Dev Box with AVX512 support, for .NET 8 we get:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>Now instead of the 128-bit registers, we see use of the 512-bit registers from AVX512.</p>
<p style=display:none!important>The JIT in .NET 8 also now unrolls s (, , etc.) for small-enough constant lengths, thanks to and . And then with that unrolling takes advantage of AVX512 if it’s available. extends this to , too.</p>
<p style=display:none!important> extended the unrolling and vectorization done as part of / and to utilize AVX512 when available, as well.</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important>It’s so fast in .NET 8 because, whereas with .NET 7 it ends up calling through to the underlying helper:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>in .NET 8, the JIT generates code for the operation directly, taking advantage of AVX512’s greater width and thus able to process a larger input without significantly increasing code size:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>Even super simple operations get in on the action. Here we just have a cast from a to a :</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>Thanks to from , the code for that shrinks from this:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>using the AVX instruction, to this:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>using the AVX512 instruction.</p>
<p style=display:none!important>As yet another example, with we see the JIT using AVX512 to accelerate various APIs:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<h2 id=branching style=display:none!important>Branching</h2>
<p style=display:none!important>Branching is integral to all meaningful code; while some algorithms are written in a branch-free manner, branch-free algorithms typically are challenging to get right and complicated to read, and typically are isolated to only small regions of code. For everything else, branching is the name of the game. Loops, if/else blocks, ternaries… it’s hard to imagine any real code without them. Yet they can also represent one of the more significant costs in an application. Modern hardware gets big speed boosts from pipelining, for example from being able to start reading and decoding the next instruction while the previous ones are still processing. That, of course, relies on the hardware knowing what the next instruction is. If there’s no branching, that’s easy, it’s whatever instruction comes next in the sequence. For when there is branching, CPUs have built-in support in the form of branch predictors, used to determine what the next instruction most likely will be, and they’re often right… but when they’re wrong, the cost incurred from that incorrect branch prediction can be huge. Compilers thus strive to minimize branching.</p>
<p style=display:none!important>One way the impact of branches is reduced is by removing them completely. Redundant branch optimizers look for places where the compiler can prove that all paths leading to that branch will lead to the same outcome, such that the compiler can remove the branch and everything in the path not taken. Consider the following example:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>Running that on .NET 7, we can glimpse into the impact of failed branch prediction. When we always take the branch the same way, the throughput is 2.5x what it was when it was impossible for the branch predictor to determine where we were going next:</p>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important>We can also use this example for a .NET 8 improvement. That guarded call has its own branch to ensure that is within the bounds of the span; we can see that very clearly by looking at the disassembly generated on .NET 7:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>In particular, look at :</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>At this point, either or (0x14) has been loaded into , and it’s being compared against , which was loaded from the span’s earlier (). There’s a very obvious redundant branch here, as the code does , and then if it doesn’t jump as part of the , it does the exact same comparison again; the first is the one we wrote in , the second is the one from itself, which got inlined.</p>
<p style=display:none!important>On .NET 8, thanks to and , that branch (and many others of a similar ilk) is optimized away. We can run the exact same benchmark, this time on .NET 8, and if we look at the assembly at the corresponding code block (which isn’t numbered exactly the same because of other changes):</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>we can see that, indeed, the redundant branch has been eliminated.</p>
<p style=display:none!important>Another way the overhead associated with branches (and branch misprediction) is removed is by avoiding them altogether. Sometimes simple bit manipulation tricks can be employed to avoid branches. from , for example, finds expressions like for signed integers and , and rewrites them to the equivalent of .</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>Here instead of code like we’d get on .NET 7, which involves a branch for the :</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>now on .NET 8, the result is branchless:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>Such bit tricks, however, only get you so far. To go further, both x86/64 and Arm provide conditional move instructions, like on x86/64 and on Arm, that encapsulate the condition into the single instruction. For example, “conditionally selects” the value from one of two register arguments based on whether the condition is true or false and writes that value into the destination register. The instruction pipeline stays filled then because the instruction after the is always the next instruction; there’s no control flow that would result in a different instruction coming next.</p>
<p style=display:none!important>The JIT in .NET 8 is now capable of emitting conditional instructions, on both x86/64 and Arm. With PRs like from and from , the JIT gains an additional “if conversion” optimization phase, where various conditional patterns are recognized and morphed into conditional nodes in the JIT’s internal representation; these can then later be emitted as conditional instructions, as was done by , , , , and . Other PRs, like from and from optimized which exact instructions would be employed, in these cases using the Arm and instructions.</p>
<p style=display:none!important>We can see all this in a simple benchmark:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important>Two things to notice:</p>
<ol style=display:none!important>
</ol>
<p style=display:none!important>We can also look at the generated assembly to see the difference. In particular, on .NET 8, we see this for the generated assembly:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>That sequence in there is the comparison between the randomly-generated floating-point value and the probability threshold followed by the conditional move (“conditionally move if below or equal”).</p>
<p style=display:none!important>There are many methods that implicitly benefit from these transformations. Take even a simple method, like , whose code I’ve copied here:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>That pattern should look familiar. Here’s the assembly we get on .NET 7:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>The two arguments come in via the and registers. They’re compared, and if the first argument is greater than or equal to the second, it jumps down to the bottom where the first argument is moved into as the return value; if it wasn’t, then the second value is moved into . And on .NET 8:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>Again the two arguments come in via the and registers, and they’re compared. The second argument is then moved into as the return value. If the comparison showed that the first argument was greater than the second, it’s then moved into (overwriting the second argument that was just moved there). Fun.</p>
<p style=display:none!important>Note if you ever find yourself wanting to do a deeper-dive into this area, BenchmarkDotNet has some excellent additional tools at your disposal. On Windows, it enables you to collect hardware counters, which expose a wealth of information about how things actually executed on the hardware, whether it be number of instructions retired, cache misses, or branch mispredictions. To use it, add another package reference to your .csproj:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>and add an additional attribute to your tests class:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>Then make sure you’re running the benchmarks from an elevated / admin terminal. When I do that, now I see this:</p>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important>We can see it confirms what we already knew: on .NET 7 with a 0.5 probability, it ends up mispredicting a branch.</p>
<p style=display:none!important>The C# compiler (aka “Roslyn”) also gets in on the branch-elimination game in .NET 8, for a very specific kind of branch. In .NET, while we think of as only being a two-value type ( and ), is actually one byte. That means a can technically have 256 different values, where 0 is considered and [1,255] are all considered . Thankfully, unless a developer is poking around the edges of interop or otherwise using code to purposefully manipulate these other values, developers can remain blissfully unaware of the actual numeric value here, for two reasons. First, C# doesn’t consider to be a numerical type, and thus you can’t perform arithmetic on it or cast it to a type like . Second, all of the s produced by the runtime and C# are normalized to actually be 0 or 1 in value, e.g. a IL instruction is documented as “If value1 is greater than value2, 1 is pushed onto the stack; otherwise 0 is pushed onto the stack.” There is a class of algorithms, however, where being able to rely on such 0 and 1 values is handy, and we were just talking about them: branch-free algorithms.</p>
<p style=display:none!important>Let’s say we didn’t have the JIT’s new-found ability to use conditional moves and we wanted to write our own method for integers:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important> we could rely on always being 0 or 1 (we can’t), and we could do arithmetic on a (we can’t), then we could use the behavior of multiplication to implement our function. Anything multiplied by 0 is 0, and anything multiplied by 1 is itself, so we could write our like this:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>Then if is 1, would be and would be 0, such that the whole expression would evaluate to . And, conversely, if is 0, would be 0 and would be , such that the whole expression would evaluate to . As noted, though, we can’t write the above, but we could write this:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>That provides the exact semantics we want… but we’ve introduced two branches into our supposedly branch-free algorithm. This is the IL produced for that in .NET 7:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>Note all those and instructions in there. Are they necessary, though? Earlier I noted that the runtime will only produce s with a value of 0 or 1. And thanks to , the C# compiler now recognizes that and optimizes the pattern to be branchless. Our same function now in .NET 8 compiles to this:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>Zero branch instructions. Of course, you wouldn’t actually want to write this function like this anymore; just because it’s branch-free doesn’t mean it’s the most efficient. On .NET 8, here’s the assembly code produced by the JIT for the above:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>whereas if you just wrote it as:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>here’s what you’d get:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>Even so, this C# compiler optimization is useful for other branch-free algorithms. Let’s say I wanted to write a method that would compare two s, returning -1 if the first is less than the second, 0 if they’re equal, and 1 if the first is greater than the second. I could write that like this:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>Simple, but every invocation will incur at least one branch, if not two. With the optimization, we can instead write it like this:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>This is now branch-free, with the C# compiler producing:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>and, from that, the JIT producing:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>Does that mean that everyone should now be running to rewrite their algorithms in a branch-free manner? Most definitely not. It’s another tool in your tool belt, and in some cases it’s quite beneficial, especially when it can provide more consistent throughput results due to doing the same work regardless of outcome. It’s not always a win, however, and in general it’s best not to try to outsmart the compiler. Take the example we just looked at. There’s a function with that exact implementation in the core libraries: . And if you look at its implementation in .NET 8, you’ll find that it’s still using the branch-based implementation. Why? Because it often yields better results, in particular in the common case where the operation gets inlined and the JIT is able to combine the branches in the method with ones based on processing the result of . Most uses of involve additional branching based on its result, such as in a quick sort partitioning step that’s deciding whether to move elements. So let’s take an example where code makes a decision based on the result of such a comparison:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>And the resulting assembly:
</p>
<p style=display:none!important>Note that both implementations now have just one branch (a in the “branching” case and a in the “branchless” case), the “branching” implementation results in less assembly code.</p>
<h2 id=bounds-checking style=display:none!important>Bounds Checking</h2>
<p style=display:none!important>Arrays, strings, and spans are all bounds checked by the runtime. That means that indexing into one of these data structures incurs validation to ensure that the index is within the bounds of the data structure. For example, the method here:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>results in this code being generated for the method:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>Here, the is passed in , the is in , and the code is comparing the value of the index against the value stored at an 8-byte offset from the beginning of the array: that’s where the array’s length is stored. The instruction (jump if above or equal) is an unsigned comparison, such that if , it’ll jump to , where we see a call to a helper function that will throw an . All of that is the “bounds check.” The actual access into the array is the two and instructions, where the is moved into , and then the value located at (the address of the array) + (the index) + 0x10 (the offset of the start of the data in the array) is moved into the return register.</p>
<p style=display:none!important>It’s the runtime’s responsibility to ensure that all accesses are guaranteed in bounds. It can do so with a bounds check. But it can also do so by proving that the index is always in range, in which case it can elide adding a bounds check that would only add overhead and provide zero benefit. Every .NET release, the JIT improves its ability to recognize patterns that don’t need a bounds check added because there’s no way the access could be out of range. And .NET 8 is no exception, with it learning several new and valuable tricks.</p>
<p style=display:none!important>One such trick comes from , where it learns how to avoid bounds checks in a pattern that’s very prevalent in collections, in particular in hash tables. In a hash table, you generally compute a hash code for a key and then use that key to index into an array (often referred to as “buckets”). As the hash code might be any and the buckets array is invariably going to be much smaller than the full range of a 32-bit integer, all of the hash codes need to be mapped down to an element in the array, and a good way to do that is by mod’ing the hash code by the array’s length, e.g.</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>In .NET 7, that produces:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>Note the , the tell-tale sign of a bounds check. Now in .NET 8, the JIT recognizes that it’s impossible for a value ‘d by an array’s length to be out of bounds of that array; either the array’s is greater than 0, in which case the result of the will always be and , or the is 0, and will throw an exception. As such, it can elide the bounds check:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>Now consider this:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>Our function is checking to see whether the supplied string begins and ends with a quote. It needs to be at least two characters long, and the first and last characters need to be quotes ( is shorthand for and expanded by the C# compiler into the equivalent of ). Here’s the .NET 7 assembly:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>Note that our function is indexing into the string twice, and the assembly does have a at the end of the method, but there’s only one referring to the location of that . That’s because the JIT already knows to avoid the bounds check on the access: it sees that it’s already been verified that the string’s , so it’s safe to index without a bounds check into any index . But, we do still have the bounds check for the . Now in .NET 8, we get this:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>Note the distinct lack of the ; no more bounds checks. Not only did the JIT recognize that is safe because , thanks to it also recognized that since , is and , which means it’s in-bounds and thus no range check is needed.</p>
<h2 id=constant-folding style=display:none!important>Constant Folding</h2>
<p style=display:none!important>Another important operation employed by compilers is constant folding (and the closely related constant propagation). Constant folding is just a fancy name for a compiler evaluating expressions at compile-time, e.g. if you have , rather than emitting a multiplication instruction, it can just do the multiplication at compile-time and substitute . Constant propagation is then the act of taking that new constant and using it anywhere this expression’s result feeds, e.g. if you have:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>a compiler can instead pretend it was:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>I bring this up here, after we just talked about bounds-check elimination, because there are scenarios where constant folding and bounds check elimination go hand-in-hand. If we can determine a data structure’s length at compile-time, and we can determine an index at a compile-time, then also at compile-time we can determine whether the index is in bounds and avoid the bounds check. We can also take it further: if we can determine not only the data structure’s length but also its contents, then we can do the indexing at compile-time and substitute the value from the data structure.</p>
<p style=display:none!important>Consider this example, which is similar in nature to the kind of code types often have in their or implementations:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>We have a method for formatting the value according to the specified . The call site is explicit about the format to use, as many such call sites are, explicitly passing here. The implementation is then special-casing formats that are one-character long and match in an ignore-case manner against one of three known formats (it’s using an ASCII trick based on the values of the lowercase letters being one bit different from their uppercase counterparts, such that ‘ing an uppercase ASCII letter with lowercases it). If we look at the assembly generated for this method in .NET 7, we get this:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>We can see the code here from but this is the code for , so the callee was successfully inlined. We also don’t see any code for the (the first is part of the ), nor do we see any signs of a bounds check (there’s no ). We do, however, see it loading the first character from :</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>and then using the equivalent of a cascading /. Now let’s look at .NET 8:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>Whoa. It not only saw that ‘s was 1 and not only was able to avoid the bounds check, it actually read the first character, lowercased it, and matched it against all the branches, such that the entire operation was constant folded and propagated away, leaving just a call to . That’s primarily thanks to .</p>
<p style=display:none!important>There are a multitude of other such improvements, such as which enables it to constant fold the length of a or stored in a field. Consider:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>On .NET 7, I get the following assembly:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>This is effectively a 1:1 translation of the C#, with not much interesting happening: it loads the string from , and compares its to 1; if it doesn’t match, it returns 0 (false), otherwise it compares the value in the first element of the array against 0xA (line feed) and returns whether they match. Now, .NET 8:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>That’s more interesting. I ran this code on Windows, where is . The JIT has constant folded the entire operation, seeing that the length is not 1, such that the whole operation boils down to just returning false.</p>
<p style=display:none!important>Or consider and which teach the JIT how to actually peer into the contents of an “RVA static.” These are “Relative Virtual Address” static fields, which is a fancy way of saying they live in the assembly’s data section. The C# compiler has optimizations that put constant data into such fields; for example, when you write:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>the C# compiler will actually emil IL like this:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>With these PRs, when indexing into such RVA statics, the JIT is now able to actually read the data at the relevant location, constant folding the operation to the value at that location. So, take the following benchmark:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>The method is implemented via a lookup into such an RVA static, using the passed in as an index into it. If the index ends up being a , now on .NET 8 the whole operation can be constant folded away. .NET 7:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>and .NET 8:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>You get the idea. Of course, a developer hopefully wouldn’t explicitly write , but such code can result none-the-less, especially via inlining.</p>
<p style=display:none!important>There are a multitude of these kinds of improvements in .NET 8. made it so that a value type’s primitive fields can be constant folded as if they were themselves fields, and extended that to strings. taught the JIT how to handle (which is used in methods like ), while taught it to handle (such that if the JIT knows the exact type of an instance , it can replace the invocation with the known answer). However, one of my favorite examples, purely because of just how magical it seems, comes from a series of PRs, including , , , and . Together, they enable this:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>to produce this:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>The JIT was able to successfully inline and constant fold the entire operation down to a single constant. That in that instruction is the value for the field that backs . Sure enough, if you run:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>you’ll see it produces:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>Very cool.</p>
<h2 id=non-gc-heap style=display:none!important>Non-GC Heap</h2>
<p style=display:none!important>Earlier we saw an example of the codegen when loading a constant string. As a reminder, this code:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>results in this assembly on .NET 7:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>There are two instructions here. The first is loading the location where the address to the string object is stored, and the second is reading the address stored at that location (this requires two s because on x64 there’s no addressing mode that supports moving the value stored at an absolute address larger than 32-bits). Even though we’re dealing with a string literal here, such that the data for the string is constant, that constant data still ends up being copied into a heap-allocated object. That object is interned, such that there’s only one of them in the process, but it’s still a heap object, and that means it’s still subject to being moved around by the GC. That means the JIT can’t just bake in the address of the object, since the address can change, hence why it needs to read the address each time, in order to know where it currently is. Or, does it?</p>
<p style=display:none!important>What if we could ensure that the object for this literal is created some place where it would never move, for example on the Pinned Object Heap (POH)? Then the JIT could avoid the indirection and instead just hardcode the address of the , knowing that it would never move. Of course, the POH guarantees objects on it will never , but it doesn’t guarantee addresses to them will always be valid; after all, it doesn’t root the objects, so objects on the POH are still collectible by the GC, and if they were collected, their addresses would be pointing at garbage or other data that ended up reusing the space.</p>
<p style=display:none!important>To address that, .NET 8 introduces a new mechanism used by the JIT for these kinds of situations: the Non-GC Heap (an evolution of the older “Frozen Segments” concept used by Native AOT). The JIT can ensure relevant objects are allocated on the Non-GC Heap, which is, as the name suggests, not managed by the GC and is intended to store objects where the JIT can prove the object has no references the GC needs to be aware of and will be rooted for the lifetime of the process, which in turn implies it can’t be part of an unloadable context.</p>
<p style=display:none!important></p>
<p style=display:none!important>The JIT can then avoid indirections in code generated to access that object, instead just hardcoding the object’s address. That’s exactly what it does now for string literals, as of . Now in .NET 8, that same method above results in this assembly:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important> makes a similar play, but with the objects produced by (subject to various constraints, like the not coming from an unloadable assembly, in which case permanently rooting the object would prevent unloading). Again, we can see this with a simple benchmark:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>where we get the following difference between .NET 7 and .NET 8:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>The same capability can be extended to other kinds of objects, as it is in (which is based on work from ), making cheaper by allocating the empty arrays on the Non-GC Heap.</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>And as of , it also applies to the heap object associated with value type fields, at least those that don’t contain any GC references. Wait, heap object for value type fields? Surely, Stephen, you got that wrong, value types aren’t allocated on the heap when stored in fields. Well, actually they are when they’re stored in fields; the runtime creates a heap-allocated box associated with that field to store the value (but the same box is reused for all writes to that field). And that means for a benchmark like this:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>we see the following assembly code for reading that on .NET 7:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>That code is loading the address of the field, reading from it the address of the box object, and then reading from that box object the value that’s stored inside of it. But, now on .NET 8 we get the assembly you’ve now come to expect:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>The box gets allocated on the Non-GC heap, which means the JIT can bake in the address of the object, and we get to save a .</p>
<p style=display:none!important>Beyond fewer indirections to access these Non-GC Heap objects, there are other benefits. For example, a “generational GC” like the one used in .NET divides the heap into multiple “generations,” where generation 0 (“gen0”) is for recently created objects and generation 2 (“gen2”) is for objects that have been around for a while. When the GC performs a collection, it needs to determine which objects are still alive (still referenced) and which ones can be collected, and to do that it has to trace through all references to find out what objects are still reachable. However, the generational model is beneficial because it can enable the GC to scour through much less of the heap than it might otherwise need to. If it can tell, for example, that there aren’t any references from gen2 back to gen0, then when doing a gen0 collection, it can avoid enumerating gen2 objects entirely. But to be able to know about such references, the GC needs to know any time a reference is written to a shared location. We can see that in this benchmark:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>where the code generated for that method on both .NET 7 and .NET 8 is:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>That is a JIT helper function that contains what’s known as a “GC write barrier,” a little piece of code that runs to let the GC track that a reference is being written that it might need to know about, e.g. because the object being assigned might be gen0 and the destination might be gen2. We see the same thing on .NET 7 for a tweak to the benchmark like this:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>Now we’re storing a string literal into the destination, and on .NET 7 we see assembly similarly calling :</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>But, now on .NET 8 we see this:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>No write barrier. That’s thanks to , which recognizes that these Non-GC Heap objects don’t need to be tracked, since they’ll never be collected anyway. There are multiple other PRs that improve how constant folding works with these Non-GC Heap objects, too, like , , and .</p>
<h2 id=zeroing style=display:none!important>Zeroing</h2>
<p style=display:none!important>The JIT frequently needs to generate code that zeroes out memory. Unless you’ve used , for example, any stack space allocated with needs to be zeroed, and it’s the JIT’s responsibility to generate the code that does so. Consider this benchmark:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>Here’s what the .NET 7 assembly looks like for both and :</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>We can see in the middle there that the JIT has written a zeroing loop, zeroing 16 bytes at a time by pushing two 8-byte s onto the stack on each iteration:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>Now in .NET 8 with , the JIT unrolls and vectorizes that zeroing, and after a certain threshold (which as of has also been updated and made consistent with what other native compilers do), it switches over to using an optimized routine rather than emitting a large amount of code to achieve the same thing. Here’s what we now get on .NET 8 for (on my machine… I call that out because the limits are based on what instruction sets are available):</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>Notice there’s no zeroing loop, and instead we see a bunch of 256-bit move instructions to copy the zeroed out register to the next portion of the stack. And then for we see:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>Again, no zeroing loop, and instead we see , relying on the optimized underlying to efficiently handle the zeroing. The effects of this are visible in throughput numbers as well:</p>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important> improved this further by using a standard trick frequently employed when vectorizing algorithms. Let’s say you want to zero out 120 bytes and you have at your disposal an instruction for zeroing out 32 bytes at a time. We can issue three such instructions to zero out 96 bytes, but we’re then left with 24 bytes that still need to be zeroed. What do we do? We can’t write another 32 bytes from where we left off, as we might then be overwriting 8 bytes we shouldn’t be touching. We could use scalar zeroing and issue three instructions each for 8 bytes, but could we do it in just a single instruction? Yes! Since the writes are idempotent, we can just zero out the last 32 bytes of the 120 bytes, even though that means we’ll be re-zeroing 8 bytes we already zeroed. You can see this same approach utilized in many of the vectorized operations throughout the core libraries, and as of this PR, the JIT employs it when zeroing as well.</p>
<p style=display:none!important> takes this further and uses AVX512 to improve bulk operations like this zeroing. So, running the same benchmark on my Dev Box with AVX512, I see this assembly generated for :</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>Note that now, rather than eight instructions with , we see four instructions with , as each move instruction is able to zero out twice as much, with each instruction handling 64 bytes at a time.</p>
<h2 id=value-types style=display:none!important>Value Types</h2>
<p style=display:none!important>Value types (structs) have been used increasingly as part of high-performance code. Yet while they have obvious advantages (they don’t require heap allocation and thus reduce pressure on the GC), they also have disadvantages (more data being copied around) and have historically not been as optimized as someone relying on them heavily for performance might like. It’s been a key focus area of improvement for the JIT in the last several releases of .NET, and that continues into .NET 8.</p>
<p style=display:none!important>One specific area of improvement here is around “promotion.” In this context, promotion is the idea of splitting a struct apart into its constituent fields, effectively treating each field as its own local. This can lead to a number of valuable optimizations, including being able to enregister portions of a struct. As of .NET 7, the JIT does support struct promotion, but with limitations, including only supporting structs with at most four fields and not supporting nested structs (other than for primitive types).</p>
<p style=display:none!important>A lot of work in .NET 8 went into removing those restrictions. improves upon the existing promotion support with an additional optimization pass the JIT refers to as “physical promotion;” it does away with both of those cited limitations, however as of this PR the feature was still disabled by default. Other PRs like and improved it further, and enabled the optimizations by default. The net result is visible in a benchmark like the following:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>Here we have a struct modeling some data that might be extracted from a file on Linux. The benchmark makes a local copy of the struct and returns a sum of the user and kernel times. In .NET 7, the assembly looks like this:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>The two really interesting instructions here are these:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>The struct is 80 bytes in size, and this pair of instructions is repeatedly () copying 8-bytes () 10 times ( that’s been populated with 0xA) from the source location in (which was initialized with , aka the location of the field) to the destination location in (a stack location at ). In other words, this is making a full copy of the whole struct, even though we only need two fields from it. Now in .NET 8, we get this:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>Ahhh, so much nicer. Now it’s avoided the whole copy, and is simply moving the relevant values into registers and adding them together.</p>
<p style=display:none!important>Here’s another example:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important> has a struct that’s returned from , such that when you the list directly (rather than as an ), the C# compiler binds to this struct enumerator via the enumerator pattern. This example runs afoul of the previous limitations in two ways. That has a field for the current , so if is a non-primitive value type, it violates the “no nested structs” limitation. And that has four fields, so if that has multiple fields, it pushes it beyond the four-field limit. Now in .NET 8, the JIT is able to see through the struct to its fields, and optimize the enumeration of the list to a much more efficient result.</p>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important>Note the significant improvement in both throughput and code size from .NET 7 to .NET 8 even without PGO. However, the gap here between .NET 8 without PGO and with PGO is also interesting, albeit for other reasons. We see an almost halving of execution time with PGO applied, but only four bytes of difference in assembly code size. Those four bytes stem from a single instruction that PGO was able to help remove, which we can see easily by pasting the two snippets into a diffing tool:
~12us down to ~6us is a lot for a difference of a single … why such an outsized impact? This ends up being a really good example of what I mentioned at the beginning of this article: beware microbenchmarks, as they can differ from machine to machine. Or in this case, in particular from processor to processor. The machine on which I’m writing this and on which I’ve run the majority of the benchmarks in this post is a several year old desktop with an Intel Coffee Lake processor. When I run the same benchmark on my Dev Box, which has an Intel Xeon Platinum 8370C, I see this:</p>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important>Same code size, still a large improvement due to physical promotion, but now only a small ~15% rather than ~2x improvement from PGO. As it turns out, Coffee Lake is one of the processors affected by the Jump Conditional Code issued in 2019 (“erratum” here is a fancy way of saying “bug”, or alternatively, “documentation about a bug”). The problem involved jump instructions on a 32-byte boundary, and the hardware caching information about those instructions. The issue was then subsequently fixed via a microcode update that disabled the relevant caching, but that then created a possible performance issue, as whether a jump is on a 32-byte boundary impacts whether it’s cached and therefore the resulting performance gains that cache was introduced to provide. If I set the environment variable to (to get the JIT to output the disassembly directly, rather than relying on BenchmarkDotNet to fish it out), and set the environment variable to (to get the JIT to include alignment boundary information in that output), I see this:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>Sure enough, we see that this jump instruction is falling on a 32-byte boundary. When PGO kicks in and removes the earlier , that changes the alignment such that the jump is no longer on a 32-byte boundary:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>This is all to say, again, there are many things that can impact microbenchmarks, and it’s valuable to understand the source of a difference rather than just taking it at face value.</p>
<p style=display:none!important>Ok, where were we? Oh yeah, structs. Another improvement related to structs comes in , which adds an additional “liveness” optimization pass earlier than the others it already has (liveness is just an indication of whether a variable might still be needed because its value might be used again in the future). This then allows the JIT to remove some struct copies it wasn’t previously able to, in particular in situations where the last time the struct is used is in passing it to another method. However, this additional liveness pass has other benefits as well, in particular with relation to “forward substitution.” Forward substitution is an optimization that can be thought of as the opposite of “common subexpression elimination” (CSE). With CSE, the compiler replaces an expression with something containing the result already computed for that expression, so for example if you had:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>a compiler might use CSE to rewrite that as:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>Forward substitution could be used to undo that, distributing the expression feeding into back to where is used, such that we end up back with:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>Why would a compiler want to do that? It can make certain subsequent optimizations easier for it to see. For example, consider this benchmark:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>On .NET 7, that results in this assembly:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>The generated code here is performing each multiplication individually. But when we view:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>instead as:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>and knowing that the initial result stored into is temporary (thank you, liveness), forward substitution can turn that into:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>at which point constant folding can kick in. Now on .NET 8 we get:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>Another change related to liveness is from . This adds another pass over one of the JIT’s internal representations, eliminating writes it finds to be useless.</p>
<h2 id=casting style=display:none!important>Casting</h2>
<p style=display:none!important>Various improvements have gone into improving the performance of casting in .NET 8.</p>
<p style=display:none!important> improved the performance of using when is sealed. There’s a helper the JIT uses to determine whether an object is of a specified array type, but when the is sealed, the JIT can instead emit it without the helper, generating code as if it were written like . This is another example where dynamic PGO has a measurable impact, so the benchmark highlights the improvements with and without it.</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important>Moving on, consider this benchmark:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important> here is just reading and returning the 0th element from the array. here is returning a to the 0th element from the array. Here’s the assembly we get in .NET 7:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>In , we’re immediately using the array element, so the C# compiler can emit a IL instruction, but in , the reference to the array element is being returned, so the C# compiler emits a (load element address) instruction. In the general case, requires a type check, because of covariance; you could have a , in which case if you handed out a pointing into that array and someone wrote a via that , type safety would be violated (since you’d be storing an into a even though and aren’t related). As such, the .NET 7 assembly for this code includes a call to , which is the helper function the JIT uses to perform that type check. But the array element type here is , which is sealed, which means we can’t get into that problematic situation: there’s no type you can store into a variable other than . Thus, this helper call is superfluous, and with , the JIT can now avoid using it. On .NET 8, then, we get this for :</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>No in sight.</p>
<p style=display:none!important>And then reduces the costs associated with a generic cast. Previously the JIT would always use a method to perform the cast, but with this change, it inlines a fast success path.</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<h2 id=peephole-optimizations style=display:none!important>Peephole Optimizations</h2>
<p style=display:none!important>A “peephole optimization” is one in which a small sequence of instructions is replaced by a different sequence that is expected to perform better. This could include getting rid of instructions deemed unnecessary or replacing two instructions with one instruction that can accomplish the same task. Every release of .NET features a multitude of new peephole optimizations, often inspired by real-world examples where some overhead could be trimmed by slightly increasing code quality, and .NET 8 is no exception. Here are just some of these optimizations in .NET 8:</p>
<ul style=display:none!important>
</ul>
<p style=display:none!important>(I’ve touched here on some of the improvements specific to Arm. For a more in-depth look, see ).</p>
<h2 id=native-aot style=display:none!important>Native AOT</h2>
<p style=display:none!important>Native AOT shipped in .NET 7. It enables .NET programs to be compiled at build time into a self-contained executable or library composed entirely of native code: no JIT is required at execution time to compile anything, and in fact there’s no JIT included with the compiled program. The result is an application that can have a very small on-disk footprint, a small memory footprint, and very fast startup time. In .NET 7, the primary supported workloads were console applications. Now in .NET 8, a lot of work has gone into making ASP.NET applications shine when compiled with Native AOT, as well as driving down overall costs, regardless of app model.</p>
<p style=display:none!important>A significant focus in .NET 8 was on reducing the size of built applications, and the net effect of this is quite easy to see. Let’s start by creating a new Native AOT console app:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>That creates a new directory and adds to it a new “Hello, world” app that targets .NET 7. Edit the generated nativeaotexample.csproj in two ways:</p>
<ol style=display:none!important>
</ol>
<p style=display:none!important>Now, publish the app for .NET 7. I’m currently targeting Linux for x64, so I’m using , but you can follow along on Windows with a Windows identifier, like :</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>That should successfully build the app, producing a standalone executable, and we can / the output directory to see the produced binary size (here I’ve used ):</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>So, on .NET 7 on Linux, this “Hello, world” application, including all necessary library support, the GC, everything, is ~13Mb. Now, we can do the same for .NET 8:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>and again see the generated output size:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>Now on .NET 8, that ~13MB has dropped to ~1.5M! We can get it smaller, too, using various supported configuration flags. First, we can set a size vs speed option introduced in , adding to the .csproj. Then if I don’t need globalization-specific code and data and am ok utilizing an invariant mode, I can add . Maybe I don’t care about having good stack traces if an exception occurs? added the option. Add all of those and republish:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>Sweet.</p>
<p style=display:none!important>A good chunk of those improvements came from a relentless effort that involved hacking away at the size, 10Kb here, 20Kb there. Some examples that drove down these sizes:</p>
<ul style=display:none!important>
</ul>
<p style=display:none!important>You get the idea. The improvements go beyond nipping and tucking here and there within the Native AOT compiler, though. Individual libraries also contributed. For example:</p>
<ul style=display:none!important>
</ul>
<p style=display:none!important>Of course, while size was a large focus for .NET 8, there are a multitude of other ways in which performance with Native AOT has improved. For example, and avoid helper calls as part of reading static fields. BenchmarkDotNet works with Native AOT as well, so we can run the following benchmark to compare; instead of using , we just use (BenchmarkDotNet also currently doesn’t support the with Native AOT):</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>For that, BenchmarkDotNet outputs:</p>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important>including:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>(When looking at the output of optimizations, that warning always brings a smile to my face.)</p>
<p style=display:none!important> is another good example. It improves upon support in Native AOT by ensuring that the comparer can be stored in a to enable better constant folding in consumers.</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important>As another example, avoids some overhead related to static class initialization. As we discussed in the JIT section, the JIT is able to rely on tiering to know that a static field accessed by a method must have already been initialized if the method is being promoted from tier 0 to tier 1, but tiering doesn’t exist in the Native AOT world, so this PR adds a fast-path check to help avoid most of the costs.</p>
<p style=display:none!important>Other fundamental support has also improved. , for example, changes how locks are implemented for Native AOT, employing a hybrid approach that starts with a lightweight spinlock and upgrades to using the type (which is currently internal to Native AOT but likely to ship publicly in .NET 9).</p>
<h2 id=vm style=display:none!important>VM</h2>
<p style=display:none!important>The VM is, loosely speaking, the part of the runtime that’s not the JIT or the GC. It’s what handles things like assembly and type loading. While there were a multitude of improvements throughout, I’ll call out three notable improvements.</p>
<p style=display:none!important>First, optimized the operation of mapping an instruction pointer to a (a data structure that represents a method, with various pieces of information about it, like its signature), which happens in particular any time stack walking is performed (e.g. exception handling, , etc.) and as part of some delegate creations. The change not only makes this conversion faster but also mostly lock-free, which means on a benchmark like the following, there’s a significant improvement for sequential use but an even larger one for multi-threaded use:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important>Second, improves the performance of the . This allocator is responsible for allocation related to all executable memory in the runtime, e.g. the JIT uses it to get memory into which to write the generated code that will then need to be executed. When memory is mapped, it has permissions associated with it for what can be done with that memory, e.g. can it be read and written, can it be executed, etc. The allocator maintains a cache, and this PR improved the performance of the allocator by reducing the number of cache misses incurred and reducing the cost of those cache misses when they do occur.</p>
<p style=display:none!important>Third, makes a variety of changes focused on significantly reducing startup time. This includes reducing the amount of time spent on validation of types in R2R images, making lookups for generic parameters and nested types in R2R images much faster due to dedicated metadata in the R2R image, converting an lookup into an lookup by storing an additional index in a method description, and ensuring that vtable chunks are always shared.</p>
<h2 id=gc style=display:none!important>GC</h2>
<p style=display:none!important>At the beginning of this post, I suggested that be added to the csproj used for running the benchmarks in this post. That setting configures the GC to run in “server” mode, as opposed to “workstation” mode. The workstation mode was designed for use with client applications and is less resource intensive, preferring to use less memory but at the possible expense of throughput and scalability if the system is placed under heavier load. In contrast, the server mode was designed for larger-scale services. It is much more resource hungry, with a dedicated heap by default per logical core in the machine, and a dedicated thread per heap for servicing that heap, but it is also significantly more scalable. This tradeoff often leads to complication, as while applications might demand the scalability of the server GC, they may also want memory consumption closer to that of workstation, at least at times when demand is lower and the service needn’t have so many heaps.</p>
<p style=display:none!important>In .NET 8, the server GC now has support for a dynamic heap count, thanks to ,
, and , which add a feature dubbed “Dynamic Adaptation To Application Sizes”, or DATAS. It’s off-by-default in .NET 8 in general (though on-by-default when publishing for Native AOT), but it can be enabled trivially, either by setting the environment variable to , or via the MSBuild property. The employed algorithm is able to increase and decrease the heap count over time, trying to maximize its view of throughput, and maintaining a balance between that and overall memory footprint.</p>
<p style=display:none!important>Here’s a simple example. I create a console app with in the .csproj and the following code in Program.cs, which just spawns a bunch of threads that continually allocate, and then repeatedly prints out the working set:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>When I run that, I consistently see output like:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>When I then add to the .csproj, the working set drops significantly:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>For a more detailed examination of the feature and plans for it, see .</p>
<h2 id=mono style=display:none!important>Mono</h2>
<p style=display:none!important>Thus far I’ve referred to “the runtime”, “the JIT”, “the GC”, and so on. That’s all in the context of the “CoreCLR” runtime, which is the primary runtime used for console applications, ASP.NET applications, services, desktop applications, and the like. For mobile and browser .NET applications, however, the primary runtime used is the “Mono” runtime. And it also has seen some huge improvements in .NET 8, improvements that accrue to scenarios like Blazor WebAssembly apps.</p>
<p style=display:none!important>Just as how with CoreCLR there’s both the ability to JIT and AOT, there are multiple ways in which code can be shipped for Mono. Mono includes an AOT compiler; for WASM in particular, the AOT compiler enables all of the IL to be compiled to WASM, which is then shipped down to the browser. As with CoreCLR, however, AOT is opt-in. The default experience for WASM is to use an interpreter: the IL is shipped down to the browser, and the interpreter (which itself is compiled to WASM) then interprets the IL. Of course, interpretation has performance implications, and so .NET 7 augmented the interpreter with a tiering scheme similar in concept to the tiering employed by the CoreCLR JIT. The interpreter has its own representation of the code to be interpreted, and the first few times a method is invoked, it just interprets that byte code with little effort put into optimizing it. Then after enough invocations, the interpreter will take some time to optimize that internal representation so as to speed up subsequent interpretations. Even with that, however, it’s still interpreting: it’s still an interpreter implemented in WASM reading instructions for what to do and doing them. One of the most notable improvements to Mono in .NET 8 expands on this tiering by introducing a partial JIT into the interpreter. provided the initial code for this “jiterpreter,” as some folks refer to it. As part of the interpreter, this JIT is able to participate in the same data structures used by the interpreter and process the same byte code, and works by replacing sequences of that byte code with on-the-fly generated WASM. That could be a whole method, it could just be a hot loop within a method, or it could be just a few instructions. This provides significant flexibility, including a very progressive on-ramp where optimizations can be added incrementally, shifting more and more logic from interpretation to jitted WASM. Dozens of PRs went into making the jiterpreter a reality for .NET 8, such as that added basic SIMD support, that added basic loop support, and that added a control-flow optimization pass.</p>
<p style=display:none!important>Let’s see this in action. I created a new .NET 7 Blazor WebAssembly project, added a NuGet reference to the project, and replaced the contents of with the following:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>Then I did the exact same thing, but for .NET 8, built both in Release, and ran them both. When the resulting page opened for each, I clicked the “Click me” button (a few times, but it didn’t change the results).</p>
<p style=display:none!important></p>
<p style=display:none!important>The timing measurements for how long the operation took in .NET 7 compared to .NET 8 speak for themselves.</p>
<p style=display:none!important>Beyond the jiterpreter, the interpreter itself saw a multitude of improvements, for example:</p>
<ul style=display:none!important>
</ul>
<p style=display:none!important>I’ve already alluded several times to vectorization in Mono, but in its own right this has been a big area of focus for Mono in .NET 8, across all backends. As of , which completed adding support for Mono’s AMD64 JIT backend, is now supported across all Mono backends. Mono’s WASM backends not only support , .NET 8 includes the new type, which is specific to WASM and exposes hundreds of overloads that map down to WASM SIMD operations. The basis for this type was introduced in , where the initial SIMD support was added as internal. continued the effort by adding more functionality and also making the type public, as it now is in .NET 8. Over a dozen PRs continued to build it out, such as that added intrinsics, and that added load and store intrinsics, that added floating-point support, and , which overhauled the surface area based on learnings since its initial design.</p>
<p style=display:none!important>Another effort in .NET 8, related to app size, has been around reducing reliance on ICU’s data files (ICU is the globalization library employed by .NET and many other systems). Instead, the goal is to rely on the target platform’s native APIs wherever possible (for WASM, APIs provided by the browser). This effort is referred to as “hybrid globalization,” because the dependence on ICU’s data files still remains, it’s just lessened, and it comes with behavioral changes, so it’s opt-in for situations where someone really wants the smaller size and is willing to deal with the behavioral accommodations. A multitude of PRs have also gone into making this a reality for .NET 8, such as , , and . To enable the feature, you can add to your .csproj, and for more information, there’s a that goes into much more depth.</p>
<h2 id=threading style=display:none!important>Threading</h2>
<p style=display:none!important>Recent releases of .NET saw huge improvements to the area of threading, parallelism, concurrency, and asynchrony, such as a complete rewrite of the (in .NET 6 and .NET 7), a complete rewrite of the async method infrastructure (in .NET Core 2.1), a complete rewrite of (in .NET Core 2.0), and so on. This release doesn’t include such massive overhauls, but it does include some thoughtful and impactful improvements.</p>
<h3 id=threadstatic style=display:none!important>ThreadStatic</h3>
<p style=display:none!important>The .NET runtime makes it easy to associate data with a thread, often referred to as thread-local storage (TLS). The most common way to achieve this is by annotating a static field with the attribute (another for more advanced uses is via the type), which causes the runtime to replicate the storage for that field to be per thread rather than global for the process.</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>Historically, accessing such a field has required a non-inlined JIT helper call (e.g. ), but now with and , the common and fast path from that helper can be inlined into the caller. We can see this with a simple benchmark that just increments an stored in a .</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important> was similarly optimized for Native AOT, via both and :</p>
<div class="table-responsive notranslate" style=display:none!important></div>
<h3 id=threadpool style=display:none!important>ThreadPool</h3>
<p style=display:none!important>Let’s try an experiment. Create a new console app, and add to the .csproj. Then make the entirety of the program this:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>The idea is to see the stack trace of a work item running on a thread. Now run it, and you should see something like this:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>The important piece here is the bottom line: we see we’re being called from the , which is the managed thread pool implementation that’s been used across operating systems since .NET 6. Now, instead of running directly, let’s publish for Native AOT and run the resulting app (for the specific thing we’re looking for, this part should be done on Windows).</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>Now, we see this:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>Again, note the last line: “WindowsThreadPool.” Applications published with Native AOT have historically used a implementation that wraps the . The work item queues and dispatching code is all the same as with the portable pool, but the thread management itself is delegated to the Windows pool. Now in .NET 8 with , projects have the option of using either pool; Native AOT apps can opt to instead use the portable pool, and other apps can opt to instead use the Windows pool. Opting in or out is easy: in a in the .csproj, add to opt-out in a Native AOT app, and conversely use in other apps to opt-in. When using this MSBuild switch, in a Native AOT app, whichever pool isn’t being used can automatically be trimmed away. For experimentation, the environment variable can also be set to or to explicitly opt out or in, respectively.</p>
<p style=display:none!important>There’s currently no hard-and-fast rule about why one pool might be better; the option has been added to allow developers to experiment. We’ve seen with the Windows pool that I/O doesn’t scale as well on larger machines as it does with the portable pool. However, if the Windows thread pool is already being used heavily elsewhere in the application, consolidating into the same pool can reduce oversubscription. Further, if thread pool threads get blocked very frequently, the Windows thread pool has more information about that blocking and can potentially handle those scenarios more efficiently. We can see this with a simple example. Compile this code:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>This is a dastardly repro that creates a bunch of work items, all of which block until all of the work items have been processed: basically it takes every thread the thread pool gives it and never gives it back (until the program exits). When I run this on my machine where is 12, I get output like this:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>The portable pool quickly injects threads, but after that it proceeds to only inject an additional thread once or twice a second. Now, set to and try again:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>Zoom. The Windows pool is more aggressive about injecting threads here. Whether that’s good or bad can depend on your scenario. If you’ve found yourself setting a really high minimum thread pool thread count for your application, you might want to give this option a go.</p>
<h3 id=tasks style=display:none!important>Tasks</h3>
<p style=display:none!important>Even with all the improvements to async/await in previous releases, this release sees async methods get cheaper still, both when they complete synchronously and when they complete asynchronously.</p>
<p style=display:none!important>When an async /-returning method completes synchronously, it tries to give back a cached task object rather than creating one a new and incurring the allocation. In the case of , that’s easy, it can simply use . In the case of , it uses a cache that stores cached tasks for some values. When is , for example, it can successfully cache a for both and , such that it’ll always successfully avoid the allocation. For , it caches a few tasks for common values (e.g. through ). For reference types, it caches a task for . And for the primitive integer types (, , , , , , , , , , and ), it caches a task for 0. It used to be that all of this logic was dedicated to async methods, but in .NET 6 that logic moved into , such that all use of now benefits from this caching. In .NET 8, thanks to and , the caching is improved further. In particular, the optimization of caching a task for for the primitive types is extended to be the caching of a task for for any value type that is 1, 2, 4, 8, or 16 bytes. In such cases, we can do an unsafe cast to one of these primitives, and then use that primitive’s equality to compare against . If that comparison is true, it means the value is entirely zeroed, which means we can use a cached task for created from , as that is also entirely zeroed. What if that type has a custom equality comparer? That actually doesn’t matter, since the original value and the one stored in the cached task have identical bit patterns, which means they’re indistinguishable. The net effect of this is we can cache tasks for other commonly used types.</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important>Those changes helped some async methods to become leaner when they complete synchronously. Other changes have helped practically async methods to become leaner when they complete asynchronously. When an async method suspends for the first time, assuming it’s returning /// and the default async method builders are in use (i.e. they haven’t been overridden using on the method in question), a single allocation occurs: the task object to be returned. That task object is actually a type derived from (in the implementation today the internal type is called ) and that has on it a strongly-typed field for the state machine struct generated by the C# compiler. In fact, as of .NET 7, it has three additional fields beyond what’s on the base :</p>
<ol style=display:none!important>
</ol>
<p style=display:none!important>If we can trim down the fields required, we can make every async method less expensive by allocating smaller instead of larger objects. That’s exactly what and accomplish, together shaving 16 bytes (in a 64-bit process) off the size of such async method task. How?</p>
<p style=display:none!important>The C# language allows anything to be awaitable as long as it follows the right pattern, exposing a method that returns a type with the right shape. That pattern includes a set of “OnCompleted” methods that take an delegate, enabling the async method builder to provide a continuation to the awaiter, such that when the awaited operation completes, it can invoke the to resume the method’s processing. As such, the type has on it a field used to cache an delegate that’s lazily created to point to its method; that is created during the first suspending await where it’s needed and can then be used for all subsequent awaits, such that the is allocated at most once for the lifetime of an async method, regardless of how many times the invocation suspends. (The delegate is only needed, however, if the state machine awaits something that’s not a known awaiter; the runtime has fast paths that avoid requiring that when awaiting all of the built-in awaiters). Interestingly, though, itself has a field for storing a delegate, and that field is only used when the is created to invoke a delegate (e.g. , , etc.). Since most tasks allocated today come from async methods, that means that the majority of tasks have all had a wasted field. It turns out we can just use that base field on the for this cached as well, making the field relevant to almost all tasks, and allowing us to remove the extra field on the state machine box.</p>
<p style=display:none!important>There’s another existing field on the base that also goes unused in async methods: the state object field. When you use a method like or to create a , you can provide an that’s then passed to the ‘s delegate. In an async method, though, the field just sits there, unused, lonely, forgotten, forelorn. Instead of having a separate field for the , then, we can just store the in this existing state field (being careful not to allow it to be exposed via the ‘s property that normally exposes the object state).</p>
<p style=display:none!important>We can see the effect of getting rid of those two fields with a simple benchmark like this:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important>Note the 16-byte decrease just as we predicted.</p>
<p style=display:none!important>Async method overheads are reduced in other ways, too. , for example, shrinks the size of the type that’s used as the workhorse for custom / implementations; it takes advantage of the 99.9% case to use a single field for something that previously required two fields. But my favorite addition in this regard is , which adds new overloads. Yes, I know is a sore subject with some, but these new overloads a) address a really useful scenario that many folks end up writing their own custom awaiters for, b) do it in a way that’s cheaper than custom solutions can provide, and c) actually help with the naming, as it fulfills the original purpose of that led us to name it that in the first place. When was originally devised, we debated many names, and we settled on “ConfigureAwait” because that’s what it was doing: it was allowing you to provide arguments that configured how the await behaved. Of course, for the last decade, the only configuration you’ve been able to do is pass a single to indicate whether to capture the current context / scheduler or not, and that in part has led folks to bemoan the naming as overly verbose for something that’s a single . Now in .NET 8, there are new overloads of that take a enum:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important> you know; that’s the same as today. is something that comes up now and again in various capacities, but essentially you’re awaiting something and rather than continuing synchronously if the thing you’re awaiting has already completed by the time you await it, you effectively want the system to pretend it’s not completed even if it is. Then rather than continuing synchronously, the continuation will always end up running asynchronously from the caller. This can be helpful as an optimization in a variety of ways. Consider this code that was in ‘s HTTP/2 implementation in .NET 7:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>With in .NET 8, the code is now:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>Rather than have a separate , we’ve just piggy-backed on the for the task returned from (which we know will quickly return the task to us), ensuring that the work that comes after it doesn’t run synchronously as part of the call to . Or imagine you had code that was doing:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>This is using to queue an async method’s invocation. That async method results in a Task being allocated, plus the results in a being allocated, plus a work item needs to be queued to the , so at least three allocations. Now, this same functionality can be written as:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>and rather than three allocations, we end up with just one: for the async . That’s because with all the optimizations introduced in previous releases, the state machine box object is also what will be queued to the thread pool.</p>
<p style=display:none!important>Arguably the most valuable addition to this support, though, is . It does what it sounds like: when you a task that completes in failure or cancellation, such that normally the would propagate the exception, it won’t. So, for example, in where we previously had this code:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>now we have this code:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>or in where we had this code:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>now we just have this:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>It is useful to note the cast that’s in there. returns a , but that is being cast to the base because is incompatible with . That’s because, without an exception propagating, the await will complete successfully and return a , which may be invalid if the task actually faulted. So if you have a that you want to await with , cast to the base and await it, and then you can inspect the immediately after the await completes. (If you do end up using with a , the analyzer introduced in will alert you to it.)</p>
<p style=display:none!important>The above example with is using the new to replace a previous optimization added in .NET 8, as well. added to that an implementation of the internal interface, which is the special sauce that enables the async method builders to backchannel with a known awaiter to avoid the delegate allocation. Now that the behaviors this was providing are built-in, it’s no longer needed, and the built-in implementation enjoys the same privileges via . The net result of these changes for is that it now not only has simpler code, but faster code, too. Here’s a benchmark showing the decrease in execution time and allocation associated with calls that need to wait with a and/or timeout:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important>There have been other improvements on other operations on as well. removes a defensive allocation from . It was previously doing a defensive copy such that it could then validate on the copy whether any of the elements were (a copy because another thread could erroneously and concurrently null out elements); that’s a large cost to pay for argument validation in the face of multi-threaded misuse. Instead, the method will still validate whether is in the input, and if a slips through because the input collection was erroneously mutated concurrently with the synchronous call to , it’ll just ignore the at that point. In making these changes, the PR also special-cased a input to avoid making a copy, as is also one of the main types we see fed into (e.g. someone builds up a list of tasks and then waits for all of them).</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important>The generic was also improved as part of , which removes a allocation from an extra continuation that was an implementation detail. This is one of my favorite kinds of PRs: it not only improved performance, it also resulted in cleaner code, and less code.</p>
<p style=display:none!important></p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important>One last example related to tasks, though this one is a bit different, as it’s specifically about improving test performance (and test reliability). Imagine you have a method like this:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>The purpose of this method is to wait for 30 seconds and then log a completion message as well as how much time the method observed to pass. This is obviously a simplification of the kind of functionality you’d find in real applications, but you can extrapolate from it to code you’ve likely written. How do you test this? Maybe you’ve written a test like this:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>This is validating both that the method included a value of at least 30 seconds in its log and also that at least 30 seconds passed. What’s the problem? From a performance perspective, the problem is this test had to wait 30 seconds! That’s a ton of overhead for something which would otherwise complete close to instantaneously. Now imagine the delay was longer, like 10 minutes, or that we had a bunch of tests that all needed to do the same thing. It becomes untenable to test well and thoroughly.</p>
<p style=display:none!important>To address these kinds of situations, many developers have introduced their own abstractions for the flow of time. Now in .NET 8, that’s no longer needed. As of , the core libraries include . This abstract base class abstracts over the flow of time, with members for getting the current UTC time, getting the current local time, getting the current time zone, getting a high-frequency timestamp, and creating a timer (which in turn returns the new that supports changing the timer’s tick interval). Then core library members like and ‘s constructor have new overloads that accept a , and use it for time-related functionality rather than being hardcoded to , , or . With that, we can rewrite our previous method:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>It’s been augmented to accept a parameter, though in a system that uses a dependency injection (DI) mechanism, it would likely just fetch a singleton from DI. Then instead of using or , it uses the corresponding members on the , and instead of using the overload that just takes a duration, it uses the overload that also takes a . When used in production, this can be passed , which is implemented based on the system clock (exactly what you would get without providing a at all), but in a test, it can be passed a custom instance, one that manually controls the observed flow of time. Exactly such a custom exists in the NuGet package: . Here’s an example of using it with our method:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>When I run this, it outputs the following:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>In other words, after manually advancing time by 29 seconds, the operation still hadn’t completed. Then we manually advanced time by one more second, and the operation completed. It reported that 30 seconds passed, but in reality, the whole operation took only 0.01 seconds of actual wall clock time.</p>
<p style=display:none!important>With that, let’s move up the stack to …</p>
<h2 id=parallel style=display:none!important>Parallel</h2>
<p style=display:none!important>.NET 6 introduced new async methods onto in the form of . After its introduction, we started getting requests for an equivalent for loops, so now in .NET 8, with , the class gains a set of methods. These were previously achievable by passing in an created from a method like , e.g.</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>but you can now achieve the same more simply and cheaply with:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>It ends up being cheaper because you don’t need to allocate the enumerable/enumerator, and the synchronization involved in multiple workers trying to peel off the next iteration can be done in a much less expensive manner, a single rather than using an asynchronous lock like .</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important>The allocation column here is particularly stark, and also a tad misleading. Why is much worse here allocation-wise? It’s because of the synchronization mechanism. There’s zero work being performed here by the delegate in the test, so all of the time is spent hammering on the source. In the case of , that’s a single instruction to get the next value. In the case of , it’s a , and under a lot of contention, many of those calls are going to complete asynchronously, resulting in allocation. In a real workload, where the body delegate is doing real work, synchronously or asynchronously, the impact of that synchronization is much, much less dramatic. Here I’ve changed the calls to just be a simple for 1ms (and also significantly lowered the iteration count):</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>and the two methods are the effectively same:</p>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important>Interestingly, this method is also one of the first public methods in the core libraries to be based on the generic math interfaces introduced in .NET 7:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>When initially designing the method, we copied the synchronous counterpart, which has overloads specific to and overloads specific to . Now that we have , however, we realized we could not only reduce the number of overloads and not only reduce the number of implementations, by using we could also open the same method up to other types folks want to use, such as or or ; they all “just work,” which is pretty cool. (The new , added in .NET 8 in by , is another new public type relying on these interfaces.) Once we did that, in we used a similar technique to deduplicate the implementations, such that both and share the same generic implementations internally.</p>
<h2 id=exceptions style=display:none!important>Exceptions</h2>
<p style=display:none!important>In .NET 6, gained a method, as we dipped our toes into the waters of providing “throw helpers.” The intent of the method is to concisely express the constraint being verified, letting the system throw a consistent exception for failure to meet the constraint while also optimizing the success and 99.999% case where no exception need be thrown. The method is structured in such a way that the fast path performing the check gets inlined, with as little work as possible on that path, and then everything else is relegated to a method that performs the actual throwing (the JIT won’t inline that throwing method, as it’ll look at its implementation and see that the method always throws).</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>In .NET 7, gained another overload, this time for pointers, and two new methods were introduced: for s and .</p>
<p style=display:none!important>Now in .NET 8, a slew of new such helpers have been added. Thanks to , gains to complement :</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>and thanks to from and , gains 9 new methods:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>Those PRs used these new methods in a few places, but then , , , , and rolled out their use more broadly throughout the core libraries. To get a sense for the usefulness of these methods, here are the number of times each of these methods is being called from within the for the core libraries in as of the time I’m writing this paragraph:</p>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important>These new methods also do more work in the throwing portion (e.g. formatting the exception message with the invalid arguments), which helps to better exemplify the benfits of moving all of that work out into a separate method. For example, here is the copied straight from :</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>and here is a benchmark showing what consumption would look like if the expression were directly part of :</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important>The most relevant highlight from the generated assembly is from the case:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>Because there’s more cruft inside the method, the system decides not to inline it, and so we end up with two method invocations that occur even when the value is within range (the first is a , the second here is a , since there was no follow-up work in this method that would require control flow returning).</p>
<p style=display:none!important>To make it easier to roll out usage of these helpers, added new analyzers to look for argument validation that can be replaced by one of the throw helper methods on , , , or . enables the analyzers for and fixes up many call sites.
</p>
<h2 id=reflection style=display:none!important>Reflection</h2>
<p style=display:none!important>There have been a variety of improvements here and there in the reflection stack in .NET 8, mostly around reducing allocation or caching information so that subsequent access is faster. For example, tweaks some code in to avoid allocating an array in order to set a property on an attribute.</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important>Other changes like from , from , and from also removed allocations in the reflection stack, in particular by more liberal use of spans. And from improves the handling of generics information on a , leading to a boost for various generics-related members, in particular for for which the result is now cached on the object.</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important>However, the largest impact on performance in reflection in .NET 8 comes from . This is a continuation of work done in .NET 7 to improve the performance of . When you know at compile-time the signature of the target method you want to invoke via reflection, you can achieve the best performance by using to get and cache a delegate for the method in question, and then performing all invocations via that delegate. However, if you don’t know the signature at compile-time, you need to rely on more dynamic means, like , which historically has been much more costly. Some enterprising developers turned to reflection emit to avoid that overhead by emitting custom invocation stubs at run-time, and that’s one of the optimization approaches taken under the covers in .NET 7 as well. Now in .NET 8, the code generated for many of these cases has improved; previously the emitter was always generating code that could accommodate / arguments, but many methods don’t have such arguments, and the generated code can be more efficient when it needn’t factor those in.</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important>However, there’s overhead involved here on each call and that’s repeated on each call. If we could extract that upfront work, do it once, and cache it, we can achieve much better performance. That’s exactly what the new and types implemented in provide. These don’t incorporate all of the obscure corner-cases that handles (like specially recognizing and handling ), but for everything else, it provides a great solution for optimizing the repeated invocation of methods whose signatures are unknown at build time.</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important>As of , these types are then used by the method in to further improve DI service construction performance. improves it further by adding a an additional caching layer that further avoids reflection on each construction.</p>
<h2 id=primitives style=display:none!important>Primitives</h2>
<p style=display:none!important>It’s hard to believe that after two decades we’re still finding opportunity to improve the core primitive types in .NET, yet here we are. Some of this comes from new scenarios that drive optimization into different places; some of it comes from new opportunity based on new support that enables different approaches to the same problem; some of it comes from new research highlighting new ways to approach a problem; and some of it simply comes from many new eyes looking at a well-worn space (yay open source!) Regardless of the reason, there’s a lot to be excited about here in .NET 8.</p>
<h3 id=enums style=display:none!important>Enums</h3>
<p style=display:none!important>Let’s start with . has obviously been around since the earliest days of .NET and is used heavily. Although ‘s functionality and implementation have evolved, and although it’s received new APIs, at its core, how the data is stored has fundamentally remained the same for many years. In the .NET Framework implementation, there’s an internal class that stores a and a , and in .NET 7, there’s an that serves the same purpose. That contains the names of all of the enum’s values, and the stores their numeric counterparts. It’s a to accommodate all possible underlying types an can be, including those supported by C# (, , , , , , , ) and those additionally supported by the runtime (, , , , ) even though effectively no one uses those (partial support used to be on this list as well, but was deleted in .NET 8 in by ).</p>
<p style=display:none!important>As an aside, as part of all of this work, we examined the breadth of appropriately-licensed NuGet packages, looking for what the most common underlying types were in their use of . Out of ~163 million s found, here’s the breakdown of their underlying types. The result is likely not surprising, given the default underlying type for , but it’s still interesting:</p>
<p style=display:none!important></p>
<p style=display:none!important>There are several issues with the cited design for how stores its data. Every operation translates between these values and the actual type being used by the particular , plus the array is often twice as large as it needs to be ( is the default underlying type for an enum and, as seen in the above graph, by the most commonly used). The approach also leads to significant assembly code bloat when dealing with all the new generic methods that have been added to in recent years. s are structs, and when a struct is used as a generic type argument, the JIT specializes the code for that value type (whereas for reference types it emits a single shared implementation used by all of them). That specialization is great for throughput, but it means that you get a copy of the code for every value type it’s used with; if you have a lot of code (e.g. formatting) and a lot of possible types being substituted (e.g. every declared type), that’s a lot of possible increase in code size.</p>
<p style=display:none!important>To address all of this, to modernize the implementation, and to make various operations faster, rewrites . Rather than having a non-generic that stores a array of all values, it introduces a generic that stores a . Then based on the enum’s type, every generic and non-generic method looks up the underlying and invokes a generic method with that but with a generic type parameter for the type, e.g. and both look up the for and invoke the internal . In this way, the implementation stores a strongly-typed value rather than storing the worst case , and all of the implementations across generic and non-generic entrypoints are shared while not having full generic specialization for every : worst case, we end up with one generic specialization per underlying type, of which only the previously cited 8 are expressible in C#. The generic entrypoints are able to do the mapping very efficiently, thanks to from which makes a JIT intrinsic (such that it effectively becomes a const), and the non-generic entrypoints use switches on / as was already being done in a variety of methods.</p>
<p style=display:none!important>Other improvements were made to as well. improves the performance of various methods like and in cases where all of the ‘s defined values are sequential starting from 0. In that common case, the internal function that looks up the value in the can do so with a simple array access, rather than needing to search for the target.</p>
<p style=display:none!important>The net result of all of these changes are some very nice performance improvements:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important>These changes, however, also made s play much more nicely with string interpolation. First, now sports a new static method, which enables formatting an ‘s string representation directly into a :</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>Second, now implements , such that any code written to use a value’s method now lights up with s, too. However, even though enums are value types, they’re special and weird in that they derive from the reference type , and that means calling instance methods like or end up boxing the enum value.</p>
<p style=display:none!important>So, third, the various interpolated string handlers in were updated to special-case , which as noted is now effectively free thanks to JIT optimizations, using directly in order to avoid the boxing. We can see the impact this has by running the following benchmark:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<h2 id=numbers style=display:none!important>Numbers</h2>
<p style=display:none!important>Such formatting improvements weren’t just reserved for s. The performance of number formatting also sees a nice set of improvements in .NET 8. Daniel Lemire has a discussing various approaches to counting the number of digits in an integer. Digit counting is relevant to number formatting as we need to know how many characters the number will be, either to allocate a string of the right length to format into or to ensure that a destination buffer is of a sufficient length. implements this inside of .NET’s number formatting, providing a branch-free, table-based lookup solution for computing the number of digits in a formatted value.</p>
<p style=display:none!important> improves performance further by using a trick . One of the more expensive parts of formatting a decimal is in dividing by 10 to pull off each digit; if we can reduce the number of divisions, we can reduce the overall expense of the formatting operation. The trick here is, rather than dividing by 10 for each digit in the number, we instead divide by 100 for each pair of digits in the number, and then have a precomputed lookup table for the -based representation of all values 0 to 99. This lets us cut the number of divisions in half.</p>
<p style=display:none!important> also expands on a previous optimization already present in .NET. The formatting code contained a table of precomputed strings for single digit numbers, so if you asked for the equivalent of , the implementation wouldn’t need to allocate a new string, it would just fetch from the table and return it. This PR expands that cache from single digit numbers to being all numbers 0 through 299 (it also makes the cache lazy, such that we don’t need to pay for the strings for values that are never used). The choice of 299 is somewhat arbitrary and could be raised in the future if the need presents itself, but in examining data from various services, this addresses a significant chunk of the allocations that come from number formatting. Coincidentally or not, it also includes all success status codes from the HTTP protocol.</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important>Numbers in .NET 8 also gain the ability to format as binary (via , and parse from binary (via ), via the new “b” specifier. For example, this:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>outputs:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>That implementation is then used to reimplement the existing method, such that it’s also now optimized:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important>In a significant addition to the primitive types (numerical and beyond), .NET 8 also sees the introduction of the new interface. was introduced in .NET 6, and with it methods on many types that enable those types to directly format into a :</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>Now in .NET 8, we also have the interface:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>that enables types to directly format into a . These are by design almost identical, the key difference being whether the implementation of these interfaces writes out UTF16 s or UTF8 s. With and , all of the numerical primitives in both implement the new interface and expose a public method. So, for example, exposes these:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>They have the exact same functionality, support the exact same format strings, the same general performance characteristics, and so on, and simply differ in whether writing out UTF16 or UTF8. How can I be so sure they’re so similar? Because, drumroll, they share the same implementation. Thanks to generics, the two methods above delegate to the exact same helper:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>just with one with as and the other as . So, when we run a benchmark like this:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>we get practically identical results like this:</p>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important>And now that the primitive types themselves are able to format with full fidelity as UTF8, the class largely becomes legacy. In fact, the previously mentioned PR also rips out ‘s implementation and just reparents it on top of the same formatting logic from the primitive types. All of the previously cited performance improvements to number formatting then not only accrue to and for UTF16, and not only to for UTF8, but then also to (plus, removing duplicated code and reducing maintenance burden makes me giddy).</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important>Not only is UTF8 formatting directly supported by all these types, so, too, is parsing. added the new interface and implemented it on the primitive numeric types. Just as with its formatting counterpart, this provides identical behavior to , just for UTF8 instead of UTF16. And just as with its formatting counterpart, all of the parsing logic is shared in generic routines between the two modes. In fact, not only does this share logic between UTF16 and UTF8 parsing, it follows closely on the heals of , which uses the same generic tricks to deduplicate the parsing logic across all the primitive types, such that the same generic routines end up being used for all the types and both UTF8 and UTF16. That PR removed almost 2,000 lines of code from :</p>
<p style=display:none!important></p>
<h2 id=datetime style=display:none!important>DateTime</h2>
<p style=display:none!important>Parsing and formatting are improved on other types, as well. Take and . improved a variety of aspects of formatting:</p>
<ul style=display:none!important>
</ul>
<p style=display:none!important>Here’s some of the example impact:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important>Parsing has also improved meaningfully. For example, improves the handling of “ddd” (abbreviated name of the day of the week), “dddd” (full name of the day of the week), “MMM” (abbreviated name of the month), and “MMMM” (full name of the month) in a custom format string; these show up in a variety of commonly used format strings, such as in the expanded definition of the RFC1123 format: . When the general parsing routine encounters these in a format string, it needs to consult the supplied / for that culture’s associated month and day names, e.g. , and then needs to do a linguistic ignore-case comparison for each name against the input text; that’s not particularly cheap. However, if we’re given an invariant culture, we can do the comparison much, much faster. Take “MMM” for abbreviated month name, for example. We can read the next three characters (), ensure they’re all ASCII (), and then combine them all into a single , employing the same ASCII casing trick discussed earlier (). We can do the same thing, precomputed, for each month name, which for the invariant culture we know in advance, and the entire lookup becomes a single numerical :</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>Nifty, and way faster.</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important>A variety of other PRs contributed as well. The decreased allocation in the previous benchmark is thanks to , which removed a string allocation that might occur when the format string contained quotes; the PR simply replaced the string allocation with use of spans. further reduced the cost of parsing with the “r” and “o” formats by removing some work that ended up being unnecessary, removing a virtual dispatch, and general streamlining of the code paths. And removed some allocations that occured in when parsing with some cultures, in particular those that employ genitive month names. If the parser needed to retrieve the or arrays, it would do so via the public properties for these on ; however, out of concern that code could mutate those arrays, these public properties hand back copies. That means that the parser was allocating a copy every time it accessed one of these. The parser can instead access the underlying original array, and pinky swear not to change it.</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important> and also implement , thanks to , and as with the numerical types, the implementations are all shared between UTF16 and UTF8; thus all of the optimizations previously mentioned accrue to both. And again, ‘s support for formatting is just reparented on top of this same shared logic.</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important>Since we’re talking about , a brief foray into . gets a object for the specified identifier. One of the is that supports both the Windows time zone set as well as the IANA time zone set, regardless of whether running on Windows or Linux or macOS. However, the was only being cached when its ID matched that for the current OS, and as such calls that resolved to the other set weren’t being fulfilled by the cache and were falling back to re-reading from the OS. ensures a cache can be used in both cases. It also allows returning the immutable objects directly, rather than cloning them on every access. also improves , in particular on Linux and macOS, by lazily loading several of the properties. then improves on that with a new overload of that allows the caller to skip the sort the implementation would otherwise perform on the result.</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important>Back to formatting and parsing…</p>
<h2 id=guid style=display:none!important>Guid</h2>
<p style=display:none!important>Formatting and parsing improvements go beyond the numerical and date types. also gets in on the game. Thanks to , implements , and as with all the other cases, it shares the exact same routines between UTF16 and UTF8 support. Then , , and from vectorize that formatting support.</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important>Before moving on from primitives and numerics, let’s take a quick look at , which has methods for producing pseudo-random numerical values.</p>
<h2 id=random style=display:none!important>Random</h2>
<p style=display:none!important> from provides an implementation in based on ‘s . When a method like is invoked, it needs to provide a value in the range . In order to provide an unbiased answer, the .NET 7 implementation generates a 32-bit value, narrows down the range to the smallest power of 2 that contains the max (by taking the log2 of the max and shifting to throw away bits), and then checks whether the result is less than the max: if it is, it returns the result as the answer. But if it’s not, it rejects the value (a process referred to as “rejection sampling”) and loops around to start the whole process over. While the cost to produce each sample in the current approach isn’t terrible, the nature of the approach makes it reasonably likely the sample will need to be rejected, which means looping and retries. With the new approach, it effectively implements modulo reduction (e.g. ), except replacing the expensive modulo operation with a cheaper multiplication and shift; then a rejection sampling loop is still employed, but the bias it corrects for happens much more rarely and thus the more expensive path happens much more rarely. The net result is a nice boost on average to the throughput of ‘s methods ( can also get a boost from dynamic PGO, as the internal abstraction uses can be devirtualized, so I’ve shown here the impact with and without PGO enabled.)</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important> from then further improves this for values. The core part of the algorithm involves multiplying the random value by the max value and then taking the low part of the product:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>This can be made more efficient by not using ‘s multiplication implementation and instead using ,</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>which is implemented to use the or intrinsics when one is available.</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important>Finally, I’ll mention . is both a commonly-used type in its own right and also an abstraction; many of the APIs on are virtual, such that a derived type can be implemented to completely swap out the algorithm employed. So, for example, if you wanted to implement a that derived from and completely replaced the base algorithm by overriding every virtual method, you could do so, pass your instance around as , and everyone’s happy… unless you’re creating your derived type frequently and care about allocation. actually includes multiple pseudo-random generators. .NET 6 imbued it with an implementation of the / algorithms, which are used when you just do . However, if you instead instantiate a derived type, the implementation falls back to the same algorithm (a variant of Knuth’s subtractive random number generator algorithm) it’s used since the dawn of , as it doesn’t know what the derived type will be doing nor what dependencies it may have taken on the nature of the algorithm employed. That algorithm carries with it a 56-element , which means that derived classes end up instantiating and initializing that array even if they never use it. With this PR, the creation of that array is made lazy, such that it’s only initialized if and when it’s used. With that, a derived implementation that wants to avoid that cost can.</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<h2 id=strings-arrays-and-spans style=display:none!important>Strings, Arrays, and Spans</h2>
<p style=display:none!important>.NET 8 sees a tremendous amount of improvement in the realm of data processing, in particular in the efficient manipulation of strings, arrays, and spans. Since we’ve just been talking about UTF8 and , let’s start there.</p>
<h3 id=utf8 style=display:none!important>UTF8</h3>
<p style=display:none!important>As noted, is now implemented on a bunch of types. I noted all the numerical primitives, , and , and with the type also implements it, as do and the new types, thanks to . However, .NET 8 doesn’t just provide implementations of this interface on all of these types, it also consumes the interface in a key place.</p>
<p style=display:none!important>If you’ll recall, was completely overhauled. This included not only making string interpolation much more efficient, but also in providing a pattern that a type could implement to allow for the string interpolation syntax to be used efficiently to do things other than create a new string. For example, a new extension method for was added that makes it possible to format an interpolated string directly into a destination buffer:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>The above gets translated (“lowered”) by the compiler into the equivalent of the following:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>The implementation of that generic call examines the and tries to do the most optimal thing. In this case, it’ll see that implements , and it’ll end up using its to format directly into the destination span.</p>
<p style=display:none!important>That’s for UTF16. Now with , we have the opportunity to do the same thing but for UTF8. And that’s exactly what does. It introduces the new method, which behaves exactly like the aforementioned , except writing as UTF8 into a destination instead of as UTF16 into a destination . The implementation also special-cases , using its to write directly into the destination buffer.</p>
<p style=display:none!important>With that, we can write the equivalent to the method we wrote earlier:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>and that gets lowered as you’d now expect:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>So, identical, other than the parts you expect to change. But that’s also a problem in some ways. Take a look at that call. In the UTF16 case where we’re dealing with a destination , the implementation of simply needs to copy that string into the destination; not only that, but the JIT will inline the call, see that a string literal is being copied, and will unroll the copy, making it super efficient. But in the UTF8 case, we can’t just copy the UTF16 string s into the destination UTF8 buffer; we need to UTF8 encode the string. And while we can certainly do that ( and make that trivial with the addition of a new method), it’s frustratingly inefficient to need to spend cycles repeatedly at run-time doing work that could be done at compile time. After all, we’re dealing with a string literal known at JIT time; it’d be really, really nice if the JIT could do the UTF8 encoding and then do an unrolled copy just as it’s already doing in the UTF16 case. And with and , that’s exactly what happens, such that performance is effectively the same between them.</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<h2 id=ascii style=display:none!important>ASCII</h2>
<p style=display:none!important>UTF8 is the predominent encoding for text on the internet and for the movement of text between endpoints. However, much of this data is actually the ASCII subset, the 128 values in the range . When you know the data you’re working with is ASCII, you can achieve even better performance by using routines optimized for the subset. The new class in .NET 8, introduced in and , and then further optimized in from ,
 from , , and , provides this:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>Note that it provides overloads that operate on UTF16 () and UTF8 (), and in many cases, intermixes them, such that you can, for example, compare a UTF8 with a UTF16 , or transcode a UTF16 to a UTF8 (which, when working with ASCII, is purely a narrowing operation, getting rid of the leading 0 in each ). For example, the PR that added these methods also used them in a variety of places (something I advocate for strongly, in order to ensure what has been designed is actually meeting the need, or ensure that other core library code is benefiting from the new APIs, which in turn makes those APIs more valuable, as their benefits accrue to more indirect consumers), including in multiple places in . Previously, had its own helpers for this purpose, an example of which I’ve copied here into this benchmark:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important>Many of these new APIs also got the treatment, such that they light up when AVX512 is supported by the current machine, thanks to from and from .</p>
<h2 id=base64 style=display:none!important>Base64</h2>
<p style=display:none!important>An even further constrained subset of text is Base64-encoded data. This is used when arbitrary bytes need to be transferred as text, and results in text that uses only 64 characters (lowercase ASCII letters, uppercase ASCII letters, ASCII digits, ‘+’, and ‘/’). .NET has long had methods on for encoding and decoding Base64 with UTF16 (), and it got an additional set of span-based methods in .NET Core 2.1 with the introduction of . At that point, the class was also introduced, with dedicated surface area for encoding and decoding with UTF8 (). That’s now improved further in .NET 8.</p>
<p style=display:none!important> from and make two contributions here. First, they bring the behavior of the methods for UTF8 in line with its counterparts on the class, in particular around handling of whitespace. As it’s very common for there to be newlines in Base64-encoded data, the class’ methods for decoding permitted whitespace; in contrast, the class’ methods for decoding would fail if whitespace was encountered. These decoding methods now permit exactly the same whitespace that does. And that’s important in part because of the second contribution from these PRs, which is a new set of static methods. As with and , these methods simply state whether the supplied UTF8 or UTF16 input represents a valid input, such that the decoding methods on both and could successfully decode it. And as with all such processing we see introduced into .NET, we’ve strived to make the new functionality as efficient as possible so that it can be used to maximal benefit elsewhere. For example, from updated the new to use it, and updated to use it. Here we can see a benchmark comparing the old non-vectorized with the new version using the vectorized :</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<h2 id=hex style=display:none!important>Hex</h2>
<p style=display:none!important>Another relevant subset of ASCII is hexadecimal, and improvements have been made in .NET 8 around conversions between bytes and their representation in hex. In particular, vectorized the method using an algorithm . On even a moderate length input, this has a very measurable impact on throughput:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important>Of course, the improvements in .NET 8 go well beyond just the manipulation of certain known sets of characters; there is a wealth of other improvements to explore. Let’s start with , which was introduced in .</p>
<h2 id=string-formatting style=display:none!important>String Formatting</h2>
<p style=display:none!important>Since the beginning of .NET, and friends have provided APIs for handling composite format strings, strings with text interspersed with format item placeholders, e.g. . These strings can then be passed to various APIs, like , which are provided with both the composite format string and the arguments that should be substituted in for the placeholders, e.g. will return a string like (the in the placeholder indicates the 0-based number of the argument to substitute, and the is the format that should be used, in this case the ). Such a method invocation needs to parse the composite format string each time it’s called, even though for a given call site the composite format string typically doesn’t change from invocation to invocation. These APIs are also generally non-generic, which means if an argument is a value type (as is in my example), it’ll incur a boxing allocation. To simplify the syntax around these operations, C# 6 gained support for string interpolation, such that instead of writing , you could instead write , and it was then up to the compiler to achieve the same behavior as if had been used (which the compiler typically achieved simply by lowering the interpolation into a call to ).</p>
<p style=display:none!important>In .NET 6 and C# 10, string interpolation was , both in terms of the scenarios supported and in terms of its efficiency. One key aspect of the efficiency is it enabled the parsing to be performed once (at compile-time). It also enabled avoiding all of the allocation associated with providing arguments. These improvements contributed to all use of string interpolation and a significant portion of the use of in real-world applications and services. However, the compiler support works by being able to see the string at compile time. What if the format string isn’t known until run-time, such as if it’s pulled from a resource file or some other source of configuration? At that point, remains the answer.</p>
<p style=display:none!important>Now in .NET 8, there’s a new answer available: . Just as an interpolated string allows the compiler to do the heavy lifting once in order to optimize repeated use, allows that reusable work to be done once in order to optimize repeated use. As it does the parsing at run-time, it’s able to tackle the remaining cases that string interpolation can’t reach. To create an instance, one simply calls its method, which takes a composite format string, parses it, and returns a instance:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>Then, existing methods like now have new overloads, exactly the same as the existing ones, but instead of taking a , they take a . The same formatting as was done earlier can then instead be done like this:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>This overload (and other new overloads of methods like and ) accepts generic arguments, avoiding the boxing.</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important>If you know the composite format string at compile time, interpolated strings are the answer. Otherwise, can give you throughput in the same ballpark at the expense of some startup costs. Formatting with a is actually implemented with the same interpolated string handlers that are used for string interpolation, e.g. ends up calling into methods on to do the actual formatting work.</p>
<p style=display:none!important>There’s also a new analyzer to help with this. CA1863 “Use ‘CompositeFormat'” was introduced in to identify and calls that could possibly benefit from switching to use a argument instead.
</p>
<h2 id=spans style=display:none!important>Spans</h2>
<p style=display:none!important>Moving on from formatting, let’s turn our attention to all the other kinds of operations one frequently wants to perform on sequences of data, whether that be arrays, strings, or the unifying force of spans. A home for many routines for manipulating all of these, via spans, is the type, which has received a multitude of new APIs in .NET 8.</p>
<p style=display:none!important>One very common operation is to count how many of something there are. For example, in support of multiline comments, needs to count how many line feed characters there are in a given piece of JSON. This is, of course, trivial to write as a loop, whether character-by-character or using and slicing. Now in .NET 8, you can also just call the extension method, thanks to from and from . Here we’re counting the number of line feed characters in from Project Gutenberg:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important>The core of the implementation here that enables to be so fast, in particular when searching for a single value, is based on just two key primitives: and . Here’s the loop that forms the bulk of the implementation (the implementation has similar loops for and as well):</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>This is creating a vector where every element of the vector is the target (in this case, ). Then, as long as there’s at least one vector’s worth of data remaining, it loads the next vector () and compares that with the target vector (). That produces a new where each element is all ones when the values are equal and all zeros when they’re not. We then extract out the most significant bit of each element (), so getting a bit with the value where the values were equal, otherwise . And then we use on the resulting to get the “population count,” i.e. the number of bits that are , and we add that to our running tally. In this way, the inner loop of the count operation remains branch-free, and the implementation can churn through the data very quickly. You can find several examples of using in , which used it in several places in the core libraries.</p>
<p style=display:none!important>A similar new method is , which comes in .NET 8 in two shapes. from added an in-place variant:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>and added a copying variant:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>As an example of where this comes in handy, has some code paths that need to normalize directory separators to be , such that any characters need to be replaced. This previously used an loop as was shown in the previous benchmark, and now it can just use . Here’s a comparison (which, purely for benchmarking purposes, is normalizing back and forth so that each time the benchmark runs it finds things in the original state):</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important>The new does better than both the manual loop and the loop. As with , has a fairly simple and tight inner loop; again, here’s the variant of that loop:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>This is loading the next vector’s worth of data () and comparing that with a vector filled with the , which produces a new vector with s for equality and for inequality. It then calls the super handy . This is a branchless SIMD condition operation: it produces a new vector that has an element from one vector if mask’s bits were s and from another vector if the mask’s bits were s (think a ternary operator). That resulting vector is then saved out as the result. In this manner, it’s overwriting the whole span, in some cases just writing back the value that was previously there, and in cases where the original value was the target , writing out the instead. This loop body is branch-free and doesn’t change in cost based on how many elements need to be replaced. In an extreme case where there’s nothing to be replaced, an -based loop could end up being a tad bit faster, since the body of ‘s inner loop has even fewer instructions, but such an loop pays a relatively high cost for every replacement that needs to be done.</p>
<p style=display:none!important> also had such an -based implementation for its and methods, and they’re now based on , so the improvements accrue there as well.</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important>Interestingly, whereas was using and switched to use , wasn’t using at all, a gap that’s been fixed in . when dealing with strings is more complicated in because of its segmented nature. isn’t just backed by an array: it’s actually a linked list of segments, each of which stores an array. With the -based , it can simply operate on each segment individually, but for the -based , it needs to deal with the possibility that the value being searched for crosses a segment boundary. was thus walking each segment character-by-character, doing an equality check at each position. Now with this PR, it’s using and only falling back to a character-by-character check when close enough to a segment boundary that it might be crossed.</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important>As long as we’re on the subject of , it saw some other nice improvements in .NET 8. from tweaked both and the JIT to enable the JIT to unroll the memory copies that occur as part of appending a constant string.</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important>And from changed to use instead of manually looping, taking advantage of the optimized implementation, even for reasonably small counts.</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important>Back to , another new helpful method is (and ). This is a span-based counterpart to for uses of . I say “some” because there are effectively two main patterns for using : when you expect a certain number of parts, and when there are an unknown number of parts. For example, if you want to parse a version string as would be used by , there are at most four parts (“major.minor.build.revision”). But if you want to split, say, the contents of a file into all of the lines in the file (delimited by a ), that’s an unknown (and potentially quite large) number of parts. The new method is focused on the situations where there’s a known (and reasonably small) maximum number of parts expected. In such a case, it can be significantly more efficient than , especially from an allocation perspective.</p>
<p style=display:none!important> has overloads that accept an , and behaves identically to these overloads; however, rather than giving it an , you give it a whose length is the same value you would have used for . For example, let’s say you want to split a key/value pair separated by an . If this were , you could write that as:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>Of course, if the input was actually erroneous for what you were expecting and there were 100 equal signs, you’d end up creating an array of 101 strings. So instead, you might write that as:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>Wait, “3”? Aren’t there only two parts, and if so, why not pass “2”? Because of the behavior of what happens with the last part. The last part contains the remainder of the string after the separator before it, so for example the call:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>produces the array:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>If you want to know whether there were more than two parts, you need to request at least one more, and then if that last one was produced, you know the input was erroneous. For example, this:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>produces this:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>and this:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>produces this:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>We can do the same thing with the new overload, except a) the caller provides the destination span to write the results into, and b) the results are stored as a rather than as a . That means that the whole operation is allocation-free. And thanks to the indexer on that lets you pass in a and slice the span, you can easily use the written ranges to access the relevant portions of the input.</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>Here’s an example from , which used to reduce the cost of :</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important>More examples of and being used are in and . Both of those remove allocations from various types that were previously using .</p>
<p style=display:none!important> also includes a new set of methods for ranges, thanks to :</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>Want to find the index of the next ASCII digit? No problem:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>Want to determine whether some input contains any non-ASCII or control characters? You got it:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>For example, uses to quickly determine whether portions of a might contain a bidirectional control character, searching for anything in the range , and then only examining further if anything in that range is found. And uses to determine whether to use or . It was previously implemented with a simple loop, and it’s now implemented with an even simpler call to :</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important>More of a productivity thing than performance (at least today), but .NET 8 also includes new methods () that allow writing these kind of calls that are then compared against 0 in a slightly cleaner fashion, e.g. the previous example could have been simplified slightly to:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>One of the things I love about these kinds of helpers is that code can simplify down to use them, and then as the helpers improve, so too does the code that relies on them. And in .NET 8, there’s a lot of “the helpers improve.”</p>
<p style=display:none!important> from added support for to most of these span-based helpers in . That means that when running on hardware which supports AVX512, many of these operations simply get faster. This benchmark uses environment variables to explicitly disable support for the various instruction sets, such that we can compare performance of a given operation when nothing is vectorized, when is used and hardware accelerated, when is used and hardware accelerated, and when is used and hardware accelerated. I’ve run this on my Dev Box that does support AVX512:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important>So, not a halving going from 128-bit to 256-bit or another halving going from 256-bit to 512-bit, but pretty close.</p>
<p style=display:none!important> vectorized for large enough inputs (the same underlying implementation is used for both and ). In a loop, it loads the next two vectors. It then checks to see whether anything in those vectors is non-ASCII; it can do so efficiently by OR’ing them together () and then seeing whether the high bit of any of the elements is set… if none are, then all the elements in both of the input vectors are ASCII (). If it finds anything non-ASCII, it just continues on with the old mode of comparison. But as long as everything is ASCII, then it can proceed to do the comparison in a vectorized manner. For each vector, it uses some bit hackery to create a lowercased version of the vector, and then compares the lowercased versions for equality.</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important> uses the same tricks to vectorize and :</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important> from also streamlined :</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important> improves the internal method that’s used by the vast majority of . If you look in the source for , you’ll find a fairly common pattern: special-case , , , and with a vectorized implementation, and then fall back to a general non-vectorized implementation for everything else. Except it’s not exactly “special-case , , , and “, but rather “special-case bitwise-equatable types that are the same size as , , , or .” If something is “bitwise equatable,” that means we don’t need to worry about any implementation it might provide or any override it might have, and we can instead simply rely on the value’s bits being the same or different from another value to identify whether the values are the same or different. And if such bitwise equality semantics apply for a type, then the intrinsics that determine equality for , , , and can be used for any type that’s 1, 2, 4, or 8 bytes, respectively. In .NET 7, would be true only for a finite and hardcoded list in the runtime: , , , , , , , , , , , , , and s. Now in .NET 8, that list is extended to a dynamically discoverable set where the runtime can easily see that the type itself doesn’t provide any equality implementation.</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important>Note this not only means the result gets vectorized, it also ends up avoiding excessive boxing (hence all that allocation), as it’s no longer calling on each value type instance.</p>
<p style=display:none!important> improved the vectorization of . Imagine we’re searching some text for the word “elementary.” In .NET 7, it would end up doing an in order to find the first possible place “elementary” could match, and would then do the equivalent of a . If the fails, then it loops around to search for the next possible starting location. This is ok if the the characters being searched for are rare, but in this example, is the most common letter in the English alphabet, and so an is frequently stopping, breaking out of the vectorized inner loop, in order to do the full comparison. In contrast to this, in .NET 7 was improved using the algorithm ; the idea there is that rather than just searching for one character (e.g. the first), you have a vector for another character as well (e.g. the last), you offset them appropriately, and you AND their comparison results together as part of the inner loop. Even if is very common, and then a nine characters later is much, much less common, and thus it can stay in its tight inner loop for longer. Now in .NET 8, we apply the same trick to when we can find two ASCII characters in the input, e.g. it’ll simultaneously search for or followed by a or ‘ nine characters later.</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important>Even just a simple is also significantly improved in .NET 8. Here I’m searching “The Adventures of Sherlock Holmes” for an , which I happen to know doesn’t appear, such that the entire search will be spent in ‘s tight inner loop.</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important>That improvement is thanks to . The goal of SIMD and vectorization is to do more with the same; rather than processing one thing at a time, process 2 or 4 or 8 or 16 or 32 or 64 things at a time. For s, which are 16 bits in size, in a 128-bit vector you can process 8 of them at a time; double that for 256-bit, and double it again for 512-bit. But it’s not just about the size of the vector; you can also find creative ways to use a vector to process more than you otherwise could. For example, in a 128-bit vector, you can process 8 s at a time… but you can process 16 s at a time. What if you could process the s instead as s? You could of course reinterpret the 8 s as 16 s, but for most algorithms you’d end up with the wrong answer (since each of the would be treated independently). What if instead you could condense two vectors’ worth of s down to a single vector of , and then do the subsequent processing on that single vector of ? Then as long as you were doing a few instructions-worth of processing on the vector and the cost of that condensing was cheap enough, you could approach doubling your algorithm’s performance. And that’s exactly what this PR does, at least for very common needles, and on hardware that supports SSE2. SSE2 has dedicated instructions for taking two vectors and narrowing them down to a single vector, e.g. take a and a , and combine them into a by taking the low from each in the input. However, these particular instructions don’t simply ignore the other in each completely; instead, they “saturate.” That means if casting the value to a would overflow, it produces 255, and if it would underflow, it produces 0. That means we can take two vectors of 16-bit values, pack them into a single vector of 8-bit values, and then as long as the thing we’re searching for is in the range [1, 254], we can be sure that equality checks against the vector will be accurate (comparisons against 0 or 255 might lead to false positives). Note that while Arm does have support for similar “narrowing with saturation,” the cost of those particular instructions was measured to be high enough that it wasn’t feasible to use them here (they are used elsewhere). This improvement applies to several other -based methods as well, including and .</p>
<p style=display:none!important>One last -centric improvement to highlight. The and types don’t implement , but the method does exist to enable getting an enumerable from them. It’s buried away in primarily so as to guide developers not to iterate through the directly, but to instead iterate through its , e.g.</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>The driving force behind this is that the property has some overhead, as a can be backed by multiple different object types (namely a , a if it’s a , or a ), and needs to fetch a for the right one. Even so, from time to time you do actually need an from a , and provides that. In such situations, it’s actually beneficial from a performance perspective that one doesn’t just pass the as an , since doing so would box the value, and then enumerating that enumerable would require a second allocation for the . In contrast, can return an instance that is both the and the . In fact, that’s what it’s done since it was added, with the entirety of the implementation being:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>The C# compiler generates an for such an iterator that does in fact also implement and return itself from to avoid an extra allocation, so that’s good. As noted, though, has some overhead, and this is accessing once per element… not ideal. addresses this in multiple ways. First, itself can check the type of the underlying object behind the , and for a or a can return a different iterator that just directly indexes into the array or string rather than going through on every access. Moreover, can check to see whether the bounds represented by the are for the full length of the array or string… if they are, then can just return the original object, without any additional allocation. The net result is a much more efficient enumeration scheme for anything other than a , which is much more rare (but also not negatively impacted by the improvements for the other types).</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<h2 id=searchvalues style=display:none!important>SearchValues</h2>
<p style=display:none!important>As should be obvious from the length of this document, there are a sheer ton of performance-focused improvements in .NET 8. As I previously noted, I think the most valuable addition in .NET 8 is enabling dynamic PGO by default. After that, I think the next most exciting addition is the new type. It is simply awesome, in my humble opinion.</p>
<p style=display:none!important>Functionally, doesn’t do anything you couldn’t already do. For example, let’s say you wanted to search for the next ASCII letter or digit in text. You can already do that via :</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>And that works, but it hasn’t been particularly fast. In .NET 7, is optimized for searching for up to 5 target characters, e.g. it could efficiently vectorize a search for English vowels (). But with a target set of 62 characters like in the previous example, it would no longer vectorize, and instead of trying to see how many characters it could process per instruction, switches to trying to see how few instructions it can employ per character (meaning we’re no longer talking about fractions of an instruction per character in the haystack and now talking about multiple instructions per character in the haystack). It does this via a , referred to in the implementation as a “probabilistic map.” The idea is to maintain a bitmap of 256 bits. For every needle character, it sets 2 bits in that bitmap. Then when searching the haystack, for each character it looks to see whether both bits are set in the bitmap; if at least one isn’t set, then this character can’t be in the needle and the search can continue, but if both bits are in the bitmap, then it’s likely but not confirmed that the haystack character is in the needle, and the needle is then searched for the character to see whether we’ve found a match.</p>
<p style=display:none!important>There are actually known algorithms for doing these searches more efficiently. For example, the is a great choice when searching for an arbitrary set of ASCII characters, enabling us to efficiently vectorize a search for a needle composed of any subset of ASCII. Doing so requires some amount of computation to analyze the needle and build up the relevant bitmaps and vectors that are required for performing the search, just as we have to do so for the Bloom filter (albeit generating different artifacts). implements these techniques in . Rather than always building up a probabilistic map, it first examines the needle to see if all of the values are ASCII, and if they are, then it switches over to this optimized ASCII-based search; if they’re not, it falls back to the same probabilistic map approach used previously. The PR also recognizes that it’s only worth attempting either optimization under the right conditions; if the haystack is really short, for example, we’re better off just doing the naive search, where for every character in the haystack we search through the needle to see if the is a target.</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important>Even with those improvements, this work of building up these vectors is quite repetitive, and it’s not free. If you have such an in a loop, you’re paying to build up those vectors over and over and over again. There’s also additional work we could do to further examine the data to choose an even more optimal approach, but every additional check performed comes at the cost of more overhead for the call. This is where comes in. The idea behind is to perform all this work once and then cache it. Almost invariably, the pattern for using a is to create one, store it in a field, and then use that for all searching operations for that target set. And there are now overloads of methods like that take a or , for example, instead of a or , respectively. Thus, my previous ASCII letter or digit example would instead look like this:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important> provided the initial implementation of (it was originally named , but we renamed it subsequently to the more general so that we can use it now and in the future with other methods, like or ). If you peruse the implementation, you’ll see that the factory methods don’t just return a concrete type; rather, provides an internal abstraction that’s then implemented by more than fifteen derived implementations, each specialized for a different scenario. You can see this fairly easily in code by running the following program:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>and you’ll see output like the following:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>highlighting that each of these different inputs ends up getting mapped to a different -derived type.</p>
<p style=display:none!important>After that initial PR, has been successively improved and refined. , for example, added AVX2 support, such that with 256-bit vectors being employed (when available) instead of 128-bit vectors, some benchmarks close to doubled in throughput, and enabled WASM support. added a method to be used when implementing scalar fallback paths. And reduced the overhead of calling with a simply by tweaking how the relevant bitmaps and vectors are internally passed around. But two of my favorite tweaks are and , which improve overheads when ‘\0’ (null) is one of the characters in the needle. Why would this matter? Surely searching for ‘\0’ can’t be so common? Interestingly, in a variety of scenarios it can be. Imagine you have an algorithm that’s really good at searching for any subset of ASCII, but you want to use it to search for either a specific subset of ASCII something non-ASCII. If you just search for the subset, you won’t learn about non-ASCII hits. And if you search for everything other than the subset, you’ll learn about non-ASCII hits but also all the wrong ASCII characters. Instead what you want to do is invert the ASCII subset, e.g. if your target characters are ‘A’ through ‘Z’ and ‘a’ through ‘z’, you instead create the subset including ‘\u0000’ through ‘\u0040’, ‘\u005B’ through ‘\u0060’, and ‘\u007B’ through ‘\u007F’. Then, rather than doing an with that inverted subset, you instead do with that inverted subset; this is a true case of “two wrongs make a right,” as we’ll end up with our desired behavior of searching for the original subset of ASCII letter plus anything non-ASCII. And as you’ll note, ‘\0’ is in our inverted subset, making the performance when ‘\0’ is in there more important than it otherwise would be.</p>
<p style=display:none!important>Interestingly, the probabilistic map code path in .NET 8 actually also enjoys some amount of vectorization, even without , thanks to (it was also further improved in that used better instructions on Arm, and in that avoided some wasted work). That means that whether or not is used, searches involving probabilistic map get much faster than in .NET 7. For example, here’s a benchmark that again searches “The Adventures of Sherlock Holmes” and counts the number of line endings in it, using the same needle that uses:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important> can then be used to improve upon that. It does so not only by caching the probabilistic map that each call to above needs to recompute, but also by recognizing that when a needle contains ASCII, that’s a good indication (heuristically) that ASCII haystacks will be prominent. As such, adds a fast path that performs a search for either any of the ASCII needle values or any non-ASCII value, and if it finds a non-ASCII value, then it falls back to performing the vectorized probabilistic map search. </p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important> further augments that heuristic by guarding that ASCII fast path behind a quick check to see if the very next character is non-ASCII, skipping the ASCII-based search if it is and thereby avoiding the overhead when dealing with an all non-ASCII input. For example, here’s the result of running the previous benchmark, with the exact same code, except changing the URL to be , which is an almost entirely Greek document containing Aristotle’s “The Constitution of the Athenians”:</p>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important>With all of that goodness imbued in , it’s now being used extensively throughout . For example, previously had its own dedicated implementation of a function that it used to search for any character with an ordinal value less than 32, or a quote, or a backslash. That implementation in .NET 7 was . Now in .NET 8 thanks to , it’s simply this:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>Such use was rolled out in a bunch of PRs, for example that used in ,
 in , in , in , in and ,
 in ,
 in , and in . and in are particularly nice, including optimizing the commonly-used helper with ; this shows up as a sizable improvement, especially when there’s nothing to escape.</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important>All in all, just in , is now used in more than 40 places, and that’s not including all the uses that get generated as part of (more on that in a bit). This is helped along by , which adds a new analyzer that will flag opportunities for and update the code to use it:
</p>
<p style=display:none!important>Throughout this discussion, I’ve mentioned several times, using it as an example of the kind of thing that wants to efficiently search for multiple characters. After and , it now also uses , plus has been enhanced with other optimizations. Given the discussion of , it’ll be obvious how it’s employed here, at least the basics of it. Previously, relied on an internal helper which did this:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>Now, it does:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>where that is just:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>Straightforward. However, it takes things a bit further. Note that there are 6 characters in that list, some of which are ASCII, some of which aren’t. Knowing the algorithms currently employs, we know that this will knock it off the
path of just doing an ASCII search, and it’ll instead use the algorithm that does a search for one of the 3 ASCII characters plus anything non-ASCII, and if it finds anything non-ASCII, will then fallback to doing the probabilistic map search. If we could remove just one of those characters, we’d be back into the range of just being able to use the implementation that can work with any 5 characters. On non-Windows systems, we’re in luck. by default replaces a line ending with ; on Windows, that’s , but on Linux and macOS, that’s . If the replacement text is (which can also be opted-into on Windows by using the overload), then searching for only to replace it with is a nop, which means we can remove from the search list when the replacement text is , bringing us down to only 5 target characters, and giving us a little edge. And while that’s a nice little gain, the bigger gain is that we won’t end up breaking out of the vectorized loop as frequently, or at all if all of the line endings are the replacement text. Further, the .NET 7 implementation was always creating a new string to return, but we can avoid allocating it if we didn’t actually replace anything with anything new. The net result of all of this are huge improvements to , some due to and some beyond.</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important>The changes also accrue to the span-based non-allocating :</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<h2 id=regex style=display:none!important>Regex</h2>
<p style=display:none!important>Having just examined , it’s a good time to talk about , as the former now plays an integral role in the latter. was significantly improved in , and then again was overhauled for , which saw the introduction of the regex source generator. Now in .NET 8, continues to receive significant investment, in particular this release in taking advantage of much of the work already discussed that was introduced lower in the stack to enable more efficient searching.</p>
<p style=display:none!important>As a reminder, there are effectively three different “engines” within , meaning effectively three different components for actually processing a regex. The simplest engine is the “interpreter”; the constructor translates the regular expression into a series of which the then evaluates against the incoming text. This is done in a “scan” loop, which (simplified) looks like this:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important> tries to move through as much of the input text as possible until it finds a position in the input that could feasibly start a match, and then evaluates the pattern at that position against the input. That evaluation in the interpreter involves a loop like this, processing the opcodes that were produced from the pattern:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>Then there’s the non-backtracking engine, which is what you get when you select the option introduced in .NET 7. This engine shares the same implementation as the interpreter, such that all of the optimizations involved in skipping through as much text as possible (ideally via vectorized operations) accrue to both the interpreter and the non-backtracking engine. However, that’s where the similarities end. Rather than processing regex opcodes, the non-backtracking engine works by converting the regular expression pattern into a lazily-constructed deterministic finite automata (DFA) or non-deterministic finite automata (NFA), which it then uses to evaluate the input text. The key benefit of the non-backtracking engine is that it provides linear-time execution guarantees in the length of the input. For a lot more detail, please read .</p>
<p style=display:none!important>The third engine actually comes in two forms: and the regex source generator (introduced in .NET 7). Except for a few corner-cases, these are effectively the same as each other in terms of how they work. They both generate custom code specific to the input pattern provided, with the former generating IL at run-time and the latter generating C# (which is then compiled to IL by the C# compiler) at build-time. The structure of the resulting code, and 99% of the optimizations applied, are identical between them; in fact, in .NET 7, the was completely rewritten to be a block-by-block translation of the C# code the regex source generator emits. For both, the actual emitted code is fully customized to the exact pattern supplied, with both trying to generate code that processes the regex as efficiently as possible, and with the source generator trying to do so by generating code that is as close as possible to what an expert .NET developer might write. That’s in large part because the source it generates is visible, even in Visual Studio live as you edit your pattern:
</p>
<p style=display:none!important>I mention all of this because there is ample opportunity throughout , both in the used by the interpreter and non-backtracking engines and throughout the code generated by and the regex source generator, to use APIs introduced to make searching faster. I’m looking at you, and friends.</p>
<p style=display:none!important>As noted earlier, new variants have been introduced in .NET 8 for searching for ranges, and as of , will now take full advantage of them in generated code. For example, consider , which might be used to search for a zip code in the United States. The regex source generator in .NET 7 would emit code for that contained this:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>Now in .NET 8, that same attribute instead generates this:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>That .NET 7 implementation is examining one character at a time, whereas the .NET 8 code is vectorizing the search via , examining multiple characters at a time. This can lead to significant speedups.</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important>The generated code can use these APIs in other places as well, even as part of validating the match itself. Let’s say your pattern was instead , which is going to look for and capture a sequence of at least three word characters that is then followed by an ASCII digit. This is a standard greedy loop, so it’s going to consume as many word characters as it can (which includes ASCII digits), and will then backtrack, giving back some of the word characters consumed, until it can find a digit. Previously, that was implemented just by giving back a single character, seeing if it was a digit, giving back a single character, seeing if it was a digit, and so on. Now? The source generator emits code that includes this:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>In other words, it’s using to optimize that backwards search for the next viable backtracking location.</p>
<p style=display:none!important>Another significant improvement that builds on improvements lower in the stack is . As was previously covered, the vectorization of has been improved in .NET 8. Previously, wasn’t utilizing this API, as it was often able to do better with its own custom-generated code. But now that the API has been optimized, this PR changes to use it, making the generated code both simpler and faster. Here I’m searching case-insensitively for the whole word “year”:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important>In addition to learning how to use the existing and the new and , in .NET 8 also learns how to use the new . This is a big boost for , as it now means that it can vectorize searches for many more sets than it previously could. For example, let’s say you wanted to search for all hex numbers. You might use a pattern like . If you plug that into the regex source generator in .NET 7, you’ll get a emitted that contains code like this:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>Now in .NET 8, thanks in large part to , you’ll instead get code like this:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>What is that ? It’s a emitted into the file’s class:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>The source generator explicitly recognized this set and so created a nice name for it, but that’s purely about readability; it can still use even if it doesn’t recognize the set as something that’s well-known and easily nameable. For example, if I instead augment the set to be all valid hex digits and an underscore, I then instead get this:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>When initially added to , was only used when the input set was all ASCII. But as improved over the development of .NET 8, so too did ‘s use of it. With , now relies on ‘s ability to efficiently search for both ASCII and non-ASCII, and will similarly emit a if it’s able to efficiently enumerate the contents of a set and that set contains a reasonably small number of characters (today, that means no more than 128). Interestingly, ‘s optimization to first do a search for the ASCII subset of a target and then fallback to a vectorized probabilistic map search was first prototyped in (), after which we decided to push the optimization downwards into so that could generate simpler code and so that other non- consumers would benefit.</p>
<p style=display:none!important>That still, however, leaves the cases where we can’t efficiently enumerate the set in order to determine every character it includes, nor would we want to pass a gigantic number of characters off to . Consider the set , i.e. “word characters.” Of the 65,536 values, 50,409 match the set . It would be inefficient to enumerate all of those characters in order to try to create a for them, and doesn’t try. Instead, as of , employs a similar approach as noted above, but with a scalar fallback. For example, for the pattern , it emits the following helper into :</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>The fact that it named the helper “IndexOfAnyWordChar” is, again, separate from the fact that it was able to generate this helper; it simply recognizes the set here as part of determining a name and was able to come up with a nicer one, but if it didn’t recognize it, the body of the method would be the same and the name would just be less readable, as it would come up with something fairly gibberish but unique.</p>
<p style=display:none!important>As an interesting aside, I noted that the source generator and are effectively the same, just with one generating C# and one generating IL. That’s 99% correct. There is one interesting difference around their use of , though, one which makes the source generator a bit more efficient in how it’s able to utilize the type. Any time the source generator needs a instance for a new combination of characters, it can just emit another field for that instance, and because it’s , the JIT’s optimizations around devirtualization and inlining can kick in, with calls to use this seeing the actual type of the instance and optimizing based on that. Yay. is a different story. emits IL for a given , and it does so using ; this provides the lightest-weight solution to reflection emit, also allowing the generated methods to be garbage collected when they’re no longer referenced. s, however, are just that, methods. There’s no support for creating additional static fields on demand, without growing up into the much more expensive -based solution. How then can create and store an arbitrary number of instances, and how can it do so in a way that similarly enables devirtualization? It employs a few tricks. First, a field was added to the internal type that stores the delegate to the generated method: As an array, this enables any number of to be stored; the emitted IL can access the field, grab the array, and index into it to grab the relevant instance. Just doing that, of course, would not allow for devirtualization, and even dynamic PGO doesn’t help here because currently s don’t participate in tiering; compilation goes straight to tier 1, so there’d be no opportunity for instrumentation to see the actual -derived type employed. Thankfully, there are available solutions. The JIT can learn about the type of an instance from the type of a local in which it’s stored, so one solution is to create a local of the concrete and sealed derived type (we’re writing IL at this point, so we can do things like that without actually having access to the type in question), read the from the array, store it into the local, and then use the local for the subsequent access. And, in fact, we did that for a while during the .NET 8 development process. However, that does require a local, and requires an extra read/write of that local. Instead, a tweak in allows the JIT to use the in to learn about the actual type of , and so can just use to inform the JIT as to the actual type of the instance such that it’s then devirtualized. The code uses then to emit the IL to load a is this:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>We can see all of this in action with a benchmark like this:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>Here we’re searching the same Sherlock Holmes text for the names of some of the most common characters in the detective stories. The regex pattern analyzer will try to find something for which it can vectorize a search, and it will look at all of the characters that can validly exist at each position in a match, e.g. all matches begin with ‘H’, ‘W’, ‘L’, ‘M’, ‘A’, or ‘G’. And since the shortest match is five letters (“Adler”), it’ll end up looking at the first five positions, coming up with these sets:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>All of those sets have more than five characters in them, though, an important delineation as in .NET 7 that is the largest number of characters for which will vectorize a search. Thus, in .NET 7, ends up emitting code that walks the input checking character by character (though it does match the set using a fast branch-free bitmap mechanism):</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>Now in .NET 8, with we efficiently search for any of these sets, and the implementation ends up picking the one it thinks is statistically least likely to match:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>where that is defined as:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>This leads the overall searching process to be much more efficient.</p>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important>Other PRs like , , and have also contributed to how and friends are used, tweaking the various heuristics involved. But there have been improvements to as well outside of this realm.
, for example, streamlines the matching performance of when matching against non-ASCII characters by using a bit-twiddling trick. And changes the underlying type of an internal enum from to , and in doing so ends up shrinking the size of the object containing a value of this enum by 8 bytes (in a 64-bit process). More impactful is , which makes a measurable improvement for . was maintaining a list of segments to be composed back into the final string; some segments would come from the original , while some would be the replacement . As it turns out, though, the string reference contained in that is unnecessary. We can instead just maintain a list of , where every time we add a segment we add to the list the and the , and with the nature of replace, we can simply rely on the fact that we’ll need to insert the replacement text between every pair of values.</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important>One last improvement in to highlight isn’t actually due to anything in , but actually in a primitive uses on every operation: . Consider this benchmark:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>This is purely measuring the overhead of calling into a instance; the matching routine will complete immediately as the pattern matches any input. Since we’re only talking about tens of nanoseconds, your numbers may vary here, but I routinely get results like this:</p>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important>That several nanosecond improvement is primarily due to , which made and for reference types into intrinsics, special-casing when the JIT can see that the new value to be written is . These APIs need to employ a GC write barrier as part of writing the object reference into the shared location, for the same reasons previously discussed earlier in this post, but when writing , no such barrier is required. This benefits , which uses as part of renting a to use to actually process the match. Each instance caches a runner object, and every operation tries to rent and return it… that renting is done with :</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>Many object pool implementations employ a similar use of and will similarly benefit.</p>
<h2 id=hashing style=display:none!important>Hashing</h2>
<p style=display:none!important>The library was introduced in .NET 6 to provide implementations; initially, it shipped with four types: , , , and . In .NET 8, it gets significant investment, in adding new optimized algorithms, in improving the performance of existing implementations, and in adding new surface area across all of the algorithms.</p>
<p style=display:none!important>The xxHash family of hash algorithms has become quite popular of late due to its high performance on both large and small inputs and its overall level of quality (e.g. how few collisions are produced, how well inputs are dispersed, etc.) previously included implementations of the older XXH32 and XXH64 algorithms (as and , respectively). Now in .NET 8, thanks to , it includes the XXH3 algorithm (as ), and thanks to from , it includes the XXH128 algorithm (as ). The algorithm was also further optimized in from by amortizing the costs of some loads and stores, and in from , which improved throughput on Arm by making better use of the hardware intrinsics.</p>
<p style=display:none!important>To see overall performance of these hash functions, here’s a microbenchmark comparing the throughput of the cryptographic SHA256 with each of these non-cryptographic hash functions. I’ve also included an implementation of FNV-1a, which is the hash algorithm that may be used by the C# compiler for statements (when it needs to over a string, for example, and it can’t come up with a better scheme, it hashes the input, and then does a binary search through the pregenerated hashes for each of the cases), as well as an implementation based on (noting that is different from the rest of these, in that it’s focused on enabling the hashing of arbitrary .NET types, and includes per-process randomization, whereas a goal of these other hash functions is to be 100% deterministic across process boundaries).</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important>A key reason and do so much better than and is that their design is focused on being vectorizable. As such, the .NET implementations employ the support in to take full advantage of the underlying hardware. This data also hints at why the C# compiler uses FNV-1a: it’s really simple and also really low overhead for small inputs, which are the most common form of input used in statements, but it would be a poor choice if you expected primarily longer inputs.</p>
<p style=display:none!important>You’ll note that in the previous example, and both end up in the same ballpark as in terms of throughput (XXH3 generally ranks better than CRC32/64 in terms of quality). CRC32 in that comparison benefits significantly from from , from , and from . These vectorize the and implementations, based on a decade-old paper from Intel titled “Fast CRC Computation for Generic Polynomials Using PCLMULQDQ Instruction.” The cited instruction is part of SSE2, however the PR is also able to vectorize on Arm by taking advantage of Arm’s instruction. The net result is huge gains over .NET 7, in particular for larger inputs being hashed.</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important>Another change also further improves performance of some of these algorithms, but with a primary purpose of actually making them easier to use in a variety of scenarios. The original design of was focused on creating non-cryptographic alternatives to the existing cryptographic algorithms folks were using, and thus the APIs are all focused on writing out the resulting digests, which are opaque bytes, e.g. CRC32 produces a 4-byte hash. However, especially for these non-cryptographic algorithms, many developers are more familiar with getting back a numerical result, e.g. CRC32 produces an . Same data, just a different representation. Interestingly, as well, some of these algorithms operate in terms of such integers, so getting back bytes actually requires a separate step, both ensuring some kind of storage location is available in which to write the resulting bytes and then extracting the result to that location. To address all of this, adds to all of the types in new utility methods for producing such numbers. For example, has two new methods added to it:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>If you just want the -based CRC32 hash for some input bytes, you can simply call this one-shot static method . Or if you’re building up the hash incrementally, having created an instance of the type and having appended data to it, you can get the current hash via . This also shaves off a few instructions for an algorithm like which actually needs to do more work to produce the result as bytes, only to then need to get those bytes back as a :</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important>Also on the hashing front, from adds new methods that allow for iterative crc32c hash computation. A nice aspect of crc32c is that multiple platforms provide instructions for this operation, including SSE 4.2 and Arm, and the .NET method will employ whatever hardware support is available, by delegating into the relevant hardware intrinsics in , e.g.</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>We can see the impact those intrinsics have by comparing a manual implementation of the crc32c algorithm against the now built-in implementation:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<h2 id=initialization style=display:none!important>Initialization</h2>
<p style=display:none!important>Several releases ago, the C# compiler added a valuable optimization that’s now heavily employed throughout the core libraries, and that newer C# constructs (like ) rely on heavily. It’s quite common to want to store and access sequences or tables of data in code. For example, let’s say I want to quickly look up how many days there are in a month in the Gregorian calendar, based on that month’s 0-based index. I can use a lookup table like this (ignoring leap years for explanatory purposes):</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>Of course, now I’m allocating a , so I should move that out to a field. Even then, though, that array has to be allocated, and the data loaded into it, incurring some startup overhead the first time it’s used. Instead, I can write it as:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>While this looks like it’s allocating, it’s actually not. The C# compiler recognizes that all of the data being used to initialize the is constant and that the array is being stored directly into a , which doesn’t provide any means for extracting the array back out. As such, the compiler instead lowers this into code that effectively does this (we can’t exactly express in C# the IL that gets generated, so this is pseudo-code):</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>It blits the data for the array into the assembly, and then constructing the span isn’t via an array allocation, but rather just wrapping the span around a pointer directly into the assembly’s data. This not only avoids the startup overhead and the extra object on the heap, it also better enables various JIT optimizations, especially when the JIT is able to see what offset is being accessed. If I run this benchmark:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>it produces this assembly:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>In other words, for the array, it’s reading the address of the array and is then reading the element at offset 0x10, or decimal 16, which is where the array’s data begins. For the span, it’s simply loading the value 0x1F, or decimal 31, as it’s directly reading the data from the assembly data. (This isn’t a case of a missing optimization in the JIT for the array example… arrays are mutable, so the JIT can’t constant fold based on the current value stored in the array, since technically it could change.)</p>
<p style=display:none!important>However, this compiler optimization only applied to , , and . Any other primitive, and the compiler would simply do exactly what you asked it to do: allocate the array. Far from ideal. The reason for the limitation was endianness. The compiler needs to generate binaries that work on both little-endian and big-endian systems; for single-byte types, there’s no endianness concern (since endianness is about the ordering of the bytes, and if there’s only one byte, there’s only one ordering), but for multi-byte types, the generated code could no longer just point directly into the data, as on some systems the data’s bytes would be reversed.</p>
<p style=display:none!important>.NET 7 added a new API to help with this, . Rather than just emitting , the idea was that the compiler would emit a call to , passing in a reference to the field containing the data. The JIT and VM would then collude to ensure the data was loaded correctly and efficiently; on a little-endian system, the code would be emitted as if the call weren’t there (replaced by the equivalent of wrapping a span around the pointer and length), and on a big-endian system, the data would be loaded, reversed, and cached into an array, and the code gen would then be creating a span wrapping that array. Unfortunately, although the API shipped in .NET 7, the compiler support for it didn’t, and because no one was then actually using it, there were a variety of issues in the toolchain that went unnoticed.</p>
<p style=display:none!important>Thankfully, all of these issues are now addressed in .NET 8 and the C# compiler (and also backported to .NET 7). added support to the C# compiler for also supporting , , , , , , , , , and s based on these. On target frameworks where is available (.NET 7+), the compiler generates code that uses it. On frameworks where the function isn’t available, the compiler falls back to emitting a array to cache the data and wrapping a span around that. This was an important consideration for libraries that build for multiple target frameworks, so that when building “downlevel”, the implementation doesn’t fall off the proverbial performance cliff due to relying on this optimization (this optimization is a bit of an oddity, as you actually need to write your code in a way that, without the optimization, ends up performing worse than what you would have otherwise had). With the compiler implementation in place, and fixes to the Mono runtime in and , and with fixes to the trimmer (which needs to preserve the alignment of the data that’s emitted by the compiler) in , the rest of the runtime was then able to consume the feature, which it did in . So now, for example, can use this to store not only how many days there are in a (non-leap) year, but also store how many days there are before a given month, something that wasn’t previously possible efficiently in this form due to there being values larger than can be stored in a .</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important> (which hasn’t yet merged but should soon) then rounds things out by ensuring that the pattern of initializing a to a will always avoid the array allocation, regardless of the type of being used. The need only be expressible as a constant in C#. That means this optimization now also applies to , , , and . For these, the compiler will fallback to using a cached array singleton. With that, this code:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>now compiles down to something like this (again, this is pseudo-code, since we can’t exactly represent in C# what’s emitted in IL):</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>Another closely-related C# compiler improvement comes in from . The previously mentioned optimization around single-byte types also applies to initialization. If I write:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>the C# compiler emits code similar to if I’d written the following:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>If, however, I switch from the multi-byte to the single-byte :</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>then I get something closer to this:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>Unlike the the case, however, which optimized not only for , , and but also for s with and as an underlying type, the optimization didn’t. Thanks to this PR, it now does.</p>
<p style=display:none!important>There’s another semi-related new feature spanning C# 12 and .NET 8: . has long provided a way to use stack space as a buffer, rather than needing to allocate memory on the heap; however, for most of .NET’s history, this was “unsafe,” in that it produced a pointer:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>C# 7.2 introduced the immensely useful improvement to stack allocate directly into a span, at which point it becomes “safe,” not requiring being in an context and with all access to the span bounds checked appropriately, as with any other span:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>The C# compiler will lower that to something along the lines of:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>However, this is still limited to the kinds of things that can be ‘d, namely types (types which don’t contain any managed references), and it’s limited in where it can be used. That’s not only because can’t be used in places like and blocks, but also because there are places where you want to be able to have such buffers that aren’t limited to the stack: inside of other types. C# has long supported the notion of “fixed-size buffers,” e.g.</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>but these require being in an context since they present to a consumer as a pointer (in the above example, the type of is a ) and they’re not bounds-checked, and they’re limited in the element type supported (it can only be , , , , , , , , , , , or ).</p>
<p style=display:none!important>.NET 8 and C# 12 provide an answer for this: . This new attribute can be placed onto a containing a single field, like this:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>The runtime then expands that struct to be logically the same as if you wrote:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>ensuring that all of the storage is appropriately contiguous and aligned. Why is that important? Because C# 12 then makes it easy to get a span from one of these instances, e.g.</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>This is all “safe,” and the type of the field can be anything that’s valid as a generic type argument. That means pretty much anything other than s, s, and pointers. This is a constraint imposed by the C# language, since with such a field type you wouldn’t be able to construct a , but the warning can be suppressed, as the runtime itself does support anything as the field type. The compiler-generated code for getting a span is equivalent to if you wrote:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>which is obviously complicated and not something you’d want to be writing frequently. In fact, the compiler doesn’t want to emit that frequently, either, so it puts it into a helper in the assembly that it can reuse.</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>( is a class the C# compiler emits to contain helpers and other compiler-generated artifacts used by code it emits elsewhere in the program. You saw it in the previous discussion as well, as it’s where it emits the data in support of array and span initialization from constants.)</p>
<p style=display:none!important>The -attributed type is also a normal like any other, and can be used anywhere any other can be used; that it’s using is effectively an implementation detail. So, for example, you can embed it into another type, and the following code will print out “0” through “7” as you’d expect:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important> provided the CoreCLR runtime support for , and provided the Mono runtime support, and merged the C# compiler support.</p>
<p style=display:none!important>This feature isn’t just about you using it directly, either. The compiler itself also uses as an implementation detail behind other new and planned features… we’ll talk more about that when discussing collections.</p>
<h3 id=analyzers style=display:none!important>Analyzers</h3>
<p style=display:none!important>Lastly, even though the runtime and core libraries have made great strides in improving the performance of existing functionality and adding new performance-focused support, sometimes the best fix is actually in the consuming code. That’s where analyzers come in. Several new analyzers have been added in .NET 8 to help find particular classes of string-related performance issues.</p>
<p style=display:none!important>, added in from , looks for calls to where the result is then being checked for equality with 0. This is functionally the same as a call to , but is much more expensive as it could end up examining the entire source string rather than just the starting position ( fixes a few such uses in ).
</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important>CA1865, CA1866, and CA1867 are all related to each other. Added in from , these look for calls to methods like , searching for calls passing in a single-character argument, e.g. , and recommending the argument be converted into a . Which diagnostic ID the analyzer raises depends on whether the transformation is 100% equivalent behavior or whether a change in behavior could potentially result, e.g. switching from a linguistic comparison to an ordinal comparison.
</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important>CA1862, added in , looks for places where code is performing a case-insensitive comparison (which is fine) but doing so by first lower/uppercasing an input string and then comparing that (which is far from fine). It’s much more efficient to just use a . fixes a few such cases.
</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important>And , added in from , looks for opportunities to lift and cache arrays being passed as arguments. addresses the issues found by the analyzer in .
</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<h2 id=collections style=display:none!important>Collections</h2>
<p style=display:none!important>Collections are the bread and butter of practically every application and service. Have more than one of something? You need a collection to manage them. And since they’re so commonly needed and used, every release of .NET invests meaningfully in improving their performance and driving down their overheads.</p>
<h3 id=general style=display:none!important>General</h3>
<p style=display:none!important>Some of the changes made in .NET 8 are largely collection-agnostic and affect a large number of collections. For example, special-cases “empty” on a bunch of the built-in collection types to return an empty singleton enumerator, thus avoiding allocating a largely useless object. This is wide-reaching, affecting , , , , , , , , , and . Interestingly, was already on this plan (as were a few other collections, like ); if you called on any of length 0, you already got back a singleton enumerator hardcoded to return from its . That same enumerator singleton is what’s now returned from the implementations of all of those cited collection types when they’re empty at the moment is called.</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important>Enumerator allocations are avoided in other contexts, as well. from avoids an unnecessary enumerator allocation in and , rearranging some code in order to use ‘s struct-based enumerator rather than relying on it being boxed as an . This both saves an allocation and avoids unnecessary interface dispatch.</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important>There are other places where “empty” has been special-cased. and added an singleton to , , and , and then used that singleton in a bunch of places, multiple of which accrue further to many other places that consume them. For example, now checks whether the array being wrapped is empty, and if it is, returns rather than allocating a new to wrap the empty array (it also makes a similar update to as was discussed with the previous PRs). ‘s and will now return the same singleton if the count is known to be 0. And so on. These kinds of changes reduce the overall “peanut butter” layer of allocation across uses of collections.</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important>Of course, there are many much more targeted and impactful improvements for specific collection types, too.</p>
<h2 id=list style=display:none!important>List</h2>
<p style=display:none!important>The most widely used collection in .NET, other than , is . While that claim feels accurate, I also like to be data-driven, so as one measure, looking at the same NuGet packages we looked at earlier for enums, here’s a graph showing the number of references to the various concrete collection types:
</p>
<p style=display:none!important>Given its ubiquity, sees a variety of improvements in .NET 8. improves the performance of its method, in particular when dealing with non- inputs. When adding an , reads the collection’s , ensures the list’s array is large enough to store all the incoming data, and then copies it as efficiently as the source collection can muster by invoking the collection’s method to propagate the data directly into the ‘s backing store. But if the input enumerable isn’t an , has little choice but to enumerate the collection and add each item one at a time. Prior to this release, simply delegated to , which meant that when discovered the source wasn’t an , it would fall back to calling with each item from the enumerable. That method is too large to be inlined by default, plus involves additional checks that aren’t necessary for the usage (e.g. it needs to validate that the supplied position is within the range of the list, but for adding, we’re always just implicitly adding at the end, with a position implicitly known to be valid). This PR rewrote to not just delegate to , at which point when it falls back to enumerating the non- enumerable, it calls the optimized , which is inlineable, and which doesn’t have any extraneous checks.</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>For this test, I’ve configured it to run with and without PGO on .NET 8, because this particular test benefits significantly from PGO, and I want to tease those improvements apart from those that come from the cited improvements to . Why does PGO help here? Because the method will see that the type of the enumerable is always the compiler-generated iterator for and will thus generate code specific to that type, enabling the calls that would otherwise involve interface dispatch to instead be devirtualized.</p>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important> has improved in other ways, too. One of the long-requested features for , ever since spans were introduced in .NET Core 2.1, was better integration between and . provides that, adding support to both and for data stored in a , and also support for copying all of the data in a to a via a method. It was of course previously possible to achieve this, but doing so required handling one element at a time, which when compared to vectorized copy implementations is significantly slower.</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important>You may note that these new , , and methods were added as extension methods rather than as instance methods on . That was done for a few reasons, but the primary motivating factor was avoiding ambiguity. Consider this example:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>This will fail to compile with:</p>
<blockquote style=display:none!important>
</blockquote>
<p style=display:none!important>because an array both implements and has an implicit conversion to , and as such the compiler doesn’t know which to use. It’s likely this ambiguity will be resolved in a future version of the language, but for now we resolved it ourselves by making the span-based overload an extension method:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>The other significant addition for comes in from . In .NET 5, the method was added; it returns a for the in-use area of a ‘s backing store. For example, if you write:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>that will provide you with a with length 3, since the list’s is 3. This is very useful for a variety of scenarios, in particular for consuming a ‘s data via span-based APIs. It doesn’t, however, enable scenarios that want to efficiently write to a , in particular where it would require increasing a ‘s count. Let’s say, for example, you wanted to create a new that contained 100 ‘a’ values. You might think you could write:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>but that won’t impact the contents of the created list at all, because the span’s will match the of the list: 0. What we need to be able to do is change the count of the list, effectively telling it “pretend like 100 values were just added to you, even though they weren’t.” This PR adds the new method, which does just that. We can now write the previous example like:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>and we will successfully find ourselves with a list containing 100 ‘a’ elements.</p>
<h2 id=linq style=display:none!important>LINQ</h2>
<p style=display:none!important>That new method is not only exposed publicly, it’s also used as an implementation detail now in LINQ (Language-Integrated Query), thanks to . ‘s method now benefits from this in a variety of places. For example, calling will behave very much like the previous example (albeit with an extra enumerable allocation for the ), creating a new list, using to set its count to 100, getting the backing span, and calling to populate it. The impact of directly writing to the span rather than going through for each item is visible in the following examples:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important>In the case of and , the benefit is almost entirely due to writing directly into the span for each element vs the overhead of . In the case of , because the call has direct access to the span, it’s able to use the vectorized method (as it was previously doing just for ), achieving an even larger speedup.</p>
<p style=display:none!important>You’ll note that I didn’t include a test for above. That’s because it was improved in other ways, and I didn’t want to conflate them in the measurements. In particular, from vectorized the internal method that’s used by the specialization of both and on the iterator returned from . That means that rather than writing one at a time, on a system that supports 128-bit vectors (which is pretty much all hardware you might use today) it’ll instead write four s at a time, and on a system that supports 256-bit vectors, it’ll write eight s at a time. Thus, benefits both from writing directly into the span and from the now vectorized implementation, which means it ends up with similar speedups as above. We can also tease apart these improvements by changing what instruction sets are seen as available.</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important>These optimized span-based implementations now also accrue to other usage beyond and . If you look at the and implementations in .NET Framework, you’ll see that they’re just normal C# iterators, e.g.</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>but years ago, these methods were changed in .NET Core to return a custom iterator (just a normal class implementing where we provide the full implementation rather than the compiler doing so). Once we have a dedicated type, we can add additional interfaces to it, and does exactly that, making these internal , , and several other types implement . That then means that any code which queries an for whether it implements , such as to use its and methods, will light up when passed one of these instances as well. And the same implementation that’s used internally to implement and is then used as well with . That means if you write code like:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>and that came from one of these enlightened types, it’ll now benefit from the exact same use of vectorization previously discussed, as the will ensure its array is appropriately sized to handle the incoming data and will then hand its array off to the iterator’s method to write into directly.</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important>Vectorization with LINQ was also improved in other ways. In .NET 7, and were taught how to vectorize the handling of some inputs (when the enumerable was actually an array or list of or values), and in .NET 8 expanded that to cover , , , , , , , and as well (it also switched the implementation from using to using both and , so that shorter inputs could still benefit from some level of vectorization).</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important> has now also been vectorized, for and , thanks to from . in LINQ performs arithmetic, and normal operations are , which makes the vectorization of this method a bit more challenging. To achieve it, it takes advantage of a neat little bit hack trick for determining whether an addition of two signed twos-complement numbers underflow or overflow. The same logic applies for both and here, so we’ll focus just on . It’s impossible for the addition of a negative to overflow when added to a positive , so the only way two summed values can underflow or overflow is if they have the same sign. Further, if any wrapping occurs, it can’t wrap back to the same sign; if you add two positives numbers together and it overflows, the result will be negative, and if you add two negative numbers together and it underflows, the result will be positive. Thus, a function like this can tell us whether the sum wrapped:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>We’re ‘ing the result with each of the inputs, and ‘ing those together. That will produce a number who’s top-most bit is 1 if there was overflow/underflow, and otherwise 0, so we can then mask off all the other bits and compare to 0 to determine whether wrapping occurred. This is useful for vectorization, because we can easily do the same thing with vectors, summing the two vectors and reporting on whether any of the elemental sums overflowed:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>With that, can be vectorized. For sure, it’s not as efficient as if we didn’t need to care about the ; after all, for every addition operation, there’s at least an extra set of instructions for the two s and the ‘ing of them (we can amortize the bit check across several operations by doing some loop unrolling). With 256-bit vectors, an ideal speedup for such a sum operation over values would be 8x, since we can process eight 32-bit values at a time in a 256-bit vector. We’re then doing fairly well that we get a 4x speedup in that situation:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important>LINQ has improved in .NET 8 beyond just vectorization; other operators have seen other kinds of optimization. Take /, for example. These LINQ operators implement a “stable sort”; that means that while sorting the data, if two items compare equally, they’ll end up in the final result in the same order they were in the original (an “unstable sort” doesn’t care about the ordering of two values that compare equally). The core sorting routine shared by spans, arrays, and lists in .NET (e.g. ) provides an unstable sort, so to use that implementation and provide stable ordering guarantees, LINQ has to layer the stability on top, which it does by factoring into the comparison operation between keys the original location of the key in the input (e.g. if two values otherwise compare equally, then it proceeds to compare their original locations). That, however, means it needs to remember their original locations, which means it needs to allocate a separate for positions. Interestingly, though, sometimes you can’t tell the difference between whether a sort is stable or unstable. takes advantage of the fact that for primitive types like , two values that compare equally with the default comparer are indistinguishable, in which case it’s fine to use an unstable sort because the only values that can compare equally have identical bits and thus trying to maintain an order between them doesn’t matter. It thus enables avoiding all of the overhead associated with maintaining a stable sort.</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important> also improves sorting in LINQ, this time for /, and in particular when the type of the key used (the type returned by the delegate provided to ) is a value type and the default comparer is used. This change employs the same approach that some of the .NET collections like already do, which is to take advantage of the fact that value types when used as generics get a custom copy of the code dedicated to that type (“generic specialization”), and that will get devirtualized and possibly inlined. As such, it adds a dedicated path for when the key is a value type, and that enables the comparison operation (which is invoked times) to be sped up.</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important>Of course, sometimes the most efficient use of LINQ is simply not using it. It’s an amazing productivity tool, and it goes to great lengths to be efficient, but sometimes there are better answers that are just as simple. , added in from , flags one such case. It looks for use of on collections that directly expose a , , or property that could be used instead. While does use in an attempt to check the collection’s number of items without allocating or using an enumerator, even if it’s successful in doing so it incurs the overhead of the interface check and dispatch. It’s faster to just use the properties directly. fixed several cases of this.
</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<h2 id=dictionary style=display:none!important>Dictionary</h2>
<p style=display:none!important>In addition to making existing methods faster, LINQ has also gained some new methods in .NET 8. from added new overloads of . Unlike the existing overloads that are extensions on any arbitrary and accept delegates for extracting from each a and/or , these new overloads are extensions on and . This is primarily an addition for convenience, as it means that such an enumerable that previously used code like:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>can instead be simplified to just be:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>Beyond being simpler, this has the nice benefit of also being cheaper, as it means the method doesn’t need to invoke two delegates per item. It also means that this new method is a simple passthrough to ‘s constructor, which has its own optimizations that take advantage of knowing about internals, e.g. it can more efficiently copy the source data if it’s a .</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important>It also benefits from the ‘s constructor being optimized in additional ways. As noted, its constructor accepting an already special-cased when the enumerable is actually a . With , it now also special-cases when the enumerable is a or a . When such a source is found, a span is extracted from it (a simple cast for an array, or via for a ), and then that span (rather than the original ) is what’s enumerated. That saves an enumerator allocation and several interface dispatches per item for these reasonably common cases.</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important>The most common operation performed on a dictionary is looking up a key, whether to see if it exists, to add a value, or to get the current value. Previous .NET releases have seen significant improvements in this lookup time, but even better than optimizing a lookup is not needing to do one at all. One common place we’ve seen unnecessary lookups is with guard clauses that end up being unnecessary, for example code that does:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>This incurs two lookups, one as part of , and then if the key wasn’t in the dictionary, another as part of the call. Code can instead achieve the same operation with:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>which incurs only one lookup. , added in from , looks for such places where an call is guarded by a call. fixed a few occurrences of this in .
</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important>Similarly, from added , which looks for or calls on s where the call is guarded by a , and recommends removing the call. from fixes occurrences of this in .
</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important>Other related analyzers previously released have also been improved. improved to find more opportunities for using , with and using the analyzer to find and fix more occurrences.</p>
<p style=display:none!important>Other dictionaries have also improved in .NET 8. in particular got a nice boost from , for all key types but especially for the very common case where is and the equality comparer is either the default comparer (whether that be , , or , all of which behave identically) or . In .NET Core, hash codes are randomized, meaning there’s a random seed value unique to any given process that’s incorporated into string hash codes. So if, for example, I run the following program:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>I get the following output, showing that the hash code for a given string is stable across multiple calls:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>but when I run the program again, I get a different stable value:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>This randomization is done to help mitigate a class of denial-of-service (DoS) attacks involving dictionaries, where an attacker might be able to trigger the worst-case algorithmic complexity of a dictionary by forcing lots of collisions amongst the keys. However, the randomization also incurs some amount of overhead. It’s enough overhead so that actually special-cases keys with a default or comparer to skip the randomization until a sufficient number of collisions has been detected. Now in .NET 8, employs the same trick. When it starts life, a instance using a default or comparer performs hashing using a non-randomized comparer. Then as it’s adding an item and traversing its internal data structure, it keeps track of how many keys it has to examine that had the same hash code. If that count surpasses a threshold, it then switches back to using a randomized comparer, rehashing the whole dictionary in order to mitigate possible attacks.</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important>The above benchmark also benefited from , which tweaked another long-standing optimization in the type. maintains a object for every key/value pair it stores. As multiple threads might be reading from the dictionary concurrent with updates happening, the dictionary needs to be really careful about how it mutates data stored in the collection. If an update is performed that needs to update a in an existing node (e.g. ), the dictionary needs to be very careful to avoid torn reads, such that one thread could be reading the value while another thread is writing the value, leading to the reader seeing part of the old value and part of the new value. It does this by only reusing that same for an update if it can write the atomically. It can write it atomically if the is a reference type, in which case it’s simply writing a pointer-sized reference, or if the is a primitive value that’s defined by the platform to always be written atomically when written with appropriate alignment, e.g. , or when in a 64-bit process. To make this check efficient, computes once whether a given is writable atomically, storing it into a field, such that in tier 1 compilation, the JIT can treat the value as a . However, this trick doesn’t always work. The field was on itself, and if one of those generic type parameters ended up being a reference type (e.g. ), accessing the field would require a generic lookup (the JIT isn’t currently able to see that the value stored in the field is only dependent on the and not on the ). To fix this, the field was moved to a separate type where is the only generic parameter, and a check for (which is itself a JIT intrinsic that manifests as a ) is done separately.</p>
<p style=display:none!important>‘s was also improved this release, via . Mutation of a requires taking a lock. However, in the case of , we only actually need the lock if it’s possible the item being removed is contained. If the number of items protected by the given lock is 0, we know will be a nop. Thus, this PR added a fast path to that read the count for that lock and immediately bailed if it was 0.</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important>Another dictionary that’s been improved in .NET 8 is . As background if you haven’t used this type before, is a very specialized dictionary based on ; think of it as every key being a weak reference (so if the GC runs, the key in the dictionary won’t be counted as a strong root that would keep the object alive), and that if the key is collected, the whole entry is removed from the table. It’s particularly useful in situations where additional data needs to be associated with an object but where for whatever reason you’re unable to modify that object to have a reference to the additional data. improves the performance of lookups on a , in particular for objects that in the collection, and even more specifically for an object that’s never been in any dictionary. Since is about object references, unlike other dictionaries in .NET, it doesn’t use the default to determine whether an object is in the collection; it just uses object reference equality. And that means to get a hash code for an object, it uses the same functionality that the base does. It can’t just call , as the method could have been overridden, so instead it directly calls to the same public that uses:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>This PR tweaks what does here. It introduces a new internal that will avoid creating and storing a hash code for the object if the object doesn’t already have one. It then uses that method from as part of (and , and other related APIs). If returns a value indicating the object doesn’t yet have one, then the operation can early-exit, because for the object to have been stored into the collection, it must have had a hash code generated for it.</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important>So, improvements to , , … are those the “end all be all” of hash table world? Don’t be silly…</p>
<h2 id=frozen-collections style=display:none!important>Frozen Collections</h2>
<p style=display:none!important>There are many specialized libraries available on NuGet, providing all manner of data structures with this or that optimization or targeted at this or that scenario. Our goal with the core .NET libraries has never been to provide all possible data structures (it’s actually been a goal not to), but rather to provide the most commonly needed data structures focused on the most commonly needed scenarios, and rely on the ecosystem to provide alternatives where something else is deemed valuable. As a result, we don’t add new collection types all that frequently; we continually optimize the ones that are there and we routinely augment them with additional functionality, but we rarely introduce brand new collection types. In fact, in the last several years, the only new general-purpose collection type introduced into the core libraries was class, which was added in .NET 6. However, enough of a need has presented itself that .NET 8 sees the introduction of not one but two new collection types: and .</p>
<p style=display:none!important>Beyond causing “Let It Go” to be stuck in your head for the rest of the day (“you’re welcome”), what benefit do these new types provide, especially when we already have and ? There are enough similarities between the existing immutable collections and the new frozen collections that the latter are actually included in the library, which means they’re also available as part of the NuGet package. But there are also enough differences to warrant us adding them. In particular, this is an example of where scenario and intended use make a big impact on whether a particular data structure makes sense for your needs.</p>
<p style=display:none!important>Arguably, the existing collections were misnamed. Yes, they’re “immutable,” meaning that once you’ve constructed an instance of one of the collection types, you can’t change its contents. However, that could have easily been achieved simply by wrapping an immutable facade around one of the existing mutable ones, e.g. an immutable dictionary type that just copied the data into a mutable and exposed only reading operations:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>Yet, if you look at the implementation of , you’ll see a ton of code involved in making the type tick. Why? Because it and its friends are optimized for something very different. In academic nomenclature, the immutable collections are actually “persistent” collections. A persistent data structure is one that provides mutating operations on the collection (e.g. Add, Remove, etc.) but where those operations don’t actually change the existing instance, instead resulting in a new instance being created that contains that modification. So, for example, ironically exposes an method, but this method doesn’t actually modify the collection instance on which it’s called; instead, it creates and returns a brand new instance, containing all of the key/value pairs from the original instance as well as the new key/value pair being added. Now, you could imagine that being done simply by copying all of the data to a new and adding in the new value, e.g.</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>but while functional, that’s terribly inefficient from a memory consumption perspective, as every addition results in a brand new copy of all of the data being made, just to store that one additional pair in the new instance. It’s also terribly inefficient from an algorithmic complexity perspective, as adding N values would end up being an algorithm (each new item would result in copying all previous items). As such, is optimized to share as much as possible between instances. Its implementation uses an , a self-balancing binary search tree. Adding into such a tree not only requires time (whereas the full copy shown in above is ), it also enables reusing entire portions of a tree between instances of dictionaries. If adding a key/value pair doesn’t require mutating a particular subtree, then both the new and old dictionary instances can point to that same subtree, thereby avoiding significant memory increase. You can see this from a benchmark like the following:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>which when run on .NET 8 yields the following results for me:</p>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important>That highlights that the tree-based nature of makes it significantly more efficient (~120x better in both throughput and allocation in this run) for example of performing lots of additions, when compared with using for the same purpose a treated as being immutable. And that’s why these immutable collections came into being in the first place. The C# compiler uses lots and lots of dictionaries and sets and the like, and it employs a lot of concurrency. It needs to enable one thread to “tear off” an immutable view of a collection even while other threads are updating the collection, and for such purposes it uses .</p>
<p style=display:none!important>However, just because the above numbers look amazing doesn’t mean is always the right tool for the immutable job… it actually rarely is. Why? Because the exact thing that made it so fast and memory efficient for the above benchmark is also its downfall on one of the most common tasks needed for an “immutable” dictionary: reading. With its tree-based data structure, not only are adds , but lookups are also , which for a large dictionary can be extremely inefficient when compared to the access times of a type like . We can see this as well with a simple benchmark. Let’s say we’ve built up our 10,000-element dictionary as in the previous example, and now we want to query it:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important>Uh oh. Our in this example is ~12x as expensive for lookups and ~20x as expensive for enumeration as . If your process will be spending most of its time performing reads on the dictionary rather than creating it and/or performing mutation, that’s a lot of cycles being left on the table.</p>
<p style=display:none!important>And that’s where frozen collections come in. The collections in are immutable, just as are those in , but they’re optimized for a different scenario. Whereas the purpose of a type like is to enable efficient mutation (into a new instance), the purpose of is to represent data that never changes, and thus it doesn’t expose any operations that suggest mutation, only operations for reading. Maybe you’re loading some configuration data into a dictionary once when your process starts (and then re-loading it only rarely when the configuration changes) and then querying that data over and over and over again. Maybe you’re creating a mapping from HTTP status codes to delegates representing how those status codes should be handled. Maybe you’re caching schema information about a set of dynamically-discovered types and then using the resulting parsed information every time you encounter those types later on. Whatever the scenario, you’re creating an immutable collection that you want to be optimized for reads, and you’re willing to spend some more cycles creating the collection (because you do it only once, or only once in a while) in order to make reads as fast as possible. That’s exactly what and provide.</p>
<p style=display:none!important>Let’s update our previous example to now also include :</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important>Now we’re talkin’. Whereas for this lookup test was ~9x faster than , was 50% faster than even .</p>
<p style=display:none!important>How does that improvement happen? Just as doesn’t just wrap a , doesn’t just wrap one, either. It has a customized implementation focused on making read operations as fast as possible, both for lookups and for enumerations. In fact, it doesn’t have just one implementation; it has many implementations.</p>
<p style=display:none!important>To start to see that, let’s change the example. In the United States, the Social Security Administration tracks the popularity of baby names. In 2022, the for girls were Olivia, Emma, Charlotte, Amelia, Sophia, Isabella, Ava, Mia, Evelyn, and Luna. Here’s a benchmark that checks to see whether a name is one of those:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important>Significantly faster. Internally, can pick an implementation based on the data supplied, both the type of the data and the exact values being used. In this case, if we print out the type of , we see:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>That’s an implementation detail, but what we’re seeing here is that the , even though it’s strongly-typed as , is actually a derived type named . has analyzed the data supplied to it and chosen a strategy that it thinks will yield the best overall throughput. Part of that is just seeing that the type of the data is , in which case all the -based strategies are able to quickly discard queries that can’t possibly match. In this example, the set will have tracked that the longest string in the collection is “Charlotte” at only nine characters long; as such, when it’s asked whether the set contains “Alexandria”, it can immediately answer “no,” because it does a quick length check and sees that “Alexandria” at 10 characters can’t possibly be contained.</p>
<p style=display:none!important>Let’s take another example. Internal to the C# compiler, it has the notion of “special types,” and it has a dictionary that maps from a string-based type name to an used to identify that special-type. As a simplified representation of this, I’ve just extracted those strings to create a set:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important>Here the item we’re searching for is in the collection, so it’s not getting its performance boost from a fast path to fail out of the search. The concrete type of in this case sheds some light on it:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>One of the biggest costs involved in looking up something in a hash table is often the cost of producing the hash in the first place. For a type like , it’s trivial, as it’s literally just its value. But for a type like , the hash is produced by looking at the string’s contents and factoring each character into the resulting value. The more characters need to be considered, the more it costs. In this case, the type has identified that in order to differentiate all of the items in the collection, only a subset of them needs to be hashed, such that it only needs to examine a subset of the incoming string to determine what a possible match might be in the collection.</p>
<p style=display:none!important>A bunch of PRs went into making happen in .NET 8. It started as an internal project used by several services at Microsoft, and was then cleaned up and added as part of . That provided the core types and initial strategy implementations, with following it to provide additional strategies (although we subsequently backed out a few due to lack of motivating scenarios for what their optimizations were targeting).</p>
<p style=display:none!important> then removed some virtual dispatch from the string-based implementations. As noted in the previous example, one approach the strategies take is to try to hash less, so there’s a phase of analysis where the implementation looks at the various substrings in each of the items and determines whether there’s an offset and length for substring that across all of the items provides an ideal differentiation. For example, consider the strings “12a34”, “12b34”, “12c34”; the analyzer would determine that there’s no need to hash the whole string, it need only consider the character at index 2, as that’s enough to uniquely hash the relevant strings. This was initially achieved by using a custom comparer type, but that then meant that virtual dispatch was needed in order to invoke the hashing routine. Instead, this PR created more concrete derived types from /, such that the choice of hashing logic was dictated by the choice of concrete collection type to instantiate, saving on the per-operation dispatch.</p>
<p style=display:none!important>In any good story, there’s a twist, and we encountered a twist with these frozen collection types as well. I’ve already described the scenarios that drove the creation of these types: create once, use . And as such, a lot of attention was paid to overheads involved in reading from the collection, but initially very little time was paid to optimizing construction time. In fact, improving construction time was initially a non-goal, with a willingness to spend as much time as was needed to eke out more throughput for reading. This makes sense if you’re focusing on long-lived services, where you’re happy to spend extra seconds once an hour or day or week to optimize something that will then be used many thousands of times per second. However, the equation changes a bit when types like this are exposed in the core libraries, such that the expected number of developers using them, the use cases they have for them, and the variations of data thrown at them grows by orders of magnitude. We started hearing from developers that they were excited to use / not just because of performance but also because they were truly immutable, both in implementation and in surface area (e.g. no method to confuse things), and that they’d be interested in employing them in object models, UIs, and so on. At that point, you’re no longer in the world of “we can take as much time for construction as we want,” and instead need to be concerned about construction taking inordinate amounts of time and resources.</p>
<p style=display:none!important>As a stop-gap measure, changed the existing / methods to not do any analysis of the incoming data, and instead have both construction time and read throughput in line with that of /. It then added new overloads with a argument, to enable developers to opt-in to those longer construction times in exchange for better read throughput. This wasn’t an ideal solution, as it meant that it took more discovery and more code for a developer to achieve the primary purpose of these types, but it also helped developers avoid pits of failure by using what looked like a harmless method but could result in significant increases in processing time (one degenerate example I created resulted in running literally for minutes).</p>
<p style=display:none!important>We then set about to improve the overall performance of the collections, with a bunch of PRs geared towards driving down the costs:</p>
<ul style=display:none!important>
</ul>
<p style=display:none!important>With all of those optimizations in place, construction time has now improved to the point where it’s no longer a threat, and effectively reverted , getting rid of the -based overloads, such that everything is now optimized for reading.</p>
<p style=display:none!important>As an aside, it’s worth noting that for keys in particular, the C# compiler has now also gotten in on the game of better optimizing based on the known characteristics of the data, such that if you know all of your keys at compile-time, and you just need an ordinal, case-sensitive lookup, you might be best off simply writing a statement or expression. This is all thanks to . Let’s take the name popularity example from earlier, and express it as a statement:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>Previously compiling this would result in the C# compiler providing a lowered equivalent to this:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>If you stare at that for a moment, you’ll see the compiler has implemented a binary search tree. It hashes the name, and then having hashed all of the cases at build time, it does a binary search on the hash codes to find the the right case. Now with the recent improvements, it instead generates an equivalent of this:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>Now what’s it doing? First, it’s bucketed the strings by their length; any string that comes in that’s not 3, 4, 6, 8, or 9 characters long will be immediately rejected. For 8 and 9 characters, there’s only one possible answer it could be for each, so it simply checks against that string. For the others, it’s recognized that each name in that length begins with a different letter, and switches over that. In this particular example, the first character in each bucket is a perfect differentiator, but if it wasn’t, the compiler will also consider other indices to see if any of those might be better differentiators. This is implementing the same basic strategy as the we saw earlier.</p>
<p style=display:none!important>I was careful in my choice above to use a . If I’d instead written the possibly more natural expression:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>then up until recently the compiler wouldn’t even have output the binary search, and would have instead just generated a cascading / as if I’d written:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>With from , however, the -based version is now lowered the same as the -based version.</p>
<p style=display:none!important>Back to frozen collections. As noted, types are in the library, and they’re not the only improvements to that library. A variety of new APIs have been added to help enable more productive and efficient use of the existing immutable collections…</p>
<h2 id=immutable-collections style=display:none!important>Immutable Collections</h2>
<p style=display:none!important>For years, developers have found the need to bypass an ‘s immutability. For example, the previously-discussed exposes an for its keys and an for its values. It does this by creating a , which it uses for a variety of purposes while building up the collection, and then it wants to wrap that as an to be exposed for consumption. But with the public APIs available on /, there’s no way to transfer ownership like that; all the APIs that accept an input or allocate a new array and copy all of the data into it, so that the implementation can be sure no one else is still holding onto a reference to the array being wrapped (if someone was, they could use that mutable reference to mutate the contents of the immutable array, and guarding against that is one of the key differentiators between a read-only collection and an immutable collection). Enabling such wrapping of the original array is thus an “unsafe” operation, albeit one that’s valuable to enable for developers willing to accept the responsibility. Previously, developers could achieve this by employing a hack that works but only because of implementation detail: using to cast between the types. When a value type’s first field is a reference type, a reference to the beginning of the struct is also a reference to the reference type, since they’re both at the exact same memory location. Thus, because contains just a single field (for the it wraps), a method like the following will successfully wrap an around a :</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>That, however, is both uintuitive and depends on having the array at a 0-offset from the start of the struct, making it a brittle solution. To provide something robust, added the new class, and on it two new methods: and . These methods support casting back and forth between a and an , without allocation. They’re defined in on a class, as that’s one of the ways we have to both hide more dangerous functionality and declare that something is inherently “unsafe” in some capacity.</p>
<p style=display:none!important>There are also new overloads exposed for constructing immutable collections with less allocation. All of the immutable collections have a corresponding static class that provides a method, e.g. has the corresponding static class which provides a method. Now in .NET 8 as of , these methods all have a new overload that takes a , e.g. . This means an immutable collection can be created without incurring the allocation required to either go through the associated builder (which is a reference type) or to allocate an array of the exact right size.</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<h3 id=bitarray style=display:none!important>BitArray</h3>
<p style=display:none!important> from added two new methods to , and , which do exactly what their names suggest: returns whether all of the bits in the array are set, and returns whether any of the bits in the array are set. While useful, what I really like about these additions is that they make good use of the method introduced in .NET 8. ‘s storage is an , where each element in the array represents 32 bits (for the purposes of this discussion, I’m ignoring the corner-case it needs to deal with of the last element’s bits not all being used because the count of the collection isn’t a multiple of 32). Determining whether any bits are set is then simply a matter of doing . Similarly, determining whether all bits are set is simply a matter of doing . The bit pattern for is all 1s, so will return true if and only if it finds any integer that doesn’t have all of its bits set; thus if the call doesn’t find any, all bits are set. The net result is gets to maintain simple code that’s also vectorized and optimized, thanks to delegating to these shared helpers. You can see examples of these methods being used in , which replaced bespoke implementations of the same functionality with the new built-in helpers.</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<h3 id=collection-expressions style=display:none!important>Collection Expressions</h3>
<p style=display:none!important>With and then a myriad of subsequent PRs, C# 12 introduces a new terse syntax for constructing collections: “collection expressions.” Let’s say I want to construct a , for example, with the elements 1, 2, and 3. I could do it like so:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>or utilizing collection initializers that were added in C# 3:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>Now in C# 12, I can write that as:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>I can also use “spreads,” where enumerables can be used in the syntax and have all of their contents splat into the collection. For example, instead of:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>or:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>I can simply write:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>If it were just a simpler syntax for collections, it wouldn’t be worth discussing in this particular post. What makes it relevant from a performance perspective, however, is that the C# compiler is free to optimize this however it sees fit, and it goes to great lengths to write the best code it can for the given circumstance; some optimizations are already in the compiler, more will be in place by the time .NET 8 and C# 12 are released, and even more will come later, with the language specified in such a way that gives the compiler the freedom to innovate here. Let’s take a few examples…</p>
<p style=display:none!important>If you write:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>the compiler won’t just translate that into:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>After all, we have a perfectly good singleton for this in the way of , something the compiler already emits use of for things like , and it can emit the same thing here:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>Ok, what about the optimizations we previously saw around the compiler lowering the creation of an array involving only constants and storing that directly into a ? Yup, that applies here, too. So, instead of writing:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>you can write:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>and the exact same code results.</p>
<p style=display:none!important>What about ? Earlier in the discussion of collections we saw that now sports an , and the compiler is free to use that. For example, if you write this:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>the compiler could emit the equivalent of this:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>One of my favorite optimizations it achieves, though, is with spans and the use of the attribute we already saw. If you write:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>the compiler can lower that to code along the lines of this:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>In short, this collection expression syntax becomes way to utilize in the vast majority of situations, allowing the compiler to create a shared definition for you.</p>
<p style=display:none!important>That optimization also feeds into another, which is both an optimization and a functional improvement over what’s in C# 11. Let’s say you have this code… what do you expect it to print?</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>Unless you’re steeped in and how collection initializers work, you likely didn’t predict the (unfortunate) answer:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important> is a struct, so this will end up using its default initialization, which contains a array. But even if that was made to work, the C# compiler will have lowered the code I wrote to the equivalent of this:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>which is “wrong” in multiple ways. doesn’t actually mutate the original collection, but instead returns a new instance that contains the additional element, so when we enumerate , we wouldn’t see any of the additions. Plus, we’re doing all this work and allocation to create the results of , only to drop those results on the floor.</p>
<p style=display:none!important>Collection expressions fix this. Now you can write this:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>and running it successfully produces:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>Why? Because added a new attribute that’s recognized by the C# compiler. That attribute is placed on a type and points to a factory method for creating that type, accepting a and returning the instance constructed from that data. That PR also tagged with this attribute:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>such that when the compiler sees an being constructed from a collection expression, it runs to use . Not only that, it’s able to use the -based optimization we just talked about for creating that input. As such, the code the compiler generates for this example as of today is equivalent to this:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>, , , , and are all similarly attributed such that they all work with collection expressions as well.</p>
<p style=display:none!important>Of course, the compiler could actually do a bit better for . As was previously noted, the compiler is free to optimize these how it sees fit, and we already mentioned the new method. As I write this, the compiler doesn’t currently employ that method, but in the future the compiler can special-case , such that it could then generate code equivalent to the following:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>saving on both stack space as well as an extra copy of the data. This is just one of the additional optimizations possible.</p>
<p style=display:none!important>In short, collection expressions are intended to be a great way to express the collection you want built, and the compiler will ensure it’s done efficiently.</p>
<h2 id=file-i-o style=display:none!important>File I/O</h2>
<p style=display:none!important>.NET 6 overhauled how file I/O is implemented in .NET, rewriting , introducing the class, and a multitude of other changes. .NET 8 continues to improve performance with file I/O further.</p>
<p style=display:none!important>One of the more interesting ways performance of a system can be improved is cancellation. After all, the fastest work is work you don’t have to do at all, and cancellation is about stopping doing unneeded work. The original patterns for asynchrony in .NET were based on a non-cancelable model (see for an in-depth history and discussion), and over time as all of that support has shifted to the -based model based on , more and more implementations have become fully cancelable as well. As of .NET 7, the vast majority of code paths that accepted a actually respected it, more than just doing an up-front check to see whether cancellation was already requested but then not paying attention to it during the operation. Most of the holdouts have been very corner-case, but there’s one notable exception: s created without .</p>
<p style=display:none!important> inherited the bifurcated model of asynchrony from Windows, where at the time you open a file handle you need to specify whether it’s being opened for synchronous or asynchronous (“overlapped”) access. A file handle opened for overlapped access requires that all operations be asynchronous, and vice versa if it’s opened for non-overlapped access requires that all operations be synchronous. That causes some friction with , which exposes both synchronous (e.g. ) and asynchronous (e.g. ) methods, as it means that one set of those needs to emulate the behavior. If the is opened for asynchronous access, then needs to do the operation asynchronously and block waiting for it complete (a pattern we less-than-affectionately refer to as ), and if the is opened for synchronous access, then needs to queue a work item that will do the operation synchronously (). Even though that method accepts a , the actual synchronous that ends up being invoked as part of a work item hasn’t been cancelable. Now in .NET 8, thanks to , it is, at least on Windows.</p>
<p style=display:none!important>In .NET 7, was fixed for this same case, relying on an internal helper that would use the Win32 to interrupt pending I/O, while also using appropriate synchronization to ensure that only the intended associated work was interrupted and not work that happened to be running on the same worker thread before or after (Linux already fully supported cancellation as of .NET 5). This PR adapted that same helper to then be usable as well inside of on Windows, in order to gain the same benefits. The same PR also further improved the implementation of that helper to reduce allocation and to further streamline the processing, such that the existing support in gets leaner as well.</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important>Interacting with paths via and has also improved in various ways. improved on Windows both functionally and for performance; in many situations in the past, we’ve made the behavior of .NET on Unix match the behavior of .NET on Windows, but this PR interestingly goes in the other direction. On Unix, uses the libc function, which accepts a template that must end in “XXXXXX” (6 s), and it populates those s with random values, using the resulting name for a new file that gets created. On Windows, was using the Win32 function, which uses a similar pattern but with only 4 s. With the characters Windows will fill in, that enables only 65,536 possible names, and as the temp directory fills up, it becomes more and more likely there will be conflicts, leading to longer and longer times for creating a temp file (it also means that on Windows has been limited to creating 65,536 simultaneously-existing files). This PR changes the format on Windows to match that used on Unix, and avoids the use of , instead doing the random name assignment and retries-on-conflict itself. The net result is more consistency across OSes, a much larger number of temporary files possible (a billion instead of tens of thousands), as well as a better-performing method:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important> is another on the list of methods that improves, thanks to making use of methods. Here, uses (on Unix, where the only directory separator is ) or (on Windows, where both and can be a directory separator) to search for the beginning of the file name.</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important>Related to and , various methods on also return paths. had been using to get the system path, but this was leading to noticeable overhead when starting up an ASP.NET application. changed this to use directly, which on Windows takes advantage of the much more efficient path (and resulting in simpler code), but then also fixed on Windows to use , such that its performance accrues to the higher-level uses as well.</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important> improves and , making the property lazy. Previously when constructing the info object if only the full name existed (and not the name of just the directory or file itself), the constructor would promptly create the string, even if the info object is never used (as is often the case when it’s returned from a method like ). Now, that string is lazily created on first use of the property.</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important> has gotten a whole lot faster on macOS, thanks to from . now employs the OS’s function (if available) to perform the copy, and if both the source and destination are on the same volume, creates a copy-on-write clone of the file in the destination; this makes the copy at the OS level much faster, incurring the majority cost of actually duplicating the data only occurring if one of the files is subsequently written to.</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important>Some more specialized changes have been incorporated as well. is a core abstraction for writing text to an arbitrary destination, but sometimes you want that destination to be nowhere, a la on Linux. For this, provides the property, which returns a instance that nops on all of its members. Or, at least that’s the visible behavior. In practice, only a subset of its members were actually overridden, which meant that although nothing would end up being output, some work might still be incurred and then the fruits of that labor thrown away. ensures that all of the writing methods are overridden in order to do away with all of that wasted work.</p>
<p style=display:none!important>Further, one of the places ends up being used is in , where allows you to replace with your own writer, at which point all of the writing methods on output to that instead. In order to provide thread-safety of writes, synchronizes access to the underlying writer, but if the writer is doing nops anyway, there’s no need for that synchronization. does away with it in that case, such that if you want to temporarily silence , you can simply set its output to go to , and the overhead of operations on will be minimized.</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<h2 id=networking style=display:none!important>Networking</h2>
<p style=display:none!important>Networking is the heart and soul of most modern services and applications, which makes it all the more important that .NET’s networking stack shine.</p>
<h3 id=networking-primitives style=display:none!important>Networking Primitives</h3>
<p style=display:none!important>Let’s start at the bottom of the networking stack, looking at some primitives. Most of these improvements are around formatting, parsing, and manipulation as bytes. Take , for example, which improved the performance of various such operations on . stores a that’s used as the address when it’s representing an IPv4 address, and it stores a that’s used when it’s representing an IPv6 address. A is two bytes, so a is 16 bytes, or 128 bits. “128 bits” is a very convenient number when performing certain operations, as such a value can be manipulated as a (accelerating computation on systems that accelerate it, which is most). This PR takes advantage of that to optimize common operations with an . The constructor, for example, is handed a for an IPv6 address, which it needs to read into its ; previously that was done with a loop over the input, but now it’s handled with a single vector: load the single vector, possibly reverse the endianness (which can be done in just three instructions: OR together the vector shifted left by one byte and shifted right by one byte), and store it.</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important> now also implements and , thanks to and . That means, for example, that using an as part of string interpolation no longer needs to allocate an intermediate string. As part of this, some changes were made to formatting to streamline it. It’s a bit harder to measure these changes, though, because caches a string it creates, such that subsequent calls just return the previous string created. To work around that, we can use private reflection to null out the field ( do this in a real code; private reflection against the core libraries is very much unsupported).</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important>Unfortunately, such use of reflection has a non-trivial amount of overhead associated with it, which then decreases the perceived benefit from the improvement. Instead, we can use reflection emit either directly or via to emit a custom helper that makes it less expensive to null out that private field.</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important>But .NET 8 actually includes a feature that streamlines this; the feature’s primary purpose is in support of scenarios like source generators with Native AOT, but it’s useful for this kind of benchmarking, too. The new attribute (introduced in and supported by , , and ) lets you define an method that bypasses visibility. In this case, I’ve used it to get a to the private field, at which point I can just assign through the .</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important> is another networking primitive that saw multiple improvements. removed a variety of allocations, primarily around substrings that were instead replaced by spans. replaced unsafe code as part of scheme parsing with safe span-based code, making it both safer and faster. But is more interesting, as it made implement . That means that when, for example, a is used as an argument to an interpolated string, the can now format itself directly to the underlying buffer rather than needing to allocate a temporary string that’s then added in. This can be particularly useful for reducing the costs of logging and other forms of telemetry. It’s a little difficult to isolate just the formatting aspect of a for benchmarking purposes, as caches information gathered in the process, but even with constructing a new one each time you can see gains:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important>Other networking primitives improved in other ways. reduced the overhead of the methods of several networking types, like . was previously allocating and is now allocation-free. Same for .</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important>And improved in . This is a quintessential example of code doing its own manual looping looking for something (in this case, the four characters that require encoding) when it could have instead just used a well-placed .</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important>Moving up the stack to , there are some nice improvements in .NET 8 here as well.</p>
<h2 id=sockets style=display:none!important>Sockets</h2>
<p style=display:none!important> and are for Windows only because the problem they address doesn’t manifest on other operatings systems, due to how asynchronous operations are implemented on the various platforms.</p>
<p style=display:none!important>On Unix operatings systems, the typical approach to asynchrony is to put the socket into non-blocking mode. Issuing an operation like () when there’s nothing to receive then fails immediately with an value of or , informing the caller that no data was available to receive yet and it’s not going to wait for said data because it’s been told not to. At that point, the caller can choose how it wants to wait for data to become available. does what many other systems do, which is to use (on Linux) or (on macOS). These mechanisms allow for a single thread to wait efficiently for any number of registered file descriptors to signal that something has changed. As such, has one or more dedicated threads that sit in a wait loop, waiting on the / to signal that there’s something to do, and when there is, queueing off the associated work, and then looping around to wait for the next notification. In the case of a , that queued work will end up reissuing the , which will now succeed as data will be available. The interesting thing here is that during that interim period while waiting for data to become available, there was no pending call from .NET to or anything else that would require a managed buffer (e.g. an array) be available. That’s not the case on Windows…</p>
<p style=display:none!important>On Windows, the OS provides dedicated asynchronous APIs (“overlapped I/O”), with being a thin wrapper around the Win32 function. accepts a pointer to the buffer to write into and a pointer to a callback that will be invoked when the operation has completed. That means that while waiting for data to be available, actually needs a pointer to the buffer it’ll write the data into (unless 0 bytes have been requested, which we’ll talk more about in a bit). In .NET world, buffers are typically on the managed heap, which means they can be moved around by the GC, and thus in order to pass a pointer to such a buffer down to , that buffer needs to be “pinned,” telling the GC “do not move this.” For synchronous operations, such pinning is best accomplished with the C# keyword; for asynchronous operations, or something that wraps it (like and ) are the answers. So, on Windows, uses a for any buffers it supplies to the OS to span an asynchronous operation’s lifetime.</p>
<p style=display:none!important>For the last 20 years, though, it’s been overaggressive in doing so. There’s a buffer passed to various Win32 methods, including (), to represent the target IP address. Even though these are asynchronous operations, it turns out that data is only required as part of the synchronous part of the call to these APIs; only a operation (which is typically only used with connectionless protocols, and in particular UDP) that receives not only payload data but also the sender’s address actually needs the address buffer pinned over the lifetime of the operation. was pinning the buffer using a , and in fact doing so for the lifetime of the , even though a wasn’t actually needed at all for these calls, and a would suffice around just the Win32 call itself. The first PR fixed that, the net effect of which is that a that was previously pinning a buffer for the lifetime of every on Windows then only did so for s issuing calls. The second PR then fixed , using a native buffer instead of a managed one that would need to be permanently pinned. The primary benefit of these changes is that it helps to avoid a lot of fragmentation that can result at scale in the managed heap. We can see this most easily by looking at the runtime’s tracing, which I consume in this example via an :</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>When I run this on .NET 7 on Windows, I get this:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>When I run this on .NET 8, I get this:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>Nice.</p>
<p style=display:none!important>I mentioned UDP above, with . We’ve invested a lot over the last several years in making the networking stack in .NET very efficient… for TCP. While most of the improvements there accrue to UDP as well, UDP has additional costs that hadn’t been addressed and that made it suboptimal from a performance perspective. The primary issues there are now addressed in .NET 8, thanks to and . The key problem here with the UDP-related APIs, namely and , is that the API is based on but the core implementation is based on . Every call to , for example, would accept the provided and then call to produce a , which internally has its own ; that contains the address actually passed down to the underlying OS APIs. The inverse happens on the side: the received data includes an address that would be deserialized into an which is then returned to the consumer. You can see these allocations show up by profiling a simple repro:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>The .NET allocation profiler in Visual Studio shows this:</p>
<p style=display:none!important></p>
<p style=display:none!important>So for each send/receive pair, we see three es which in turn leads to three s, and an which in turn leads to an . These costs are very difficult to address efficiently purely in implementation, as they’re directly related to what’s surfaced in the corresponding APIs. Even so, with the exact same code, it does improve a bit in .NET 8:</p>
<p style=display:none!important></p>
<p style=display:none!important>So with zero code changes, we’ve managed to eliminate one of the allocations and its associated , and to shrink the size of the remaining instances (in part due to ). But, we can do much better…</p>
<p style=display:none!important>.NET 8 introduces a new set of overloads. In .NET 7, we had these:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>and now in .NET 8 we also have these:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>Key things to note:</p>
<ul style=display:none!important>
</ul>
<p style=display:none!important>Let’s change our code sample to use these new APIs:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>When I profile that, and again look for objects created at least once per iteration, I now see this:</p>
<p style=display:none!important></p>
<p style=display:none!important>That’s not a mistake; I didn’t accidentally crop the screenshot incorrectly. It’s empty because there are no allocations per iteration; the whole program incurs only three allocations as part of the up-front setup. We can see that more clearly with a standard BenchmarkDotNet repro:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<h2 id=tls style=display:none!important>TLS</h2>
<p style=display:none!important>Moving up the stack further, has received some love in this release. While in previous releases work was done to reduce allocation, .NET 8 sees it reduced further:</p>
<ul style=display:none!important>
</ul>
<p style=display:none!important>This benchmark repeatedly creates new s and performs handshakes:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>It shows an ~13% reduction in overall allocation as part of the lifecycle:</p>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important>My favorite improvement in .NET 8, though, is , which teaches to do “zero-byte reads” in order to minimize buffer use and pinning. This has been a long time coming, and is the result of multiple users of reporting significant heap fragmentation.</p>
<p style=display:none!important>When a read is issued to , it in turn needs to issue a read on the underlying ; the data it reads has a header, which gets peeled off, and then the remaining data is decrypted and stored into the user’s buffer. Since there’s manipulation of the data read from the underlying , including not giving all of it to the user, doesn’t just pass the user’s buffer to the underlying , but instead passes its own buffer down. That means it needs a buffer to pass. With performance improvements in recent .NET releases, rents said buffer on demand from the and returns it as soon as that temporary buffer has been drained of all the data read into it. There are two issues with this, though. On Windows, a buffer is being provided to , which needs to pin the buffer in order to give a pointer to that buffer to the Win32 overlapped I/O operation; that pinning means the GC can’t move the buffer on the heap, which can mean gaps end up being left on the heap that aren’t usable (aka “fragmentation”), and that in turn can lead to sporadic out-of-memory conditions. As noted earlier, the implementation on Linux and macOS doesn’t need to do such pinning, however there’s still a problem here. Imagine you have a thousand open connections, or a million open connections, all of which are sitting in a read waiting for data; even if there’s no pinning, if each of those connections has an that’s rented a buffer of any meaningful size, that’s a whole lot of wasted memory just sitting there.</p>
<p style=display:none!important>An answer to this that .NET has been making more and more use of over the last few years is “zero-byte reads.” If you need to read 100 bytes, rather than handing down your 100-byte buffer, at which point it needs to be pinned, you instead issue a read for 0 bytes, handing down an empty buffer, at which point nothing needs to be pinned. When there’s data available, that zero-byte read completes (without consuming anything), and then you issue the actual read for the 100 bytes, which is much more likely to be synchronously satisfiable at that point. As of .NET 6, is already capable of passing along zero-byte reads, e.g. if you do and it doesn’t have any data buffered already, it’ll in turn issue a zero-byte read on the underlying . However, today itself doesn’t zero-byte reads, e.g. if you do and it doesn’t have enough data buffered, it in turn will issue a non-zero-byte read, and we’re back to pinning per operation at the layer, plus needing a buffer to pass down, which means renting one.</p>
<p style=display:none!important> teaches how to create zero-byte reads. Now when you do and the doesn’t have enough data buffered, rather than immediately renting a buffer and passing that down, it instead issues a zero-byte read on the underlying . Only once that operation completes does it then proceed to actually rent a buffer and issue another read, this time with the rented buffer. The primary downside to this is a bit more overhead, in that it can lead to an extra syscall; however, our measurements show that overhead to largely be in the noise, with very meaningful upside in reduced fragmentation, working set reduction, and stability.</p>
<p style=display:none!important>The reduction on Windows is visible with this app, a variation of one showed earlier:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>On .NET 7, this outputs:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>whereas on .NET 8, I now get:</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<p style=display:none!important>So pretty.</p>
<h2 id=http style=display:none!important>HTTP</h2>
<p style=display:none!important>The primary consumer of in .NET itself is the HTTP stack, so let’s move up the stack now to , which has seen important gains of its own in .NET 8. As with , there were a bunch of improvements here that all joined to make for a measurable end-to-end improvement (many of the opportunities here were found as part of improving ):</p>
<ul style=display:none!important>
</ul>
<p style=display:none!important>We can use the following simple GET-request benchmark to how some of these changes accrue to reduced overheads with :</p>
<div style=display:none!important></div><pre tabindex=0 style=display:none!important></pre>
<div class="table-responsive notranslate" style=display:none!important></div>
<p style=display:none!important> also sees improvements in .NET 8. With , (the implementation that’s used by and that’s returned from ) gets in on the zero-byte reads game. In .NET 7, you could perform a zero-byte on , but doing so would still issue a to the underlying stream with the receive header buffer. That in turn could cause the underlying to rent and/or pin a buffer. By special-casing zero-byte reads now in .NET 8, can take advantage of any special-casing in the base stream, and hopefully make it so that when the actual read is performed, the data necessary to satisfy it synchronously is already available.</p>
<p style=display:none!important>And with , allocation with is reduced. This is a nice example of really needing to pay attention to defaults. has an optimization where it maintains a shared singleton that it reuses between instances. However, it can only reuse them when the settings of the match the settings of that shared singleton; by default is set, and that’s enough to knock it off the path that lets it use the shared handler. This PR adds a second shared singleton for when is set, such that requests using the default proxy can now use a shared handler rather than creating one a new.</p>
<h2 id=json>JSON<button aria-label="Copy Post URL" class=linkicon data-id-href=https://devblogs.microsoft.com/dotnet/performance-improvements-in-net-8/#json#json data-toggle=tooltip data-placement=right title data-original-title="Copy Post URL"><i class="fabric-icon fabric-icon--Link"></i><div class=screenreader-text aria-atomic=true aria-live=polite></div></button></h2>
<p>A significant focus for <code>System.Text.Json</code> in .NET 8 was on improving support for trimming and source-generated <code>JsonSerializer</code> implementations, as its usage ends up on critical code paths in a multitude of services and applications, including those that are a primary focus area for Native AOT. Thus, a lot of work went into adding features to the source generator that might otherwise prevent a developer from prefering to use it. <a href=https://github.com/dotnet/runtime/pull/79828 target=_blank>dotnet/runtime#79828</a>, for example, added support for <code>required</code> and <code>init</code> properties in C#, <a href=https://github.com/dotnet/runtime/pull/83631 target=_blank>dotnet/runtime#83631</a> added support for “unspeakable” types (such as the compiler-generated types used to implement iterator methods), and <a href=https://github.com/dotnet/runtime/pull/84768 target=_blank>dotnet/runtime#84768</a> added better support for boxed values. <a href=https://github.com/dotnet/runtime/pull/79397 target=_blank>dotnet/runtime#79397</a> also added support for weakly-typed but trimmer-safe <code>Serialize</code>/<code>Deserialize</code> methods, taking <code>JsonTypeInfo</code>, that make it possible for ASP.NET and other such consumers to cache JSON contract metadata appropriately. All of these improvements are functionally valuable on their own, but also accrue to the overall goals of reducing deployed binary size, improving startup time, and generally being able to be successful with Native AOT and gaining the benefits it brings.</p>
<p>Even with that focus, however, there were still some nice throughput-focused improvements that made their way into .NET 8. In particular, a key improvement in .NET 8 is that the <code>JsonSerializer</code> is now able to utilize generated “fast-path” methods even when streaming.</p>
<p>One of the main things the JSON source generator does is generate at build-time all of the things <code>JsonSerializer</code> would otherwise need reflection to access at run-time, e.g. discovering the shape of a type, all of its members, their names, attributes that control their serialization, and so on. With just that, however, the serializer would still be using generic routines to perform operations like serialization, just doing so without needing to use reflection. Instead, the source generator can emit a customized serialization routine specific to the data in question, in order to optimize writing it out. For example, given the following types:</p>
<div><div class=code-header><span class=language></span><button class="copybutton copy-button"><i class="fabric-icon fabric-icon--Copy" aria-hidden=true></i> Copy</button></div></div><pre tabindex=0><code class="language-C# hljs language-C" data-highlighted=yes>public <span class=hljs-class><span class=hljs-keyword>class</span> <span class=hljs-title>Rectangle</span>
{</span>
    public <span class=hljs-type>int</span> X, Y, Width, Height;
    public Color Color;
}

public <span class=hljs-class><span class=hljs-keyword>struct</span> <span class=hljs-title>Color</span>
{</span>
    public byte R, G, B, A;
}

[JsonSerializable(typeof(Rectangle))]
[JsonSourceGenerationOptions(IncludeFields = <span class=hljs-literal>true</span>)]
private partial <span class=hljs-class><span class=hljs-keyword>class</span> <span class=hljs-title>JsonContext</span> :</span> JsonSerializerContext { }</code></pre>
<p>the source generator will include the following serialization routines in the generated code:</p>
<div><div class=code-header><span class=language></span><button class="copybutton copy-button"><i class="fabric-icon fabric-icon--Copy" aria-hidden=true></i> Copy</button></div></div><pre tabindex=0><code class="language-C# hljs language-C" data-highlighted=yes>private <span class=hljs-type>void</span> <span class="hljs-title function_">RectangleSerializeHandler</span><span class=hljs-params>(global::System.Text.Json.Utf8JsonWriter writer, global::Tests.Rectangle? value)</span>
{
    <span class=hljs-keyword>if</span> (value == null)
    {
        writer.WriteNullValue();
        <span class=hljs-keyword>return</span>;
    }

    writer.WriteStartObject();

    writer.WriteNumber(PropName_X, ((global::Tests.Rectangle)value).X);
    writer.WriteNumber(PropName_Y, ((global::Tests.Rectangle)value).Y);
    writer.WriteNumber(PropName_Width, ((global::Tests.Rectangle)value).Width);
    writer.WriteNumber(PropName_Height, ((global::Tests.Rectangle)value).Height);
    writer.WritePropertyName(PropName_Color);
    ColorSerializeHandler(writer, ((global::Tests.Rectangle)value).Color);

    writer.WriteEndObject();
}

private <span class=hljs-type>void</span> <span class="hljs-title function_">ColorSerializeHandler</span><span class=hljs-params>(global::System.Text.Json.Utf8JsonWriter writer, global::Tests.Color value)</span>
{
    writer.WriteStartObject();

    writer.WriteNumber(PropName_R, value.R);
    writer.WriteNumber(PropName_G, value.G);
    writer.WriteNumber(PropName_B, value.B);
    writer.WriteNumber(PropName_A, value.A);

    writer.WriteEndObject();
}</code></pre>
<p>The serializer can then just invoke these routines to write the data directly to the <code>Utf8JsonWriter</code>.</p>
<p>However, in the past these routines weren’t used when serializing with one of the streaming routines (e.g. all of the <code>SerializeAsync</code> methods), in part because of the complexity of refactoring the implementation to accommodate them, but in larger part out of concern that an individual instance being serialized might need to write more data than should be buffered; these fast paths are synchronous-only today, and so can’t perform asynchronous flushes efficiently. This is particularly unfortunate because these streaming overloads are the primary ones used by ASP.NET, which means ASP.NET wasn’t benefiting from these fast paths. Thanks to <a href=https://github.com/dotnet/runtime/pull/78646 target=_blank>dotnet/runtime#78646</a>, in .NET 8 they now do benefit. The PR does the necessary refactoring internally and also puts in place various heuristics to minimize chances of over-buffering. The net result is these existing optimizations now kick in for a much broader array of use cases, including the primary ones higher in the stack, and the wins are significant.</p>
<div><div class=code-header><span class=language></span><button class="copybutton copy-button"><i class="fabric-icon fabric-icon--Copy" aria-hidden=true></i> Copy</button></div></div><pre tabindex=0><code class="language-C# hljs language-C" data-highlighted=yes><span class=hljs-comment>// dotnet run -c Release -f net7.0 --filter "*" --runtimes net7.0 net8.0</span>

using BenchmarkDotNet.Attributes;
using BenchmarkDotNet.Running;
using System.Text.Json;
using System.Text.Json.Serialization;

BenchmarkSwitcher.FromAssembly(typeof(Tests).Assembly).Run(args);

[HideColumns(<span class=hljs-string>"Error"</span>, <span class=hljs-string>"StdDev"</span>, <span class=hljs-string>"Median"</span>, <span class=hljs-string>"RatioSD"</span>)]
[MemoryDiagnoser(displayGenColumns: <span class=hljs-literal>false</span>)]
public partial <span class=hljs-class><span class=hljs-keyword>class</span> <span class=hljs-title>Tests</span>
{</span>
    private readonly Rectangle _data = new()
    {
        X = <span class=hljs-number>1</span>, Y = <span class=hljs-number>2</span>,
        Width = <span class=hljs-number>3</span>, Height = <span class=hljs-number>4</span>,
        Color = new Color { R = <span class=hljs-number>5</span>, G = <span class=hljs-number>6</span>, B = <span class=hljs-number>7</span>, A = <span class=hljs-number>8</span> }
    };

    [Benchmark]
    public <span class=hljs-type>void</span> <span class="hljs-title function_">Serialize</span><span class=hljs-params>()</span> =&gt; JsonSerializer.Serialize(Stream.Null, _data, JsonContext.Default.Rectangle);

    [Benchmark]
    public Task <span class="hljs-title function_">SerializeAsync</span><span class=hljs-params>()</span> =&gt; JsonSerializer.SerializeAsync(Stream.Null, _data, JsonContext.Default.Rectangle);

    public <span class=hljs-class><span class=hljs-keyword>class</span> <span class=hljs-title>Rectangle</span>
    {</span>
        public <span class=hljs-type>int</span> X, Y, Width, Height;
        public Color Color;
    }

    public <span class=hljs-class><span class=hljs-keyword>struct</span> <span class=hljs-title>Color</span>
    {</span>
        public byte R, G, B, A;
    }

    [JsonSerializable(typeof(Rectangle))]
    [JsonSourceGenerationOptions(IncludeFields = <span class=hljs-literal>true</span>)]
    private partial <span class=hljs-class><span class=hljs-keyword>class</span> <span class=hljs-title>JsonContext</span> :</span> JsonSerializerContext { }
}</code></pre>
<div class="table-responsive notranslate"><table>
<thead>
<tr>
<th>Method</th>
<th>Runtime</th>
<th style=text-align:right>Mean</th>
<th style=text-align:right>Ratio</th>
<th style=text-align:right>Allocated</th>
<th style=text-align:right>Alloc Ratio</th>
</tr>
</thead>
<tbody>
<tr>
<td>Serialize</td>
<td>.NET 7.0</td>
<td style=text-align:right>613.3 ns</td>
<td style=text-align:right>1.00</td>
<td style=text-align:right>488 B</td>
<td style=text-align:right>1.00</td>
</tr>
<tr>
<td>Serialize</td>
<td>.NET 8.0</td>
<td style=text-align:right>205.9 ns</td>
<td style=text-align:right>0.34</td>
<td style=text-align:right>–</td>
<td style=text-align:right>0.00</td>
</tr>
<tr>
<td></td>
<td></td>
<td style=text-align:right></td>
<td style=text-align:right></td>
<td style=text-align:right></td>
<td style=text-align:right></td>
</tr>
<tr>
<td>SerializeAsync</td>
<td>.NET 7.0</td>
<td style=text-align:right>654.2 ns</td>
<td style=text-align:right>1.00</td>
<td style=text-align:right>488 B</td>
<td style=text-align:right>1.00</td>
</tr>
<tr>
<td>SerializeAsync</td>
<td>.NET 8.0</td>
<td style=text-align:right>259.6 ns</td>
<td style=text-align:right>0.40</td>
<td style=text-align:right>32 B</td>
<td style=text-align:right>0.07</td>
</tr>
</tbody>
</table></div>
<p>The fast-path routines are better leveraged in additional scenarios now, as well. Another case where they weren’t used, even when not streaming, was when combining multiple source-generated contexts: if you have your <code>JsonSerializerContext</code>-derived type for your own types to be serialized, and someone passes to you another <code>JsonSerializerContext</code>-derived type for a type they’re giving you to serialize, you need to combine those contexts together into something you can give to <code>Serialize</code>. In doing so, however, the fast paths could get lost. <a href=https://github.com/dotnet/runtime/pull/80741 target=_blank>dotnet/runtime#80741</a> adds additional APIs and support to enable the fast paths to still be used.</p>
<p>Beyond <code>JsonSerializer</code>, there have been several other performance improvements. In <a href=https://github.com/dotnet/runtime/pull/88194 target=_blank>dotnet/runtime#88194</a>, for example, <code>JsonNode</code>‘s implementation is streamlined, including avoiding allocating a delegate while setting values into the node, and in <a href=https://github.com/dotnet/runtime/pull/85886 target=_blank>dotnet/runtime#85886</a>, <code>JsonNode.To</code> is improved via a one-line change that stops unnecessarily calling <code>Memory&lt;byte&gt;.ToArray()</code> in order to pass it to a method that accepts a <code>ReadOnlySpan&lt;byte&gt;</code>: <code>Memory&lt;byte&gt;.Span</code> can and should be used instead, saving on a potentially large array allocation and copy.</p>
<div><div class=code-header><span class=language></span><button class="copybutton copy-button"><i class="fabric-icon fabric-icon--Copy" aria-hidden=true></i> Copy</button></div></div><pre tabindex=0><code class="language-C# hljs language-C" data-highlighted=yes><span class=hljs-comment>// dotnet run -c Release -f net7.0 --filter "*" --runtimes net7.0 net8.0</span>

using BenchmarkDotNet.Attributes;
using BenchmarkDotNet.Running;
using System.Text.Json.Nodes;

BenchmarkSwitcher.FromAssembly(typeof(Tests).Assembly).Run(args);

[HideColumns(<span class=hljs-string>"Error"</span>, <span class=hljs-string>"StdDev"</span>, <span class=hljs-string>"Median"</span>, <span class=hljs-string>"RatioSD"</span>)]
[MemoryDiagnoser(displayGenColumns: <span class=hljs-literal>false</span>)]
public <span class=hljs-class><span class=hljs-keyword>class</span> <span class=hljs-title>Tests</span>
{</span>
    private readonly JsonNode _node = JsonNode.Parse(<span class=hljs-string>""</span><span class=hljs-string>"{ "</span>Name<span class=hljs-string>": "</span>Stephen<span class=hljs-string>" }"</span><span class=hljs-string>""</span>u8);

    [Benchmark]
    public <span class=hljs-built_in>string</span> <span class="hljs-title function_">ToJsonString</span><span class=hljs-params>()</span> =&gt; _node.ToString();
}</code></pre>
<div class="table-responsive notranslate"><table>
<thead>
<tr>
<th>Method</th>
<th>Runtime</th>
<th style=text-align:right>Mean</th>
<th style=text-align:right>Ratio</th>
<th style=text-align:right>Allocated</th>
<th style=text-align:right>Alloc Ratio</th>
</tr>
</thead>
<tbody>
<tr>
<td>ToJsonString</td>
<td>.NET 7.0</td>
<td style=text-align:right>244.5 ns</td>
<td style=text-align:right>1.00</td>
<td style=text-align:right>272 B</td>
<td style=text-align:right>1.00</td>
</tr>
<tr>
<td>ToJsonString</td>
<td>.NET 8.0</td>
<td style=text-align:right>189.6 ns</td>
<td style=text-align:right>0.78</td>
<td style=text-align:right>224 B</td>
<td style=text-align:right>0.82</td>
</tr>
</tbody>
</table></div>
<p>Lastly on the JSON front, there’s the new <a href=https://learn.microsoft.com/dotnet/fundamentals/code-analysis/quality-rules/ca1869 target=_blank>CA1869</a> analyzer added in <a href=https://github.com/dotnet/roslyn-analyzers/pull/6850 target=_blank>dotnet/roslyn-analyzers#6850</a>.</p>
<p><a class=lightbox-link aria-label="Lightbox image, click or press enter to enlarge" href=https://devblogs.microsoft.com/dotnet/wp-content/uploads/sites/10/2023/09/CA1869.png data-featherlight=image><img decoding=async src=data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAABnAAAADTCAMAAACGA616AAADAFBMVEX////09Pgrka/y8vft7vT7+v0eHh729vbq6vLMztsfHx/19fYAbL6ZmJjm5+eysrIrKyvs7Oy2trY6Ojr+//6VlJX29/dKSkpxcXHKysoCAAHMzMxtbW1VVVXa2trw8vTQ4+m30uiDg4NQpLwrlSs/m7YzmDXU1NTi/f8+nT+/2uN0Uh9LnbcvhsiVwOFJokukpKR3r9lWndJhrMKz1d+jzdn//uqjzaZYqVsFA//d5eX///UrkrXl5eyBuMrAv8AsmMKZyJwgN4Dv//+dytib0fr3///7/fu6ubrU8/8wMDDW5NxCQkKEvc5rscVosGtxtMg1lrOKwdGVxtTQ4tTHxsYxkrD+4rXb29v/9N3d3d2/7v+t0bFKor2vr67u8PCce8V1tnj/8M+LwY7//t3N/v+21brh4eFsvuqAvIPH3szd6vBPlbDh8OGCyfE/k6/o8+jIgyHQuLb71qex2fqvbBruyL/B2sa35P/0+vQ1NTVkZGQAS7B6e3v//s/Ozs5OAgDu9+46OzugoKCbbwuMjIx0U3xat9y92cBCVoyEa0T41Mb95schPJR+k7BIst+Vlq7ew8Crxea+rbIzqM2Rj5EiBgFql7Gxp7LxyoaMrtve1ul2dXNNTU314tMGCBUzPnzOBXPFr9qen7AEetZ8ULTds2IBAii9vr+cVCI0JP/G5fskgdCFJgC0mtJChcl1VjQmdMOAVx8AIYCwgDlIrtHhsU3UxuObaynLnD0FJ//q9/8vlv83BgECCFSAnb/RopB0soRNOX+hYH7zy/9MTEy7gIjhvZ5wDf8iW65zfqxsGgJ2T1KlrdZoaGj6yN1bW1vW1uKcN//Abf9ondOdpr0Jm+I1mdn+5/8xKhrXmv8gRKp6PH9iXFSHZCzBoWdGcq2Jjf/OcLyrRgGjf1gMYLhdMi4MGzCkdtLjvP98Zovggn8Oaf8CNpZ+dZOehYHMBIw4Z5zNP6sQKlKMUX9gYGDSN4R0fNTMH5h6ZVdjYP86h3+NrJckUP85exyLlGPbbUg2AABB8UlEQVR42uyab2wTZRzHH0+J8sY/yfPCnL5wMUsar5LoiyZNqzZXV9kSjRpdc2nmi6ZLGh3MrczwQhdfNFu6Vdi/ODbMtkIzhCHMpSBj4BYwCCgx0cAQDFtgQGAIDBPAFyb+nrsb12uvd+02ii6/Txh97rnf/fr8/97veUoQBEEQBEEQBEEQBEEQBEEQBEEQBEEQBEEQBEEQBEEQBEEQBEEQBLFmBYIgCIIUAfIYgiAIghQBFBwEQRCkKJBHEARBEKQIkP8WtHXi9vkxguQB3Xxi96SNIEXE1T6VOuElxJ+68XU5MYT2TaVmSgiy1MRTqRslPiLzy+7JVWNEIXL7VjsuGcubxsOiKH6xniyCxoamQFY6NJtIJG7dx9EjrcxcJmiojeM4T8DMZmmR3s8qQ+N2QRCaqs1ssnDsSiaTp5aJ4EgrsyoS3MD6pdrUZtEU6DNYF41GTzLBaYhGZzooyYayW/s6SE78n/M8/6ktLV1QEXJCpZVjRj4h/z5OqCISlBuWKoKzEwb/OlVwYM24u5kgy5jGI7HYgCY40uPWQ9o1Kgi9PnPBccwmbj7zEFGId3PAWpIfjtfAvPRNi2U6tInryjQJbbXbaz0BU5v8kKbOCcLfJy0eDjUIx21ET2OqpQUEx9QmA9eWZHKVdbMvPa010C3uMpIf0mowL33XojJSG7cn0yTYZrdXeqpNbXLDxoO7qoSSDOhTr4yZf68JUl10psSrxjGjkCbZuPZG24xGgHSB3yY3mv9Sxe9MEObTVoLT8yXPsFSm+Df8pNfAZ/wnlm8G7Zv5nef/erUoo+nhR3xkobgGo21qxejj8L41pGbHZxN3PyLIsqbxsCY4E2KYWNHYMCwvomaC40/c3KxNlHEQgnwFx9UJy5q9kvOsI2bkEJNQ21IIjqNOGG4ByXnWNPKjBmJC5SCnqdrMJgMK73jmdb1ftHZDv+QpONSxiXPba6BfhogJFBb+LoP6Bjd4qq1sjJE2wXgAqQvTjG9ydbrLLL83F4PRG0Oap1FDZXljb/QEJVlQ/+f9/KSPqIENE4T5tLmOvBG5VAEKsq2iouJbU0NZcAx8Bq0Eh/Yc5PufBMm5aOp/ifjVGSALhUaY4Kg8uiV5SpXIFdJs4rxpHZH/PYUKTmRkPAWyYiY4rtnELh9Jpz5fwYl3M6npe6LZYs4Yb5eF2pZiSy0y0rQeypDqtRj6fYbbZUxwrGzScO1KbiQPCldnnoID4RC0LO07+ZJ5m9C+jK0tTXCsbAyh7ZUgca52iFxNi16ITxbg6LbKgnX7jEKcHrYoZjPY/9Y3n9oKFxxCKYtydpo3oFKXMQOfkG+xpQZS+PIYofGfi/ICsxjBISDmPm2O3NFeueKJmxjiLG8KFBw6ONwB/4iJ4NDGzFFD8xac1touyxmZEwqCs4hZME+PMO5TV4jCUSKc/JHuJE0DqfsJzV9wPuE2LnwHhQlOIW2iIW1ys4ED8ZU6MBegldlEGm6Up7tKW/50OjRjEM456r5/oe779QsQHELyExygIJ9ayfgXwflCBu1CWIzghPQSvyUpB7DqZvx3xaoBsnhCR0Tx2HMTh8Q5tuvtqG8SxTnlRV2qvzogwk2YaT8OvAxZkUOQ1gSHZYgKcK2z1xGC8AaCHNlna2pEuP4hiExG2p/1ewFFcBzvj9dynLLR5Wrv5riqDp8sMs1w4W62yWlNMsC+u5IrXeWTVxzO81F9LVe1Tr4Amn2qZ9jiX+XVRzg6G/DJyXgCuX2m0yNcTSvDxDlh+CsoJzuPEY6vmYJqDskXQC+RqROE4c/ARBfh6GzApwLc03wqp6b3fi/gOgJtPw3Zyo85vl0zMSBOD7HV/qooTn94+KzJov2DM3xlh9MZ9hJgBUv+U0ZZ9gH4u+Y9fXS/7mH9qi291s2aaI9Nf2byCRdur+HcL42xtHYKI9tUuqs6wEbaCt25ZjW04ZB8AYRVz9Avz3f49IKjswH/CnAvl094MKCYdnnl8kDh3i5n19qzaT5zl19Xx57oSfZhEcs4Ro1+MhCE8GawP2wqONIU7G3NDVFCBvmN8DfpjRyEm5rggBee3/lxiu+fLocvusDzl2MldP4Gv22tzmdm/t5tawcP8pflYJNGBHDyHhQKzngUHcwsA5R46ss/39vOHysHm4uj82kSYt879wIljL6pSzywR6+8kYO8QsZu3hmnyjUvOX3U6Tzw8G/wH5T1N2eZfPsA83P6DBuHBqrtbzgcIBq/JE/d+9ofE+eVNB0sTJyRB4FjAn4D8MGh2IB4NkBcE6IYi4kik5cQW8xisdh0bsFpbYLHmM1cQGevJ779eHlw33WW7d8OZx0jn+1rCujTJDI/aPQRTghW+Hfsdjub9K76SrY3715L5ahmwztwbrOHlXMr53ndSwDVBvJBNhyd9lrP17WltZynnF3Ya1QxcUG6lq0j+giHajbyYQUAjwZy+0wn2CA83eGbX3WU85xeJrUtI01TUEvheDW7gOxe1aYFMoVxrz7C0dlEWgCwgnuaT3Wy0XtvCzHoAXE3+JGOxAbOfiDC5TEb9BR0xcDcH+aCc+3o/h1OZaLD5N/B1Aem/I5rtivO/Tb2SVQyIxzKFuxStV8cnZzcL2Xygl21obQG2oqyk3/Oc69NOpXznDCLQKANV1dC43bZ4IK1eVg985H7pdmbITiaDfi3q/1SndNnaw34BdgnK0836zuWhOfkMldV630al19fR5J5OuNvMBAcGv+XvasPjqq64mtCZjIdtdW5dTr7R0G7rlmjbhXN1yapATc7S6am0JTM1jhOCGRCKoG4mw9mlJE2aCJJ+FADcWwSWwabRIaQACV8hUHGKB/TEWQoyIwg1IwMH3VwnFax7e/ce/fdfW/zXjblQ8A9MJv7zjvv3PPefXt+75x77tuaUTJtLLjjSH5wxztTLQAnUIOplDb7zpAAmM2YU6G/OsDpRj3AIEltmGoLdE+b1mbv5DfrLGobAcfA32z/5sWRo/bOCsanbUamtX1DchLUjDYAcN5u6rdffHNHZwUAZ6QpldpQRToh0lmRTz3ts9t/hOklGKGIFy5IeiRyB/uc7q+tPT092wE4B3syzx7K5DefDnCSDvL7EBwjNde8slLpY3jokl955TtYWo19wOKGj9N1QSwp7b2WEyE268sWr61498chBhwBoKDdgrYgBTjmKTUlb6D2/jfy0wYpTcwGU/f6yXsCZFTbCDgqwqF5ANETo7mabC8TuXkATnZVvq32WQ4WHcuBSjO2oSXkARfgUzySPbkefk8mUlbMjPhqdPyZ1OsinGiZVQA3a50aFW9BkdqBFHG6Z3pxQt04LwpZ9t/TC8iVSfK1BBnqO9Tn1Uc4Ohl0TWr6Vhp1AnB0fS/FyJE8hgXRTfHxlnoEPutTAEFTrAEnExENsGUOtbf68dmDdtL7Z1OOfdvjp0hHkSHCqZ2vSgFwfUKEygQCtfDbjGGMqN+OVoQTVE0n5Rkk5/CQJXtyL4aTDy2OjMh9sY5WqNcBjpJRHWZ7zXUqwMEObo+NlIZN1+m0tJ/0q0FpOKAf7xqthkA9uW1s2HJgavQVG4SrDqw757cAnPa2gV4kuIAzYL6zuPr3H/s3I9JRgCNClosn/ACJAaGJFYfjExxpBBwDfzNwhHk227EPQQq+y4EatKGbCxttQE8DvcUvHllYDRua953zB3csw46KMIC+OPAU6RxfpQGLTKkxxM9fp9AN548EHHyexf3yOUVBBmLDNQ2nV/vDmwAcrR3UsiPBPz58GVncOF0jQmjyyFR8tngBH+Rw8aeKA8iMbeMDHMgbiUp64DPJjebD/aIJTwvHqdpWEQ58C3ksCQaviXimiqfR/BpYMJ5r494BToTRn2yvKJOiqGR1NOCoLWYOOHBTVVzZTHOdkmjHMAKQ82TDYOpDxADCihzZG/SJDWJqgKO2dBGOUSa4BRfJqNMIOAyjxsfxXYwFDU6IHh74iFgDDoUwSZQ5Y8cyq2w8zgnhIXPrnEMV79cj42aLJqYBzsptmuNexgggOB+xRBgsGEv7zbNIdfVqrh5/QiJHVkWfRsAJb1kDDlu6CsrMdRoABxuMwUTNdKNOsj8/2n55jiaAw0YBnNnVDRfunMRsRgqcgn+G6/eaAw68OV1DQhA4+OcXdF/a3YssWBTgQAeBgd8IMx4TwPEowIESvg+dAFegdocCHKMNvI/iF5elKcCpUIAjzwU6z00an3tXgENJtRB96gEHEvVcEGwjBZ77pIGyahaAE5/JuTEIgFMlveZ7UyRVgL2rC/m1VXfnxwg4aZq8IlUWEOzem8KbkqPaVhFO2qszkdf4FXQS42UxjVIlCgVUdMKY5z7kb+ZAPEESZBQs6MHEc9/h+QiJoM0ywoELo+yOtU5FzOcZ3pJ6fg5VSEuCoICa6OjFM7wRGbX+1DcsIhxQ8xa+fkmnU5dS86ygabMuAI4YFmnbLJFLmzVGSm27TQAOIY0kLwGO/6D3oPcY2gZSEU5gNY1L7v2MGAkV/HIJh71MgQW3r1VkzhIEQYZEgRFGx0+yQzQuYwFORyt/qDDVaQAc2BPGkdEAx8J+dY4xptRYYLjhtDozBSuIBODbj+SbA84pAANhCXf2z8/b/+j+UPXOUBTgALkEpQ2n2kE4KtYIZ5ncJz5kO7iDx116G6wAJ20Y0zadYlXRrG40u4bGUSGmAxwNUxTgEAwJgqCBAOeHf6dchCGlNj7gi9N3S2kU2xDRFM6J5Zx4Krrj1fNwZw+mxAY4TMnrKNjfxycjXnrKAnBU0QDSIv6IKrWOXwyJCRfGAYcpwNFFJyLygfOYnJt7GP9C0DA64CBhkg2hoQTrCCeMN9Y69bSIcmSe6r4ltxH9IWQAHBW9+NamktCWMSKcWTUCb5hepyoawHi17F2+/IwGOKIvJpCGxQw4SYcyvz7JqZccQP379YcqjmWGDVeOXIUJrOMvQ3zCxdxhE4nIgWBaXkPo12IbY6QxM/vJ3NzWMQAH+VM+g2Cqs1nkPhmBTAyAw8zt184RzZiKBtioRQNraSENX5BpBjgswtnD8Q807p7UPaNmoDcKcFRsYx95YcmSfeOIcKIBR180wGIBHHxcfGHJPfs44DAfrxp4uyK2ooFYAAdTOCcFGSIcY9FAEh66NO3DccC5sYiSaRp8YKaPgbRbdulx7IwCHO2AcBJOyb8U3qee2AUhObQI7lem0XRt3OdaWfRs8aw6G8Ci6UQSRaXUDBGOJAFEHJTCNDrgzIZrUlvQoYQUF8fKqgJKqZnr1BPyZ9g5qAGGaYSzCCettrCphBTXFtgoqwoMOlEW3atFMk/hi6+l1AA4kt8SiiGlpiKcYyp/hra3Z86x7YcMT5nwwrwUUbtezFOL2S2VUhsdcMiRw9Vrg2kGOLK6jLZUdwaZyOcAU53UoQhMXw4jjUipEeDwIyxTasp+dY5oBBteN5ZFwwwjBapf0aG0BAdBO+sFIAjUUG19OgvtgbyPF1RvOkXBx+iAgwOxE5LGCEfptIpwICBTaphlh/LYU2pBOkilB0GetW0wRSPzogEBOPXWgAMJswVBi9SlFe/a0GrusYTvT/Fk2o1ECnBoxplKQhWx5i8F4HzQS5PQAByRg/so3+a5hfbTnmh5UGDLCSG8kXtT1o7CaE9EoUBEG3vTtLsGjmSTX79wj5yBsWhARTgrHiOLAUpCRs4jmUU48qDAamwJoYQKcS5KhqfyYASRpc5Z3esFKg3zbH+QA0ewf/8TQt4swkFIc2YOjt4oIxwA1UPCBiUDEwdTW4V2vc4kLPysCEcyH0BP87vGCCcttqIBBTh7ejK9+ZL/eebJb1P2nD24NUXJahCMOOS1sE7WgTl6/aS7ctgYwUdhMZMlF5iLmzom4MyhAGZmhRSiGTRPkpLhXPUcYKIT6CIXfoKhFQ0Am0iLfI+EVdGAtF9/jsaVnixAm1HkCzb8WO99FUx4BnlhNEMEAYs8+fq2mrCH4M7/Pjh18xf7/pFiATi0s3mdIcLR6zSJcAKqaIAK6DrXk860CZE2WADOrVMJkxTgsPa2c2OsU9YIcfT2qdGAQ1xsE+BQCUv96NGKT7fyKaAWfrJZ8YWfNxQ1n2nqQik0KmsFfkzBRtODPJ5pQUusq2n+EuyuVS9NORHi/pWO6KpAS+xBWy/PMwl2IdAtlqgUd5/3m5dF24J4JVLYd6DcVSt/nv4A2nAUxrJoFeE8h8Q/ZOCJeL4sIRtHoFy6eYiXwaIFWvEAqYGuTX48+j6ee/jZJ1unTw6JhemQml+lk4F+MIlC5jr599iOA8WyGqpn5hEJQ0jXh60hnCIyidgxJC7IK2DSntaU2dWpP7ntdP+l7r4l/HriCEh6dTK2djCJ3gzpdFJN6Jo1ft5AmcAXree7Vh1v2RsqfomP4yN8hyiLTgin1IJtA7xhAjhylQSVrHJ+D1bh9BirouG2cRm08uF7xbhElUUrwCE2ZBCRiLGja/gyPRnwa4gWsbVrngIsuTd3aH7uqulP1gs8oHHx6mSgH0zQ0/UmOtX9g5keWeaMsmgCSRLDHqNOE/t15yhe5aUcK7YUsihioywHhZPeoMqbKTygd8lQtKPaupJk2+bOo0fy238AcR3gBD87CplpApxP2buWvDJyacfIXr9ncBqVSI8gotDp1/EV4Ghl0QhWeIBix9ZRCm6UDWaAAz767Ru51HYRz4qDVBSNw4/EnM/aw28yRM578IlWVZiL6vyTclGOEMEeHRmSmB71ahta9/mp+j7eGrMxcfqOqPn4FCL5sia29MJubK3HVm0T8ZuG/Jx9ZkrLR0uPTxHhS9ouCDWJEsQOOqAFbSUv9KIaJhzZaJEOq6XFnvfzF92otrxv/vUhV5gUuBNf/5+FGDkAfOHhJH7JbVALP1WEw1+eAiGs5OQn4BNb8CPNEAZBDgRUEYT5ocAP5ydMf3jeclEFgGV/OODeqvxIGejXJqSVzm06nSq1QadyGmjT9yZPszBf7el+bOG0g/gLkoCTKmlvCoKbflRR04ui+fUMYG1o379X6mXaZXN/SKcTGwhx1ogK9OYLWAeVS0PolYtwHxfDKBZ+SsBh7aqCdVTAASVjBYRYk/P3nsztYOPDQB2rMS6TezlK83F5ega0qoWTeofNfirGBUuktEqNbMSPS8EFLZNRhiR49Q5ITJ9BsCauyZ2E816djFr4WW+q02hPeOGnGEgqS9DrNLHfcI6IaRpev5/JDtaO+k5oNlqizTMoq7vIcYtEaRvm2kM2fVstugTCdFbgzuIQoQCHiRd5Ci7rwIT9xYcgtLMeSCCJ5JROHV8BDhWs0MLPWrS1l3diDWm+ssEccFhzP/p9DNM0O5/yDJJBI11PxL7Uku35OhPoUo9AhlOFYGPN8VYvWFv9tMFF8FBppHaV1MSr1NZ4ZTuwK+IljNXjQL84XRfEmPyL/zo+38esXt4idlhpjBBi+jYoQD9PYPl7OCZdh/VbCnGysNbyKEudLAYWU1ylj/l8zNBNpIyVgQEgzpojKRb2gcPn3ATgbLYf4dyYzivJcu+YxFTL/ATMrzhjVptj6GCR7TCA6Hjj1xlmN1c3iGU2xRvRWJk/mkx7Q8OFXXdHsVn0pfHZRm+PYYV+NzMVhM4xqL0NgZekGC6A7IrFJn3FadGuTxrC0ePf1uPml4gU/Oqtt/75obSBpqRifB1WnG4Esv6iXi5hfvarq/p7ODcTef760Ttj/R4O63h3yiMylW8f84V3NyfVJlyx15z60oY3yt/D2fLzSSZ+fq317+FcN8SWruu8kXwz/dCQ/O0PFGm+87LMviMR/9WnydpJzT6185q8hDRONwVdXTz7flGwib/yZoNfAE4NZnmjaeG8xUz40gUL7gqzFmosH2+wCNZiyVoMlhSXLN/iBQuZuVLF8hn6uQssqVSxNKXzjErRz10W/UQZvyJh07U1fuF9v82/UsZfpSu/lmq07fYNk67qlb/CxuOnjDjLp6LwaFq0Lv5mmzjF6dpTUpDm2E4ckPEinvzqo2TYPLfD0egjR1DmdMydx9AqcjqcdcRaMNfhKFsAlq/S6XBX+ki81OHIW0yscqcjo8iHxrwMh6NkITmCdKejsICkCqC0nCvNczpKhVKXwyGUljkcc0kpg1KXQWkj+inirEKHI50rLUE/Qin14wNrMfUjlEYbj36clQbjExK+uXzjG/9f44vCxpfHZPzlX/nGWK78fzDHM63p12MZP54r78SVv2zjY7pt8mwWVLxvHG/KjtO1p8Q43dx0i/jT0d3iT4yiQldjhqP8mcTby1xzy1ylBRMn1rncdW5X44TErLmusrnOsqzEiY1Od7nbXTchsaDUlVfqzLsjcUKJM6PEnVE5cWJRhiu90JH+TOId6c7CPFdh0cSJlRmu8gxHCZTmOUvzNKUZznKhtMw5F0rrnO5G9BNWWnZ74sRyKOX9FBVypXckPlPiLEwP91NSSErvgFLZjztu/NUxPu/6Nj490YKCnz04ITFO1y3ZkuP0PabCxuSsDGdJAX2bc8qcpUXlLndRMtxBeRG+41k5cB0F5U6w6tzu8ko4jpysUkdeVgkefnPK3Rl1lYWukpwsuI4sOI6CnHRXYWUdDs7JynCkF0BfVg5cR1Gj212ZXED9QB/1M7eA91MJpUVQmpVF/UBpUXKjO6MRStNJaZ5QWuLKqINS2Q+8kegHSq+V8XUxGV9wfRofceVvNzf++r/yyviC5DjdsBQHnO811eUk01e6FI4jORlf6VKXuxJsPG0WusrAgj8qJceR/D/27q6ljSyO47g7Vo+nQbcurai7dkbTKA7qqlEiwlQCXhTapPUJShETKRiqLOydFyJeSKF7K3iTuBQEYa8ScuVr2L1YDOQt9CX0vv9zJmY0jzNp0uLp7wNNx5PkP4GB+WYGael89PvL8bBY2n7yTpxduyz6skpfVGkCnTrejb4US6HxBTrFiKWFJ9uj22KJvr+KE0eXOB/Z+7HEfuTQfTH0bWHoqBxKX4oXxsM9cujbG/vZlEPFfopDd/Dhm/Xh1+/Uh4e7q+0n+IG1i4eezfBOTGzo++HQYrtY/iMU3pdLsQ/h0J/ylc9D4V17aScc6pUvXw+F1nW5tBneLC49l0u9xaG710N7QuEP9hIN7ZH7X7zejy6GFvfjDC3bz469tEv7wYf/UT883FltcMd1WNyjxY7SGQ+tHAcAaLqchV89VshDz73hPFU6A7kBgBbJdbSBMjhvZ57onJeMoGbFGABAs/XpOb7YBsrgnHlUFpwc1xkAQPP5dJ5rA2U0ITjeRwAAuEMnHFBG9Vr43iyN6fR33eNffQQAwNdBcFRSrRb62PHhwWGCtuoefwQHAFoFwVGJrEXl3FwNnSE4APBdITgqqVyLpRHKzdBQdy9t1z3+CA4AtAqCo5LKtdj6f2joaqh/yUfbdY8/ggMArYLgqKR6cOgCJ8FI3eOP4ABAqyA4KqlYi9jxZ3mBozNS9/gjOADQKgiOSirVIvZL/9Xng4PjBBPqHn8EBwBaBcFRCecVenN29f6fgYGEzkj944/gAECrIDgquVWLvZPhPZ/szVj1fx0NwQGAbwbBUcmNWvhOZicnZ4d/rt0bBAcAvh0ERyWcO73JTObz2cxfJb3Rpx8VJBoLjm7d8zEAgAYgOCrh3OnNp+yUmcz++99RjN30uLtfGFlq6Aqn3TqPn6eQHABoBIKjElkLuzeZ2WzmxEhmM8MldXjdXeyN1+D4rMv4xcUFJQf/hQEAeIfgqITzYm+mzBm7OPk9dlvstL9/gDUQnK7LtKiNfLCQHADwCsFRCedOb0wzScUxMxmTlYg9Gqh+/KsG515KliaVSl3GaePSwn01APAGwVEJ59e9GZ6aMgy6xkmK4NTgNjg+61zmhhSSk27afbU+IxBlN/jpJ1OLsMb5/az11rR55pgTPz3VDNawOW2VfUdbnb2sltO/a/yyI4A7CI5KZC0M2ZvkybBJd9Wy2WQXq8FtcFhaXNWkrl2KH62SStTl10iFkDQSnKhGouXLUS/BEZWoZ04jTki+KjjGikbmy5fn3Qbn7OPG4DRzJAaPWQVL9zs7O719IfAQnKPBbgbQCARHJaIWvqlsUvaGrnFOJj/ljZq3vtwGp8/+bYFLOzfn6QvvwbEbYtYJiatRbFnz2wUzvb/XW3DshjytHRJ3o1hQW5WvDLJbfG7ea1safMM2Bl87C1f9rFzf9P0jxt53jjEPPASHiuNpNACCoyJZi5nslOwN/cln80bt77lug8Pi8XRcJqeQm3Taa3DcXna4GFW8/oloptf3Mk+VcHXZ4W6Uc/0zEfT8Xpv+YoseXxwWF37tTLAKtnRGHhwzD7wEh139xgAagOCoRNSiL5nNz7jtjevg9MXjlnVOyaHuiNykuioFZ5luGAUMuUGWZRqWI2KzpAX+wlokYAa0iBGIyHgQU75Qvo+GSP7Cc1F7XJQWon7nZpzYmSmej4gtwZQTnIHOhygs+m+f6YO09IoVNgJ7Ig2BvQmxebsFc9dPT7xa0zRjTfZjghaD9ij5PhoirRaem5fjzBVt1VihNedmXDAonzfEbuUMOcEZ6HyIwuKqfYHDxCVO2QXO2Mcb5fH57CdHiisb4hbbM/qbHuSPR/RASyIijx88O6WNrS/snc9qG1cUh4tIdWUJuVEbBDWICA8mILxwcu1NQfFGi2AqoSi4Syf7voFFEBT6AgVvaoeCV10ZsvJbhAb6QD3nzG907mhqaTSO1EQ9H8zkzrl/ZuLAfDl37oxJOHxA0brTEnPBJRIOghNLcYyimHA2CbFFh57b5PVNbuE4Ek6lkryHQ8WscJBvDNvODbjQYwV0SlGfK3oIhprgir29Dh9zS9bAYK+twiGkq4SpURQPh/aoppoeBTGe9MU+oirunr4IDg5C4Ui+0X5O20sv0mnzvf5lmyr2fpagagLV+5HnY2k54o7DQDgMug650SgeDu1RTTWegjIe+vKed0N014vACWigq5Zjdk6nT3COUZqwcBQVDozBgmF9nFwl2coZx8blBkmkVUeGQ7sXbJWrGlVNEj99KG9zS+pzWqXjM6pw5T+dYSyPCWeTkAznMS2H/vtpPt/kFk6ThcNcv7npVrpcmBWObEIvSSY6fK+HYWhHZWEQJfs+WUIFAs9AOAjEKQyPiuG0Mg7SNsDpVDg4FMPoReiZVDi8uRqrJrbFnufJrxEMQzspu1qcoMh+nyyhAhHPqHAkgBSG8BhOKxH0SGh8IBw5lHMNg4vgM+mMmsyp1XRGTTOcGY6nUhBPOFHMRbnBRqnTRjHe00YqEeFwhbZnxqSes+qEiyfUikRlc2rGfTDhbBKxLSq/v3//7OmzPL7JLRzKcCoVFs1tnN80shkO0geoBF7A05YownRWBL/AFWQFDaCkwkGaQuOhjodDz5RweqGs1H5ooBfB26xw5OYOlcAe/LRFn9/sk3LUL96LFTSAkgpH0hQZD3UynPRU4dTgN5WV2g9t9SJ4Y17vfO+Ytz9CON985+7McJ5Ud8PHL7CL5Cxn1W32C4wCy3AAQXdeD3p+uKqhKO5BxS+2SNoogAlnk4ht0Xzc/o3oVOauT1tOOMhwGrFwGuSef8lwOvIER8pqiJ4TBSV+kPs/IOFw+yaE0+dYWjh9+SNC+2S4XirDgX9EKyocGlOtpxfR0yc4upa5NEQZhmALIKcRfMlLM4GFM0RD+KgUCgczYhQAGI4No8KBf0QrKhweU62nF+HJeSqc5kFaOI3znZhxuFBNfSPKYE7qYhg5vijHsHBeQDgsFXRIHuJQAPaRunN+gsN8a8IximDC2SSmtmi6Wo12i8krHM5wBBEOkc1wIJTBPOFQLIpj+ghGGnLXaCbD4X3iD0HD+gwnciqc3mLhiNb6KeHI/fwoKxwXPuUfSQyocKjrKJPhPJ/6Q9CwPsMZSZaDunnC4YuA1trTDOdgcYbzF2cyWeGwV7bFMDo7dodwTlgtFynhSGNykAnHKIoJZ5OY8yE0Ice//9wMpwHhdGcyHJgCOUmil8y9HorRGTTNcEQSGeFEVB32RhgTY6qqHpKdu6bUwovQ1QtwBnKSRC+p5EIVM/vMXzUzIxw899feCGNiTFVFQSQ7d0yp6UXIn36a4cxOqWWf4Twsqw/CKTXZ0Yya+EWFk51SQzGYUhtDRqfVuk2pGUUx4WwSW1s5ZtFCanmFg1VqmuF0NcNRE0ihLwaATcLZrKliBrTNZDi8iR5C4fQxKI2np8FJtD8WDcioUFG4aIACehE6nJoAE1tiANhEk4vDNhRDR8OMcGAhnxLOPgbl8fQ0OIn299yBR4WKdNGAnDm8iGS4ZNHA2/SigWyG86v6RhcBwCHjq3FdNFPPCEcXDUxENVgpUN6WVlQUzllAF7ZowCiCCWeT+GFraT7mEk6TMpzry+50Sq1Ln1NT4SQ3c99mBeiy6F5wrxcX6FppLvbTGY7oKRQOJtSSLwq0fRzOfGmgR71gJx5wZll0J7gIGgMX827nNW7mh0MogHMIaEKTC3EB1krHxXY6wxlyRSAcTKhNvyjwCurIfGnAUy/YiQfUZdFYKacXQWPw1c1dFp1+D0df+Uwti47F8u7hRGJyOG6ocHRZdF1KWAvtznl30mL38DBVWxZtFMaEs0l8fbm1JB+buYTjmiQYVo4Ip3t5zUcVJ+iT+AjvfabfuZz6KEKQUxq01AxHYnudYEqN2guxwQj1l36XDbNmkYwscX3xc4DOehHxiSMnwvEl3P/x3qe+c6nJBao9ZsLQUoUjsWE4pSbtOYgvp8Ff2e+yeX8oIyPuZQR0GqYvQk48cvripxOyX7bRGTVBv21zVo1f2NRUhZVC1MMMR98QJS64EOc559yZihTDMJOd+Z8lMIwAE86G8ujRV/cFwsnQfMDKubkl4cS6WcmvJyg0Zq8094PYy0FXkDN4T7yXkZc6Rd5P2+Qnz8KSEHsNx7gXJhwjl3D4lnh78wZcf06/ZfqTCmdteF/gRxh/vNO5RSnOirEExyiICcfIKRyidnkjac7iF0rXyZcqHFeAgz9Od071sNY4WeoLnZ+GyY49wTGKYcIx8gvHuWb39rLA/8xXypcqnM/t52gYK8eEYywjHFez2+Qnwn6Qxv8PE46xlHAMwzCKYsIxTDiGYawFE45hwjEMYy2YcAwTjmEYa8GEY5hwDMNYCyYcw4RjGMZaMOEYBYTTagXFmlN2+ai661bEbtmtghZ/dkx5Ul3Ri4390qFTjvhoWHrgCnNUeuWWgT+bZhj/ISYcI4dwjqvHWeEctD4b4eze64zBX6F8vEA4bIlFHJWYrEiaBYTT+YnHOsyGD004xpfHP+ydy2rcSBSGIRgJumkzydZoDNKiIKsCTbatJzC4EfbOmffwZhbzDNnZez+Nn2nOOfWrT0lWnI4dK27m/6Clupy6ZKOPqpJiCoe8QDiQy1zZb/mesXqVcFaxBOFXCCc55PJ5kRzWVdl86C2yfUHbAQqHvBsoHELh/FLhHLzs+HFXvv7ZtT/ddoDCIe8HCoccKpxY6GFHsU4P+FAoD5LUek13+y21iFoLDiu5pwe7NQBa65ooYie1EftmlqrTSFWqLuGzFJsiMK5clZAGjTbdUFvJ0F2l87BYkE2gRgJJiRXhROtJqTBpf9Ljr/FsSyRuzlUNN+c7S1qER6N6t72QTbYL88dOClt0pe2kE6NH3V/Wneyl9Z+v+/z0p2m1XvuwFm3qwTv0SaDQzfco/4o7COdbIZwOpZv9nZA3h8IhhwunCvoAXqtw8PRHsii1Orhw0Crq5UGKTQea69BjLYkg9aCoaouHYkJRqzVMC0G9Elw4HoshMQm5WminlVVng1q0XGweKPK5oXJmhaP9RUuvMFYuHFtvfL6Q33Vr0jnRZ/21XHc351bomkD1rmk1b5G9NtxmwlHQdKtBfeoO8aiWmkYKrT+01atetmjuk8AA/X5lo38WOibhXGn68f6j/rFoqfpX7lLy52/4X6fJ/w8KhxwunGjJh6lwQBEnwilSBnVRTDXGohFaDKf3UVMWbLqqKhVLtW+Qx/rYlvBkp5pQw6GF4PNISARCZoWz1tgaM5RrLhz7GQ0WE61ufvUwjFwsrVrph+tOLOECMc+MhXOJJYzQoDuvRGEjMRjOhWNZKMwngZHA4916sqV2tTorr4p/9mlCFoHCIYcLJ5RYljwVDlIuHCwnbJ1isR12pjLiai+cOrUYJBIkWPuqYy35Krpwslj5ZUN7iEkRgTCMz8OzaDgnnJiUZs0R7cJJD3eoBPbAaQvOb3aiHPdL05oVvAApFw6WKdIf6rQ7tHThwG8uK7cfAnwS+lPgmU/5GQ6K5LdBmttpZCEoHHK4cCw9IxwcprhwUlE0pxRGJZHFSDk440lILARUgAfLrbqugAbgizw2SFwunICRRBAo7dA0nwdao8PvvzRQV5IHg3BgCTnBQRqGgDigDF2MtBZmqHC2CByOVybC2aXTH4DuYBj4BP4xrbhw0Ces55No1Hng6+rMhTMc4nyy+8byPMEhC0HhkNcLJxTF0xVOUfmTHazcMFXReWUuEUsN31+GlfQdxDnzwjHR+RnOyo50JsIJk8XUTwpHUo5LppGz/eeEI2W9lYFMOI3UTFc4l3t/GF7sZzi9CQd1PxaOae1kEM6pC0dyd2td4eCtgTPcua1GFoDCIa8XDlK5cHA+j2e/O6RGh1I7L5z8OCbGWq91/V3h4Gy/qq0EIS4cGCSfx0FbahAOxnLgDKxJBr1Mn/VQzPTM3zUzEQ7O/b01irEx5qrSQvPO/JbaeBL+9sLVaIVzu8l32W7vP+L+d0nIW0PhkBcLR/KaRDbkW2rYUMPpPPCP+tFX9XRLDSdF0Eulw9ZVfEY4QbLWLbRX5MLRmnI6D2QhmIlw4lg49TDDsQmw+lADwCb+rP9yAsXgrGcsHFioGQlnh07RH4bBIN6+0QbaK1Q0fmmgnwrHu7v1lwagmq8rCOdbcbq/E/LWUDjkpcLRVYomsZoZn+EUFZrGtN4JZez2j3L4qJ45w8FLaKG2UdM70XKdF05l6kJGLrrWGQkHGizrbB75a9FS6cJBk1w4eGGtQwAe5l+2UICsIfBcz4WjLsC70il5Ml7hbLUiEw421EwgrUZBHU/+p4FGWsFO1qG/Fg3t+CSkD7sPS5yNXGsVjq1ppEDOcK608HYz3KX2riTkTaFwyEuFo8J4SMlKz9UrF45WGcG0YS6KmodvUi7ObalZZ3CMPu3hrnnh4FtOaxNs0K4eC8c/8OyQAPhK1IUzlFbrvXBw7gQv4iQeh/tmkNE3l3sffUChGgaRLhwr2+ZbahJvmMHk7v6a/L9sTau5FuX48BONtuNJ2MDmGyxt9NNOE46l78MfIpxCC1VHdqdwyNtD4ZADhEPeA01bEnLUUDiEwjkSKBxy7FA4hMI5EigccuxQOITCORIoHHLsUDiEwiGELAKFQygcQsgiUDiEwiGELAKFQygcQsgiUDiEwiGELAKFQygcQsgiUDiEwiGELAKFQygcQsgiUDiEwiGELMJ/7JlRbqNIEIbfaAkC2I0sw2JHyr7sk6NJjrHKAXyDOcVqpaz2yPu+VdU/LuJMbHBmUB7+TxoMdHd1dQP9BYbCIRQOIWQRKBxC4RBCFoHCIRQOIWQRKBxC4RBCFoHCIRQOIWQRKBxC4RBCFoHCIRQOIWQRKBxC4RBCFoHCIRQOIWQRKBxC4RBCFoHCIRQOIWQRKBxC4RBCFoHCIRQOIWQRKBxC4RBCFoHCIRQOIWQRKBxC4RBCFoHCIRQOIWQRKBxC4RBCFoHCIRQOIWQRKBxC4RBCFoHCIRQOIWQRKBzypYRTru4DiLI7k3J1DF+SmHXBqbJacp0/PKfP6zCVOXWv0WYykF8NriKIetQ2RfiAT87kwJUsbqHdXUj6A6rs9ovVf6Ltj6nzPtzC5iW8gcIhxgzhPNwpB+zrL3h+CsZBivGAPWrVIDzJ73M4Y7298CjfKpx+df9TFgnHaTfWw4Sltsozwet9RjjrbSbU70/XkyQi9a4IJzZhLhfX/Z/GdOHE5lcIZ9a9VGZvLtNXFE7356SRjLkinPolXITCIRN5L5xBJw/2kxyjR+DuLglHxfKUTj/f6cZ2CisAIK62kx6qWcKZVXkmk4UT8063V+tNWVXKbGMGa25oq6yvTnI5Wzjr7SYsTryw8M8fwhRm3Et9blKJX0I4H1HfLJwx04RyrZzCIVOEcxDTOHePhyfsCbKrrrFqz9g1Hs0/D7od027KXZjAjOd+ZuWZTBVOlU9cjyesKuouo21mt6VwPsf0e+nyiyaFc4LCIcpU4eDV5SSSQqQC9YQknOfDsMUJHAkip/vffh8ty52t3evtrkiLGD4f2WHZ6Dbq4fi5b628yusya3BYD+cbtM820toC9rkeKKWetphGlar5wx0RCCHt2w1S0+L3wilToug5Zay9NzYyNEBPkr9mE/PVUVZNZInINlKNhozQv56uZMeX9t6y2klbi1dm1m+fdz78cRLopR4JR+pqhCqXzk/f/TrbWmwLeDYbvdVBMPnFZCL/UbdVbi0QV1KEdjWchrHYmIW/pBTfqtAAwSPi4vqWzZBBDeHo2i2pGN1pHjEEnUlvYFFinnaBF2W17icR9Bg4epXhaf5+L70iRz0Y3VYO7hMQMRpM1GuBOX89lXrlPvPBtdLr8TR/fyNvLfpjq931Fux0d7WvGJCkivvbo3ZB0l5vUwPcCWk8ZQg7+Xmxi1F2uZ5RdC/rQyqNJgvZaceq2rXfh1PfrbYcCjEdmszWL1qjGJqXFA6ZiAvHwZvL+OhBTAPO3nDwXgPh4ORYOGVjkrFP71gO+8yk0xQQTpl1ujkJp7Jn9Vuo8v0Gz7m0k924saPhr1IIZz8Uh9YWqyQGpe3wVynCariY1wipaVicKpet/2ntj7P5aP2vZaThTAGr/b0mjxG4JmwYlg1ilXV6C3LhCJakD0nDHSEJFO/k3351j+60LcqrfIfmoyQqW6QwxJFw9k2hWWP8sUuTdZrCYjQbuAB9Jz3glL/hWLfFuNvzIbcNXhOkZYfh4ZrUCGJ4IlajKdL1xVWUwNrehTPcCT6PGILfM3YFEcWzRlGaeMkDA4hZl6YUvfY2mRoK99JrQBSpP7qtzmcWVK+aRPobQ1t+w1XTxlag5wvM4/54GtwWWaTQ/SBKFHmaLhw0/edoBxiNC2e1R1e4E6CNUJcqhrbQkci2M+NsVDZdrwUhndq92B0+Fs7+RdySaYU8yrkebzB6iAgbs48G3FmLjMIh0zgXjksF4BsZZOJlh4Nap7DNnRCgHv9PHP/Uo4sIFhx9xE0ZWENk8bClC8u5r7mphpSOlxkBwcbCkV2Law+re+Ddl44qawZ9lQicHuv4nyZZolcXjpX6hy40tWxjWtSyzbAyY4tsIC+k/UY4EQcoQzhrhQbqzA7duXBsiO+SONck6iKCLO3oCoEVdOezkVpgqrD1YXm3Ad2+HbIthxYnzZZsdRaOiK3z6DOBiUWWfn095lvhtON59DsBMrMZsCjIz/AiHWOBM1WG5FDf58qFA62FHkOw9b648O1Nw1lDw+e8/5+dM9ht29jC8I4CJEu8VwVvKIhZ+O5twH6KoPD2AkEW3eYdelEUcJFH6yN1X56jj/pJSpblJqYa9/+Q2KRmeDgzIuczZ0bKLflJlZtXuDoah6shIUnFlHBoDZpGpcizcCXMdSUgHDbD7bnfPIQythoDi5+LzyGRRMIptpH246dIV/Z4Utr/5OhcZRBes3DMeRwVjp5neHBBJhJOb5Xa3U38uo/03LoZPB7xCFHwVJG3UdcF1dnzx3/l1Lg2SuJO1e0bh0s4hM2/KRFVxuzQLg8DKK8iUhaiLusqzSgykdh0LITiQW0/xFft8pLMEdJAFFTC4c9nVSn7p0xUcbOIxJNwnigEBRGSE0aabxRYWdQa6JeGp8jqI3XaXSODqhzvUu5yXN1EuxFIp82CEIjY7ZF6gUMlHHXHo1hLikyJiVJ3UZSUdeRcGTYDk1/GkHBii/xUgRoTuW8fZSRcyIk2TwcpRTbPNohicTnrWidJxZRwohBEoMx94TBuoCtBwknDtMWoF32DyBptKokD4WSmstVOKT/tcrOtzE298ByOeQHHhYNUZBh+spECuiXffWzFcw0Suu4LR38002fkf3pjOo5MJFlrinVrrQrYMIsxFk7F0fQR6r05VsIp933kPmTubdY/LDoNAl6bF81CsouzZnR1FMsIvyZcp7KsIoPqI+HUkaIqdX3o6AmnWfCqhHO8ENki5Vg4RECacRr16zQhgSXJzL6jLxydlqclUJUzcP7npSYP5P2Tx7uC1GSrMp2CMfHSFw5yVjv2hEMGtKUogZK6OkYF94VbkJ/y9oQjo9RUgTQY2IdJnEpDtmpzVZEUKrfYXxcVgSmhzjQuJqNozA+SKOF0RY7MXAkSThN5t2mXfPVTjrAxN5OkVApe5Egksskji0KSKTnooZvE+fFjG9qLBsxLOBQO9oBQC4z9k2nXMaSmdW0sGhDq2mO7jJvyeeHs0iWccrB2ePu0cKq+cCIpb8ljwil73fP2cdF+FGPdxhoJh16pPCWcNq1SiVWanEwqD55w1uMqMbPSm8OpJJwfFs8Lpz1l2x09LZx8D3rjUQUS6QunUpV3nCGcdlctlTmVSsQoxVb5KEjdaJ8iMI02fMJBzl07fpVwKiV3+ddFE9svEQ7vEpV+XEQm2mcoHFWRCy8rd5ZwHlVMhIOwGt4nGAtHVwLCqYpl94Qj4TAcpoG0zFisjwsnzfSwCKGQCE0cUVo45sUcF849dsEkPNJIODnoxq9bhIOjtCxafxR2o1l1EzfG0SE1Zd2n6zaqZto/IZzuPq/7sz1HhaOQ7eHlsoqfte5mHczcUp5YilQsqkGJB8KhJ+oLhxlfckk4WmGttQpE7gnn6UJE1BPCSSlypggyFg6ZiQfHh9QkHEKTTe+JDtxVXjNjFOSw61fkvnBSzpzpmSG1XZSnh9QiR4QdXVXPDKkdCkfvEiXEd2PhZCzBroTT89R2JJx+MSsJJxujjXBaOCy3STN8DieMhINLGFITTZt0VDgZYTkcUiNtMKTWWDjmPA6Fo0ccDa/ppcMnnNnOPVocvT+UwQwkkHfTb5rfZca1N9fPvU16l0PrarlJl7uxrs2BcMjIpDDJbfqhcFJuUP/xLu7bL8MpnOHcQxafU6mvX+29SYkHwqEHqfvCyT3JVafJkxAtfvBkUqFqzcscFILWPS2cfBuyddSEag2dXHFUmcPTKuS+DsumK68OzFd+oll1lPpYqSLLG/t94aBRtSNXghYNZOYD4fSTCh4rmbIaPTfjtEgeLRrYHBEOgVTD9KeUoDZXFbuEPK2E05u/GgmHYtLA8fNR/skb5aRw2sLkTH4nharoCydTgkXV7ghePiqcnORps7M1IxQL1Kp86vnsVWrmTEbCkWau8tfN/iM5bGhZdM7h3JMQz0H6tgEti95qgrNkAWvusDZ33w1/ZFFpQvoXbiO6jW1Fh9QNzx0Kh8XK7/dPOLs5jkPhtIcTss20WxM919CPMq+aRfecwSJaSqzZavxX5OZm+IRTRWpfOPzNrirRT46/aaCOozBl3fSXRaNuFWJd0hhPCWe54aXYodubSzjy4HrDB+nXR5ZF67SgKreR//WuVO/5y0cOjFfe6wgKgk7//cdCquiWlPfncJBzlJt2pApaFs1VNRIOSfNIKgrWNqtw5G9bNzIpQH9ZdNW/rIYrrneaKFm53O5ybfxXbd6vYosq1xcOrns/FI6KGRky0GPucX3H4XFRHgqHK6Eoc8CMdc3lcA6HVczlFkVslrPP9SIUc3xIrQpxyV5lPOzEi7meuipyBVysqn6IhdQlw3QWjjkBwjnknu9Sa/8NH3X4dRvJ2szHmhs2JJy699Sy4D7UBzLpPPgU5Jq8Sqcr0aRxfoqPIZa42YfCIeNG3eIy4h4ZUiMnD0T7P64F868r5npHH1UlViajs22xS5dwsohFpSE1rVVoDubBu3PtBxv1ecUVH/zcF2I2FM5uFvmEcAjLdFQGHg6pxU9aQzWScMan1XnUOHGs5tE5kEcAGBakGKuijsT+kFrECkq1I1XoZsMIpygdSirKvAQwZIvGCFdR09zmWmKyhPzHhKM5yTIbpf2oZqVrQ22uKgKV6wmHUjbjORwVk6s3l0VzrWjNzFHh7E9ZzlsjbNq9ejikxuc0wyrM+rdyimyLJ4QTEbea59mQOURWLCPzIuu+rSwccx6X/rbo1+CvfMXI34vvvwZ7KT33/UCvymt8cYzp89x1auGYty6c1ckvvPoueDPCuXBFLJxLY+GYtyucbZPjFZft5L4FF+6nvxnryz7gWDgXx8Ixb1c4u0/GXeAbjr81b0M46/mzX7j9ylg4l8bCMW9XOMaYvxUWjrFwjDGTYOEYC8cYMwkWjrFwjDGTYOEYC8cYMwkWjrFwjDGTYOEYC8cYMwkWjrFwjDGTYOEYC8cYMwkWjrFwjDGTYOEYC8cYMwkWjrFwjDGTYOEYC8cYMwkWjrFwjDGTYOEYC8cYMwkWjrFwjDGTYOEYC8cYMwkWjrFwjDGTYOEYC8cYMwkWjrFwjDGTYOEYC8cYMwkWjrFwjDGTYOEYC8cYMwkWjrFwjDGTYOEYC8cYMwkWjrFwjDGTYOGYFwnn7moxe01ur277u1d3vTNf3UXqy/ntYTW7BL/8/3XbypjvDQvHnCWcm6uWu68XzgljXN2eEs7d1fVsdpZw/vPr/Kf4/ennh5WE8+v84zjjhyLJzLLEl9nL+fRzBHpYtRv/Oy2cD23ZjPmnYuGYM4RznR3/9dcL5/ppYyjpqHDub2bn8u4LnsneH+F8OCacSB/x+18Qzp/tnUFu4koQhiM9jRHYeqsRrKIRB2hL9jLS23OBkSIWHGQQygJxtGyfxI2mq/hNG0zAGQ0kCt+nGafd1d2w8qeqbier3UL//xu1dkE4/j0A7hSEAz2EE8JfKqndQjgzJTavi9XmJsJZ2frO+LJw/uQDAL4ICAf6CKduCceqa9OdDiL13kexKW1oioXzfUHOxtRFq1F5BW1a+3IKWUcaL+H4OCO3aNCI3L6Mf77CeTvB8RraLJs3wnnNIvtAEo4qYovZyGprqrI92yArkXloPbKGY6N80kv2c5Ut1Zkks7LZyzx+7iTbJOFMFgcpznwAcJ8gHOghnLqY7oUTSnvcx2bpNiiCdbpqinYGFEIhL8RInZrlLqje0pbz5RVy4VSV/HWY4Sjq83aOyvX5fqckI7qgyS+iLboZzrgjnPH81+PGbhdKQCSRVfSVh5JPni20sA95XJxIZFRSm2WP9uOkcMa2zQNwnyAc6CGcgSUcTqXEpJQRfHvHXVHVdq313FciYoNML2r6SBeU3FQqLarawokofEo4fpF01BXqTkXNtu+lmpZw3sxwfNxkKeFYXqOrQu3x6zj/pUlvNONYONbVFg41NQCEAz2FY9WroMNiMkSjhlDrfxmqdAqtsUwd3CRqWltTvG3mkouOhKNWVzg+PcpIPT6kttuG9bJ1NC37eVY4znO0ykZ7MdKBBq+WHjJ0q32auLAcIjk5irmZzggnLgNwnyAc6CUc3yeZ7ktmRRVbjQmklWkVki8kFXOB+myqrFKIshkfjoUTLPyWcKZxpsYYlXVIORLOPo+YbI6EM8l2LPPDPRw5SvPWI43ykKHFNFom0+2JDGcu4aSlYpdYIxy4VxAO9BSOtktOCMdFUJpt8uicJBxFu8JJGjktnLqozmU400KJzoEN6/Q891Sjec6fy3C0h3MkHLWcrnDGe+GI12XeyXDmZzIchAN3C8KB3sKpiiScdknN7su6smuo0klqRU+W1M4KJ7YulNTqoJ5E5ZP0PG+OKlvp67JwOhmOBit0XAszqTTC0Z7OmQyHkhoAwgGjr3DKrnB0aGCvEM9MqngjQrPZI/fYHN1rI6gjnGrXoc76tHB8to3V/o/QdB0aSHWuyXIvHClifEE4y1zTW6E0XsNawtGUZu3FZeFwaADuFYQDPYQTgo5BJ+HoXtqpdCbaoxJOoSpccyw6pEqbx6Z1Szi6eIePr07s4ShaSVl6I8f+6YsZ5gLpRZJY64WaXhmODra5OFZzhdKxaC0t4TTTXTDzR0+QzghnbVM5Fg33C8KBHsJpNvEPhON79daQU3QVoS5jVPeFmj4npPWScBTadfjMt0pqLqt4zfWyaKnV8vZWy2vUhjZcNnLIbJRtdn0pY3EO39exV0RdKzGy0faO0AmAZ73s0+7PDJv+MorrHQlHSDizD/pVogAfD8KBPsJ5P9EhH8QtnuiS1jsCvIYDgHDgywlnMPnMj/Rb6BDgk4Jw4MsJZ/7r8/4JgNmIHRy4XxAOfDnhAMDnBOHAdYQDAIBw4BwIBwCuBcIBhAMANwHhAMIBgJuAcADhAMBNQDhwJJzLry4CAPwJCAcO2A5/DAAArsCP4fYBIPHfcPvPAADgr5Nvh08PAInv2yEAwFXYfnsAaPHtaQgAcAWe8A0AANyE7w8AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA8B5+A7N6i55H6klXAAAAAElFTkSuQmCC alt=CA1869></a></p>
<p>The <code>JsonSerializerOptions</code> type looks like something that should be relatively cheap to allocate, just a small options type you could allocate on each call to <code>JsonSerializer.Serialize</code> or <code>JsonSerializer.Deserialize</code> with little ramification:</p>
<div><div class=code-header><span class=language></span><button class="copybutton copy-button"><i class="fabric-icon fabric-icon--Copy" aria-hidden=true></i> Copy</button></div></div><pre tabindex=0><code class="language-C# hljs language-C" data-highlighted=yes>T value = JsonSerializer.Deserialize&lt;T&gt;(source, new JsonSerializerOptions { AllowTrailingCommas = <span class=hljs-literal>true</span> });</code></pre>
<p>That’s not the case, however. <code>JsonSerializer</code> may need to use reflection to analyze the type being serialized or deserialized in order to learn about its shape and then potentially even use reflection emit to generate custom processing code for using that type. The <code>JsonSerializerOptions</code> instance is then used not only as a simple bag for options information, but also as a place to store all of that state the serializer built up, enabling it to be shared from call to call. Prior to .NET 7, this meant that passing a new <code>JsonSerializerOptions</code> instance to each call resulted in a massive performance cliff. In .NET 7, the caching scheme was improved to combat the problems here, but even with those mitigations, there’s still significant overhead to using a new <code>JsonSerializerOptions</code> instance each time. Instead, a <code>JsonSerializerOptions</code> instance should be cached and reused.</p>
<div><div class=code-header><span class=language></span><button class="copybutton copy-button"><i class="fabric-icon fabric-icon--Copy" aria-hidden=true></i> Copy</button></div></div><pre tabindex=0><code class="language-C# hljs language-C" data-highlighted=yes><span class=hljs-comment>// dotnet run -c Release -f net8.0 --filter "*"</span>

using BenchmarkDotNet.Attributes;
using BenchmarkDotNet.Running;
using System.Text.Json;

BenchmarkSwitcher.FromAssembly(typeof(Tests).Assembly).Run(args);

[HideColumns(<span class=hljs-string>"Error"</span>, <span class=hljs-string>"StdDev"</span>, <span class=hljs-string>"Median"</span>, <span class=hljs-string>"RatioSD"</span>)]
[MemoryDiagnoser(displayGenColumns: <span class=hljs-literal>false</span>)]
public <span class=hljs-class><span class=hljs-keyword>class</span> <span class=hljs-title>Tests</span>
{</span>
    private readonly <span class=hljs-built_in>string</span> _json = <span class=hljs-string>""</span><span class=hljs-string>"{ "</span>Title<span class=hljs-string>":"</span>Performance Improvements in .NET <span class=hljs-number>8</span><span class=hljs-string>", "</span>Author<span class=hljs-string>":"</span>Stephen Toub<span class=hljs-string>", }"</span><span class=hljs-string>""</span>;
    private readonly JsonSerializerOptions _options = new JsonSerializerOptions { AllowTrailingCommas = <span class=hljs-literal>true</span> };

    [Benchmark(Baseline = <span class=hljs-literal>true</span>)]
    public BlogData <span class="hljs-title function_">Deserialize_New</span><span class=hljs-params>()</span> =&gt; JsonSerializer.Deserialize&lt;BlogData&gt;(_json, new JsonSerializerOptions { AllowTrailingCommas = <span class=hljs-literal>true</span> });

    [Benchmark]
    public BlogData <span class="hljs-title function_">Deserialize_Cached</span><span class=hljs-params>()</span> =&gt; JsonSerializer.Deserialize&lt;BlogData&gt;(_json, _options);

    public <span class=hljs-class><span class=hljs-keyword>struct</span> <span class=hljs-title>BlogData</span>
    {</span>
        public <span class=hljs-built_in>string</span> Title { get; <span class=hljs-built_in>set</span>; }
        public <span class=hljs-built_in>string</span> Author { get; <span class=hljs-built_in>set</span>; }
    }
}</code></pre>
<div class="table-responsive notranslate"><table>
<thead>
<tr>
<th>Method</th>
<th style=text-align:right>Mean</th>
<th style=text-align:right>Ratio</th>
<th style=text-align:right>Allocated</th>
<th style=text-align:right>Alloc Ratio</th>
</tr>
</thead>
<tbody>
<tr>
<td>Deserialize_New</td>
<td style=text-align:right>736.5 ns</td>
<td style=text-align:right>1.00</td>
<td style=text-align:right>358 B</td>
<td style=text-align:right>1.00</td>
</tr>
<tr>
<td>Deserialize_Cached</td>
<td style=text-align:right>290.2 ns</td>
<td style=text-align:right>0.39</td>
<td style=text-align:right>176 B</td>
<td style=text-align:right>0.49</td>
</tr>
</tbody>
</table></div>
<h2 id=cryptography>Cryptography<button aria-label="Copy Post URL" class=linkicon data-id-href=https://devblogs.microsoft.com/dotnet/performance-improvements-in-net-8/#json#cryptography data-toggle=tooltip data-placement=right title data-original-title="Copy Post URL"><i class="fabric-icon fabric-icon--Link"></i><div class=screenreader-text aria-atomic=true aria-live=polite></div></button></h2>
 
 
 
 
 </div>
</div>
 
</article> 
 <div class=related-postssection role=region aria-label="Related Post Section" data-bi-id="read next" style=display:none!important>
 
 <div class="row related-articles" style=display:none!important>
 <article class=col-md-6 style=display:none!important>
 <div class=post-card aria-label="Related Post Title" style=display:none!important>
 
 
 
 <div class=post-comments style=display:none!important><a class=comment-icon href=https://devblogs.microsoft.com/dotnet/teams-toolkit-vs177-update/#comments style=display:none!important><svg width=17 height=17 class=mr-1 viewBox="0 0 18 17" fill=none xmlns=http://www.w3.org/2000/svg>
 <path d="M0 0.125H18V12.5H6.4248L2.25 16.6748V12.5H0V0.125ZM16.875 11.375V1.25H1.125V11.375H3.375V13.9502L5.9502 11.375H16.875Z" fill=#0078D4></path>
 </svg>0 comment</a></div>
 </div>
 </article><article class=col-md-6 style=display:none!important>
 <div class=post-card aria-label="Related Post Title" style=display:none!important>
 
 
 
 <div class=post-comments style=display:none!important><a class=comment-icon href=https://devblogs.microsoft.com/dotnet/system-text-json-in-dotnet-8/#comments style=display:none!important><svg width=17 height=17 class=mr-1 viewBox="0 0 18 17" fill=none xmlns=http://www.w3.org/2000/svg>
 <path d="M0 0.125H18V12.5H6.4248L2.25 16.6748V12.5H0V0.125ZM16.875 11.375V1.25H1.125V11.375H3.375V13.9502L5.9502 11.375H16.875Z" fill=#0078D4></path>
 </svg>15 comments</a></div>
 </div>
 </article> </div>
 </div> 
 
 
 
 <div id=comments class=comments-area data-bi-id=comments style=display:none!important>
 
 
 
 
 
 <ul class=commentlist style=display:none!important>
 
 <li class="comment byuser comment-author-peter-angerer even thread-even depth-1 comment-show" id=li-comment-18843 style=display:none!important>
 <article id=comment-18843 class=comment style=display:none!important>
 
 <header style=display:none!important>
 
 
 
 <span class=voting style=display:none!important><span id=loggedoutvotes18843 style=display:none!important><a class="comment-reply-login x-hidden-focus" title data-toggle=tooltip href="https://devblogs.microsoft.com/dotnet/wp-login.php?redirect_to=https%3A%2F%2Fdevblogs.microsoft.com%2Fdotnet%2Fperformance-improvements-in-net-8%2F%23comment-18843" data-bi-id=comments data-bi-name="Login to vote" aria-label="Login to vote" data-original-title="Login to vote" style=display:none!important><span class=icon-like-dislike style=display:none!important><svg xmlns=http://www.w3.org/2000/svg viewBox="0 0 2048 2048" class="svg_dd790ee3 x-hidden-focus" focusable=false><path d="M1856 640q39 0 74 15t61 41 42 61 15 75q0 32-10 61l-256 768q-10 29-28 53t-42 42-52 26-60 10h-512q-179 0-345-69-72-29-144-44t-151-15H0V768h417q65 0 122-24t104-70l622-621q25-25 50-39t61-14q33 0 62 12t51 35 34 51 13 62q0 81-18 154t-53 146q-20 43-34 87t-19 93h444zm-256 1024q20 0 37-12t24-32q5-14 18-54t33-96 42-124 46-137 44-134 39-118 27-86 10-39q0-26-19-45t-45-19h-576q0-53 2-98t10-89 22-86 37-91q28-58 42-118t15-126q0-14-9-23t-23-9q-6 0-10 4t-9 9L734 765q-32 32-68 56t-78 41q-80 34-171 34H128v640h320q178 0 345 69 144 59 295 59h512z"></path></svg></span></a> 15</span> </span>
 
 </header>
 
 
 </article>
 <ul class=children style=display:none!important>
 <li class="comment byuser comment-author-toub bypostauthor odd alt depth-2 comment-show" id=li-comment-18862 style=display:none!important>
 <article id=comment-18862 class=comment style=display:none!important>
 
 <header style=display:none!important>
 
 
 
 <span class=voting style=display:none!important><span id=loggedoutvotes18862 style=display:none!important><a class="comment-reply-login x-hidden-focus" title data-toggle=tooltip href="https://devblogs.microsoft.com/dotnet/wp-login.php?redirect_to=https%3A%2F%2Fdevblogs.microsoft.com%2Fdotnet%2Fperformance-improvements-in-net-8%2F%23comment-18862" data-bi-id=comments data-bi-name="Login to vote" aria-label="Login to vote" data-original-title="Login to vote" style=display:none!important><span class=icon-like-dislike style=display:none!important><svg xmlns=http://www.w3.org/2000/svg viewBox="0 0 2048 2048" class="svg_dd790ee3 x-hidden-focus" focusable=false><path d="M1856 640q39 0 74 15t61 41 42 61 15 75q0 32-10 61l-256 768q-10 29-28 53t-42 42-52 26-60 10h-512q-179 0-345-69-72-29-144-44t-151-15H0V768h417q65 0 122-24t104-70l622-621q25-25 50-39t61-14q33 0 62 12t51 35 34 51 13 62q0 81-18 154t-53 146q-20 43-34 87t-19 93h444zm-256 1024q20 0 37-12t24-32q5-14 18-54t33-96 42-124 46-137 44-134 39-118 27-86 10-39q0-26-19-45t-45-19h-576q0-53 2-98t10-89 22-86 37-91q28-58 42-118t15-126q0-14-9-23t-23-9q-6 0-10 4t-9 9L734 765q-32 32-68 56t-78 41q-80 34-171 34H128v640h320q178 0 345 69 144 59 295 59h512z"></path></svg></span></a> 6</span> </span>
 
 </header>
 
 
 </article>
 </li>
</ul>
</li>
 <li class="comment byuser comment-author-rghkrish even thread-odd thread-alt depth-1 comment-show" id=li-comment-18845 style=display:none!important>
 <article id=comment-18845 class=comment style=display:none!important>
 
 <header style=display:none!important>
 
 
 
 <span class=voting style=display:none!important><span id=loggedoutvotes18845 style=display:none!important><a class="comment-reply-login x-hidden-focus" title data-toggle=tooltip href="https://devblogs.microsoft.com/dotnet/wp-login.php?redirect_to=https%3A%2F%2Fdevblogs.microsoft.com%2Fdotnet%2Fperformance-improvements-in-net-8%2F%23comment-18845" data-bi-id=comments data-bi-name="Login to vote" aria-label="Login to vote" data-original-title="Login to vote" style=display:none!important><span class=icon-like-dislike style=display:none!important><svg xmlns=http://www.w3.org/2000/svg viewBox="0 0 2048 2048" class="svg_dd790ee3 x-hidden-focus" focusable=false><path d="M1856 640q39 0 74 15t61 41 42 61 15 75q0 32-10 61l-256 768q-10 29-28 53t-42 42-52 26-60 10h-512q-179 0-345-69-72-29-144-44t-151-15H0V768h417q65 0 122-24t104-70l622-621q25-25 50-39t61-14q33 0 62 12t51 35 34 51 13 62q0 81-18 154t-53 146q-20 43-34 87t-19 93h444zm-256 1024q20 0 37-12t24-32q5-14 18-54t33-96 42-124 46-137 44-134 39-118 27-86 10-39q0-26-19-45t-45-19h-576q0-53 2-98t10-89 22-86 37-91q28-58 42-118t15-126q0-14-9-23t-23-9q-6 0-10 4t-9 9L734 765q-32 32-68 56t-78 41q-80 34-171 34H128v640h320q178 0 345 69 144 59 295 59h512z"></path></svg></span></a> 6</span> </span>
 
 </header>
 
 
 </article>
 <ul class=children style=display:none!important>
 <li class="comment byuser comment-author-toub bypostauthor odd alt depth-2 comment-show" id=li-comment-18863 style=display:none!important>
 <article id=comment-18863 class=comment style=display:none!important>
 
 <header style=display:none!important>
 
 
 
 <span class=voting style=display:none!important><span id=loggedoutvotes18863 style=display:none!important><a class="comment-reply-login x-hidden-focus" title data-toggle=tooltip href="https://devblogs.microsoft.com/dotnet/wp-login.php?redirect_to=https%3A%2F%2Fdevblogs.microsoft.com%2Fdotnet%2Fperformance-improvements-in-net-8%2F%23comment-18863" data-bi-id=comments data-bi-name="Login to vote" aria-label="Login to vote" data-original-title="Login to vote" style=display:none!important><span class=icon-like-dislike style=display:none!important><svg xmlns=http://www.w3.org/2000/svg viewBox="0 0 2048 2048" class="svg_dd790ee3 x-hidden-focus" focusable=false><path d="M1856 640q39 0 74 15t61 41 42 61 15 75q0 32-10 61l-256 768q-10 29-28 53t-42 42-52 26-60 10h-512q-179 0-345-69-72-29-144-44t-151-15H0V768h417q65 0 122-24t104-70l622-621q25-25 50-39t61-14q33 0 62 12t51 35 34 51 13 62q0 81-18 154t-53 146q-20 43-34 87t-19 93h444zm-256 1024q20 0 37-12t24-32q5-14 18-54t33-96 42-124 46-137 44-134 39-118 27-86 10-39q0-26-19-45t-45-19h-576q0-53 2-98t10-89 22-86 37-91q28-58 42-118t15-126q0-14-9-23t-23-9q-6 0-10 4t-9 9L734 765q-32 32-68 56t-78 41q-80 34-171 34H128v640h320q178 0 345 69 144 59 295 59h512z"></path></svg></span></a> 4</span> </span>
 
 </header>
 
 
 </article>
 </li>
</ul>
</li>
 <li class="comment byuser comment-author-dengyakui even thread-even depth-1 comment-show" id=li-comment-18846 style=display:none!important>
 <article id=comment-18846 class=comment style=display:none!important>
 
 <header style=display:none!important>
 
 
 
 <span class=voting style=display:none!important><span id=loggedoutvotes18846 style=display:none!important><a class="comment-reply-login x-hidden-focus" title data-toggle=tooltip href="https://devblogs.microsoft.com/dotnet/wp-login.php?redirect_to=https%3A%2F%2Fdevblogs.microsoft.com%2Fdotnet%2Fperformance-improvements-in-net-8%2F%23comment-18846" data-bi-id=comments data-bi-name="Login to vote" aria-label="Login to vote" data-original-title="Login to vote" style=display:none!important><span class=icon-like-dislike style=display:none!important><svg xmlns=http://www.w3.org/2000/svg viewBox="0 0 2048 2048" class="svg_dd790ee3 x-hidden-focus" focusable=false><path d="M1856 640q39 0 74 15t61 41 42 61 15 75q0 32-10 61l-256 768q-10 29-28 53t-42 42-52 26-60 10h-512q-179 0-345-69-72-29-144-44t-151-15H0V768h417q65 0 122-24t104-70l622-621q25-25 50-39t61-14q33 0 62 12t51 35 34 51 13 62q0 81-18 154t-53 146q-20 43-34 87t-19 93h444zm-256 1024q20 0 37-12t24-32q5-14 18-54t33-96 42-124 46-137 44-134 39-118 27-86 10-39q0-26-19-45t-45-19h-576q0-53 2-98t10-89 22-86 37-91q28-58 42-118t15-126q0-14-9-23t-23-9q-6 0-10 4t-9 9L734 765q-32 32-68 56t-78 41q-80 34-171 34H128v640h320q178 0 345 69 144 59 295 59h512z"></path></svg></span></a> 4</span> </span>
 
 </header>
 
 
 </article>
 <ul class=children style=display:none!important>
 <li class="comment byuser comment-author-toub bypostauthor odd alt depth-2 comment-show" id=li-comment-18864 style=display:none!important>
 <article id=comment-18864 class=comment style=display:none!important>
 
 <header style=display:none!important>
 
 
 
 <span class=voting style=display:none!important><span id=loggedoutvotes18864 style=display:none!important><a class="comment-reply-login x-hidden-focus" title data-toggle=tooltip href="https://devblogs.microsoft.com/dotnet/wp-login.php?redirect_to=https%3A%2F%2Fdevblogs.microsoft.com%2Fdotnet%2Fperformance-improvements-in-net-8%2F%23comment-18864" data-bi-id=comments data-bi-name="Login to vote" aria-label="Login to vote" data-original-title="Login to vote" style=display:none!important><span class=icon-like-dislike style=display:none!important><svg xmlns=http://www.w3.org/2000/svg viewBox="0 0 2048 2048" class="svg_dd790ee3 x-hidden-focus" focusable=false><path d="M1856 640q39 0 74 15t61 41 42 61 15 75q0 32-10 61l-256 768q-10 29-28 53t-42 42-52 26-60 10h-512q-179 0-345-69-72-29-144-44t-151-15H0V768h417q65 0 122-24t104-70l622-621q25-25 50-39t61-14q33 0 62 12t51 35 34 51 13 62q0 81-18 154t-53 146q-20 43-34 87t-19 93h444zm-256 1024q20 0 37-12t24-32q5-14 18-54t33-96 42-124 46-137 44-134 39-118 27-86 10-39q0-26-19-45t-45-19h-576q0-53 2-98t10-89 22-86 37-91q28-58 42-118t15-126q0-14-9-23t-23-9q-6 0-10 4t-9 9L734 765q-32 32-68 56t-78 41q-80 34-171 34H128v640h320q178 0 345 69 144 59 295 59h512z"></path></svg></span></a> 2</span> </span>
 
 </header>
 
 
 </article>
 </li>
</ul>
</li>
 <li class="comment byuser comment-author-steven-rasmussen even thread-odd thread-alt depth-1 comment-show" id=li-comment-18851 style=display:none!important>
 <article id=comment-18851 class=comment style=display:none!important>
 
 <header style=display:none!important>
 
 
 
 <span class=voting style=display:none!important><span id=loggedoutvotes18851 style=display:none!important><a class="comment-reply-login x-hidden-focus" title data-toggle=tooltip href="https://devblogs.microsoft.com/dotnet/wp-login.php?redirect_to=https%3A%2F%2Fdevblogs.microsoft.com%2Fdotnet%2Fperformance-improvements-in-net-8%2F%23comment-18851" data-bi-id=comments data-bi-name="Login to vote" aria-label="Login to vote" data-original-title="Login to vote" style=display:none!important><span class=icon-like-dislike style=display:none!important><svg xmlns=http://www.w3.org/2000/svg viewBox="0 0 2048 2048" class="svg_dd790ee3 x-hidden-focus" focusable=false><path d="M1856 640q39 0 74 15t61 41 42 61 15 75q0 32-10 61l-256 768q-10 29-28 53t-42 42-52 26-60 10h-512q-179 0-345-69-72-29-144-44t-151-15H0V768h417q65 0 122-24t104-70l622-621q25-25 50-39t61-14q33 0 62 12t51 35 34 51 13 62q0 81-18 154t-53 146q-20 43-34 87t-19 93h444zm-256 1024q20 0 37-12t24-32q5-14 18-54t33-96 42-124 46-137 44-134 39-118 27-86 10-39q0-26-19-45t-45-19h-576q0-53 2-98t10-89 22-86 37-91q28-58 42-118t15-126q0-14-9-23t-23-9q-6 0-10 4t-9 9L734 765q-32 32-68 56t-78 41q-80 34-171 34H128v640h320q178 0 345 69 144 59 295 59h512z"></path></svg></span></a> 7</span> </span>
 
 </header>
 
 
 </article>
 <ul class=children style=display:none!important>
 <li class="comment byuser comment-author-toub bypostauthor odd alt depth-2 comment-show" id=li-comment-18865 style=display:none!important>
 <article id=comment-18865 class=comment style=display:none!important>
 
 <header style=display:none!important>
 
 
 
 <span class=voting style=display:none!important><span id=loggedoutvotes18865 style=display:none!important><a class="comment-reply-login x-hidden-focus" title data-toggle=tooltip href="https://devblogs.microsoft.com/dotnet/wp-login.php?redirect_to=https%3A%2F%2Fdevblogs.microsoft.com%2Fdotnet%2Fperformance-improvements-in-net-8%2F%23comment-18865" data-bi-id=comments data-bi-name="Login to vote" aria-label="Login to vote" data-original-title="Login to vote" style=display:none!important><span class=icon-like-dislike style=display:none!important><svg xmlns=http://www.w3.org/2000/svg viewBox="0 0 2048 2048" class="svg_dd790ee3 x-hidden-focus" focusable=false><path d="M1856 640q39 0 74 15t61 41 42 61 15 75q0 32-10 61l-256 768q-10 29-28 53t-42 42-52 26-60 10h-512q-179 0-345-69-72-29-144-44t-151-15H0V768h417q65 0 122-24t104-70l622-621q25-25 50-39t61-14q33 0 62 12t51 35 34 51 13 62q0 81-18 154t-53 146q-20 43-34 87t-19 93h444zm-256 1024q20 0 37-12t24-32q5-14 18-54t33-96 42-124 46-137 44-134 39-118 27-86 10-39q0-26-19-45t-45-19h-576q0-53 2-98t10-89 22-86 37-91q28-58 42-118t15-126q0-14-9-23t-23-9q-6 0-10 4t-9 9L734 765q-32 32-68 56t-78 41q-80 34-171 34H128v640h320q178 0 345 69 144 59 295 59h512z"></path></svg></span></a> 4</span> </span>
 
 </header>
 
 
 </article>
 </li>
</ul>
</li>
 <li class="comment byuser comment-author-stuart-b-lang even thread-even depth-1 comment-show" id=li-comment-18852 style=display:none!important>
 <article id=comment-18852 class=comment style=display:none!important>
 
 <header style=display:none!important>
 
 
 
 <span class=voting style=display:none!important><span id=loggedoutvotes18852 style=display:none!important><a class="comment-reply-login x-hidden-focus" title data-toggle=tooltip href="https://devblogs.microsoft.com/dotnet/wp-login.php?redirect_to=https%3A%2F%2Fdevblogs.microsoft.com%2Fdotnet%2Fperformance-improvements-in-net-8%2F%23comment-18852" data-bi-id=comments data-bi-name="Login to vote" aria-label="Login to vote" data-original-title="Login to vote" style=display:none!important><span class=icon-like-dislike style=display:none!important><svg xmlns=http://www.w3.org/2000/svg viewBox="0 0 2048 2048" class="svg_dd790ee3 x-hidden-focus" focusable=false><path d="M1856 640q39 0 74 15t61 41 42 61 15 75q0 32-10 61l-256 768q-10 29-28 53t-42 42-52 26-60 10h-512q-179 0-345-69-72-29-144-44t-151-15H0V768h417q65 0 122-24t104-70l622-621q25-25 50-39t61-14q33 0 62 12t51 35 34 51 13 62q0 81-18 154t-53 146q-20 43-34 87t-19 93h444zm-256 1024q20 0 37-12t24-32q5-14 18-54t33-96 42-124 46-137 44-134 39-118 27-86 10-39q0-26-19-45t-45-19h-576q0-53 2-98t10-89 22-86 37-91q28-58 42-118t15-126q0-14-9-23t-23-9q-6 0-10 4t-9 9L734 765q-32 32-68 56t-78 41q-80 34-171 34H128v640h320q178 0 345 69 144 59 295 59h512z"></path></svg></span></a> 4</span> </span>
 
 </header>
 
 
 </article>
 <ul class=children style=display:none!important>
 <li class="comment byuser comment-author-toub bypostauthor odd alt depth-2 comment-show" id=li-comment-18868 style=display:none!important>
 <article id=comment-18868 class=comment style=display:none!important>
 
 <header style=display:none!important>
 
 
 
 <span class=voting style=display:none!important><span id=loggedoutvotes18868 style=display:none!important><a class="comment-reply-login x-hidden-focus" title data-toggle=tooltip href="https://devblogs.microsoft.com/dotnet/wp-login.php?redirect_to=https%3A%2F%2Fdevblogs.microsoft.com%2Fdotnet%2Fperformance-improvements-in-net-8%2F%23comment-18868" data-bi-id=comments data-bi-name="Login to vote" aria-label="Login to vote" data-original-title="Login to vote" style=display:none!important><span class=icon-like-dislike style=display:none!important><svg xmlns=http://www.w3.org/2000/svg viewBox="0 0 2048 2048" class="svg_dd790ee3 x-hidden-focus" focusable=false><path d="M1856 640q39 0 74 15t61 41 42 61 15 75q0 32-10 61l-256 768q-10 29-28 53t-42 42-52 26-60 10h-512q-179 0-345-69-72-29-144-44t-151-15H0V768h417q65 0 122-24t104-70l622-621q25-25 50-39t61-14q33 0 62 12t51 35 34 51 13 62q0 81-18 154t-53 146q-20 43-34 87t-19 93h444zm-256 1024q20 0 37-12t24-32q5-14 18-54t33-96 42-124 46-137 44-134 39-118 27-86 10-39q0-26-19-45t-45-19h-576q0-53 2-98t10-89 22-86 37-91q28-58 42-118t15-126q0-14-9-23t-23-9q-6 0-10 4t-9 9L734 765q-32 32-68 56t-78 41q-80 34-171 34H128v640h320q178 0 345 69 144 59 295 59h512z"></path></svg></span></a> 2</span> </span>
 
 </header>
 
 
 </article>
 </li>
</ul>
</li>
 <li class="comment byuser comment-author-karl-pickett even thread-odd thread-alt depth-1 comment-show" id=li-comment-18853 style=display:none!important>
 <article id=comment-18853 class=comment style=display:none!important>
 
 <header style=display:none!important>
 
 
 
 <span class=voting style=display:none!important><span id=loggedoutvotes18853 style=display:none!important><a class="comment-reply-login x-hidden-focus" title data-toggle=tooltip href="https://devblogs.microsoft.com/dotnet/wp-login.php?redirect_to=https%3A%2F%2Fdevblogs.microsoft.com%2Fdotnet%2Fperformance-improvements-in-net-8%2F%23comment-18853" data-bi-id=comments data-bi-name="Login to vote" aria-label="Login to vote" data-original-title="Login to vote" style=display:none!important><span class=icon-like-dislike style=display:none!important><svg xmlns=http://www.w3.org/2000/svg viewBox="0 0 2048 2048" class="svg_dd790ee3 x-hidden-focus" focusable=false><path d="M1856 640q39 0 74 15t61 41 42 61 15 75q0 32-10 61l-256 768q-10 29-28 53t-42 42-52 26-60 10h-512q-179 0-345-69-72-29-144-44t-151-15H0V768h417q65 0 122-24t104-70l622-621q25-25 50-39t61-14q33 0 62 12t51 35 34 51 13 62q0 81-18 154t-53 146q-20 43-34 87t-19 93h444zm-256 1024q20 0 37-12t24-32q5-14 18-54t33-96 42-124 46-137 44-134 39-118 27-86 10-39q0-26-19-45t-45-19h-576q0-53 2-98t10-89 22-86 37-91q28-58 42-118t15-126q0-14-9-23t-23-9q-6 0-10 4t-9 9L734 765q-32 32-68 56t-78 41q-80 34-171 34H128v640h320q178 0 345 69 144 59 295 59h512z"></path></svg></span></a> 0</span> </span>
 
 </header>
 
 
 </article>
 <ul class=children style=display:none!important>
 <li class="comment byuser comment-author-tomrus88 odd alt depth-2 comment-show" id=li-comment-18854 style=display:none!important>
 <article id=comment-18854 class=comment style=display:none!important>
 
 <header style=display:none!important>
 
 
 
 <span class=voting style=display:none!important><span id=loggedoutvotes18854 style=display:none!important><a class="comment-reply-login x-hidden-focus" title data-toggle=tooltip href="https://devblogs.microsoft.com/dotnet/wp-login.php?redirect_to=https%3A%2F%2Fdevblogs.microsoft.com%2Fdotnet%2Fperformance-improvements-in-net-8%2F%23comment-18854" data-bi-id=comments data-bi-name="Login to vote" aria-label="Login to vote" data-original-title="Login to vote" style=display:none!important><span class=icon-like-dislike style=display:none!important><svg xmlns=http://www.w3.org/2000/svg viewBox="0 0 2048 2048" class="svg_dd790ee3 x-hidden-focus" focusable=false><path d="M1856 640q39 0 74 15t61 41 42 61 15 75q0 32-10 61l-256 768q-10 29-28 53t-42 42-52 26-60 10h-512q-179 0-345-69-72-29-144-44t-151-15H0V768h417q65 0 122-24t104-70l622-621q25-25 50-39t61-14q33 0 62 12t51 35 34 51 13 62q0 81-18 154t-53 146q-20 43-34 87t-19 93h444zm-256 1024q20 0 37-12t24-32q5-14 18-54t33-96 42-124 46-137 44-134 39-118 27-86 10-39q0-26-19-45t-45-19h-576q0-53 2-98t10-89 22-86 37-91q28-58 42-118t15-126q0-14-9-23t-23-9q-6 0-10 4t-9 9L734 765q-32 32-68 56t-78 41q-80 34-171 34H128v640h320q178 0 345 69 144 59 295 59h512z"></path></svg></span></a> 3</span> </span>
 
 </header>
 
 
 </article>
 <ul class=children style=display:none!important>
 <li class="comment byuser comment-author-karl-pickett even depth-3 comment-show" id=li-comment-18890 style=display:none!important>
 <article id=comment-18890 class=comment style=display:none!important>
 
 <header style=display:none!important>
 
 
 
 <span class=voting style=display:none!important><span id=loggedoutvotes18890 style=display:none!important><a class="comment-reply-login x-hidden-focus" title data-toggle=tooltip href="https://devblogs.microsoft.com/dotnet/wp-login.php?redirect_to=https%3A%2F%2Fdevblogs.microsoft.com%2Fdotnet%2Fperformance-improvements-in-net-8%2F%23comment-18890" data-bi-id=comments data-bi-name="Login to vote" aria-label="Login to vote" data-original-title="Login to vote" style=display:none!important><span class=icon-like-dislike style=display:none!important><svg xmlns=http://www.w3.org/2000/svg viewBox="0 0 2048 2048" class="svg_dd790ee3 x-hidden-focus" focusable=false><path d="M1856 640q39 0 74 15t61 41 42 61 15 75q0 32-10 61l-256 768q-10 29-28 53t-42 42-52 26-60 10h-512q-179 0-345-69-72-29-144-44t-151-15H0V768h417q65 0 122-24t104-70l622-621q25-25 50-39t61-14q33 0 62 12t51 35 34 51 13 62q0 81-18 154t-53 146q-20 43-34 87t-19 93h444zm-256 1024q20 0 37-12t24-32q5-14 18-54t33-96 42-124 46-137 44-134 39-118 27-86 10-39q0-26-19-45t-45-19h-576q0-53 2-98t10-89 22-86 37-91q28-58 42-118t15-126q0-14-9-23t-23-9q-6 0-10 4t-9 9L734 765q-32 32-68 56t-78 41q-80 34-171 34H128v640h320q178 0 345 69 144 59 295 59h512z"></path></svg></span></a> 0</span> </span>
 
 </header>
 
 
 </article>
 </li>
</ul>
</li>
</ul>
</li>
 <li class="comment byuser comment-author-weihanli odd alt thread-even depth-1 comment-show" id=li-comment-18856 style=display:none!important>
 <article id=comment-18856 class=comment style=display:none!important>
 
 <header style=display:none!important>
 
 
 
 <span class=voting style=display:none!important><span id=loggedoutvotes18856 style=display:none!important><a class="comment-reply-login x-hidden-focus" title data-toggle=tooltip href="https://devblogs.microsoft.com/dotnet/wp-login.php?redirect_to=https%3A%2F%2Fdevblogs.microsoft.com%2Fdotnet%2Fperformance-improvements-in-net-8%2F%23comment-18856" data-bi-id=comments data-bi-name="Login to vote" aria-label="Login to vote" data-original-title="Login to vote" style=display:none!important><span class=icon-like-dislike style=display:none!important><svg xmlns=http://www.w3.org/2000/svg viewBox="0 0 2048 2048" class="svg_dd790ee3 x-hidden-focus" focusable=false><path d="M1856 640q39 0 74 15t61 41 42 61 15 75q0 32-10 61l-256 768q-10 29-28 53t-42 42-52 26-60 10h-512q-179 0-345-69-72-29-144-44t-151-15H0V768h417q65 0 122-24t104-70l622-621q25-25 50-39t61-14q33 0 62 12t51 35 34 51 13 62q0 81-18 154t-53 146q-20 43-34 87t-19 93h444zm-256 1024q20 0 37-12t24-32q5-14 18-54t33-96 42-124 46-137 44-134 39-118 27-86 10-39q0-26-19-45t-45-19h-576q0-53 2-98t10-89 22-86 37-91q28-58 42-118t15-126q0-14-9-23t-23-9q-6 0-10 4t-9 9L734 765q-32 32-68 56t-78 41q-80 34-171 34H128v640h320q178 0 345 69 144 59 295 59h512z"></path></svg></span></a> 4</span> </span>
 
 </header>
 
 
 </article>
 <ul class=children style=display:none!important>
 <li class="comment byuser comment-author-toub bypostauthor even depth-2 comment-show" id=li-comment-18866 style=display:none!important>
 <article id=comment-18866 class=comment style=display:none!important>
 
 <header style=display:none!important>
 
 
 
 <span class=voting style=display:none!important><span id=loggedoutvotes18866 style=display:none!important><a class="comment-reply-login x-hidden-focus" title data-toggle=tooltip href="https://devblogs.microsoft.com/dotnet/wp-login.php?redirect_to=https%3A%2F%2Fdevblogs.microsoft.com%2Fdotnet%2Fperformance-improvements-in-net-8%2F%23comment-18866" data-bi-id=comments data-bi-name="Login to vote" aria-label="Login to vote" data-original-title="Login to vote" style=display:none!important><span class=icon-like-dislike style=display:none!important><svg xmlns=http://www.w3.org/2000/svg viewBox="0 0 2048 2048" class="svg_dd790ee3 x-hidden-focus" focusable=false><path d="M1856 640q39 0 74 15t61 41 42 61 15 75q0 32-10 61l-256 768q-10 29-28 53t-42 42-52 26-60 10h-512q-179 0-345-69-72-29-144-44t-151-15H0V768h417q65 0 122-24t104-70l622-621q25-25 50-39t61-14q33 0 62 12t51 35 34 51 13 62q0 81-18 154t-53 146q-20 43-34 87t-19 93h444zm-256 1024q20 0 37-12t24-32q5-14 18-54t33-96 42-124 46-137 44-134 39-118 27-86 10-39q0-26-19-45t-45-19h-576q0-53 2-98t10-89 22-86 37-91q28-58 42-118t15-126q0-14-9-23t-23-9q-6 0-10 4t-9 9L734 765q-32 32-68 56t-78 41q-80 34-171 34H128v640h320q178 0 345 69 144 59 295 59h512z"></path></svg></span></a> 0</span> </span>
 
 </header>
 
 
 </article>
 </li>
</ul>
</li>
 <li class="comment byuser comment-author-petergeorge odd alt thread-odd thread-alt depth-1 comment-show" id=li-comment-18861 style=display:none!important>
 <article id=comment-18861 class=comment style=display:none!important>
 
 <header style=display:none!important>
 
 
 
 <span class=voting style=display:none!important><span id=loggedoutvotes18861 style=display:none!important><a class="comment-reply-login x-hidden-focus" title data-toggle=tooltip href="https://devblogs.microsoft.com/dotnet/wp-login.php?redirect_to=https%3A%2F%2Fdevblogs.microsoft.com%2Fdotnet%2Fperformance-improvements-in-net-8%2F%23comment-18861" data-bi-id=comments data-bi-name="Login to vote" aria-label="Login to vote" data-original-title="Login to vote" style=display:none!important><span class=icon-like-dislike style=display:none!important><svg xmlns=http://www.w3.org/2000/svg viewBox="0 0 2048 2048" class="svg_dd790ee3 x-hidden-focus" focusable=false><path d="M1856 640q39 0 74 15t61 41 42 61 15 75q0 32-10 61l-256 768q-10 29-28 53t-42 42-52 26-60 10h-512q-179 0-345-69-72-29-144-44t-151-15H0V768h417q65 0 122-24t104-70l622-621q25-25 50-39t61-14q33 0 62 12t51 35 34 51 13 62q0 81-18 154t-53 146q-20 43-34 87t-19 93h444zm-256 1024q20 0 37-12t24-32q5-14 18-54t33-96 42-124 46-137 44-134 39-118 27-86 10-39q0-26-19-45t-45-19h-576q0-53 2-98t10-89 22-86 37-91q28-58 42-118t15-126q0-14-9-23t-23-9q-6 0-10 4t-9 9L734 765q-32 32-68 56t-78 41q-80 34-171 34H128v640h320q178 0 345 69 144 59 295 59h512z"></path></svg></span></a> 1</span> </span>
 
 </header>
 
 
 </article>
 <ul class=children style=display:none!important>
 <li class="comment byuser comment-author-toub bypostauthor even depth-2 comment-show" id=li-comment-18867 style=display:none!important>
 <article id=comment-18867 class=comment style=display:none!important>
 
 <header style=display:none!important>
 
 
 
 <span class=voting style=display:none!important><span id=loggedoutvotes18867 style=display:none!important><a class="comment-reply-login x-hidden-focus" title data-toggle=tooltip href="https://devblogs.microsoft.com/dotnet/wp-login.php?redirect_to=https%3A%2F%2Fdevblogs.microsoft.com%2Fdotnet%2Fperformance-improvements-in-net-8%2F%23comment-18867" data-bi-id=comments data-bi-name="Login to vote" aria-label="Login to vote" data-original-title="Login to vote" style=display:none!important><span class=icon-like-dislike style=display:none!important><svg xmlns=http://www.w3.org/2000/svg viewBox="0 0 2048 2048" class="svg_dd790ee3 x-hidden-focus" focusable=false><path d="M1856 640q39 0 74 15t61 41 42 61 15 75q0 32-10 61l-256 768q-10 29-28 53t-42 42-52 26-60 10h-512q-179 0-345-69-72-29-144-44t-151-15H0V768h417q65 0 122-24t104-70l622-621q25-25 50-39t61-14q33 0 62 12t51 35 34 51 13 62q0 81-18 154t-53 146q-20 43-34 87t-19 93h444zm-256 1024q20 0 37-12t24-32q5-14 18-54t33-96 42-124 46-137 44-134 39-118 27-86 10-39q0-26-19-45t-45-19h-576q0-53 2-98t10-89 22-86 37-91q28-58 42-118t15-126q0-14-9-23t-23-9q-6 0-10 4t-9 9L734 765q-32 32-68 56t-78 41q-80 34-171 34H128v640h320q178 0 345 69 144 59 295 59h512z"></path></svg></span></a> 1</span> </span>
 
 </header>
 
 
 </article>
 </li>
</ul>
</li>
 <li class="comment byuser comment-author-volkanalkilic odd alt thread-even depth-1 comment-show" id=li-comment-18870 style=display:none!important>
 <article id=comment-18870 class=comment style=display:none!important>
 
 <header style=display:none!important>
 
 
 
 <span class=voting style=display:none!important><span id=loggedoutvotes18870 style=display:none!important><a class="comment-reply-login x-hidden-focus" title data-toggle=tooltip href="https://devblogs.microsoft.com/dotnet/wp-login.php?redirect_to=https%3A%2F%2Fdevblogs.microsoft.com%2Fdotnet%2Fperformance-improvements-in-net-8%2F%23comment-18870" data-bi-id=comments data-bi-name="Login to vote" aria-label="Login to vote" data-original-title="Login to vote" style=display:none!important><span class=icon-like-dislike style=display:none!important><svg xmlns=http://www.w3.org/2000/svg viewBox="0 0 2048 2048" class="svg_dd790ee3 x-hidden-focus" focusable=false><path d="M1856 640q39 0 74 15t61 41 42 61 15 75q0 32-10 61l-256 768q-10 29-28 53t-42 42-52 26-60 10h-512q-179 0-345-69-72-29-144-44t-151-15H0V768h417q65 0 122-24t104-70l622-621q25-25 50-39t61-14q33 0 62 12t51 35 34 51 13 62q0 81-18 154t-53 146q-20 43-34 87t-19 93h444zm-256 1024q20 0 37-12t24-32q5-14 18-54t33-96 42-124 46-137 44-134 39-118 27-86 10-39q0-26-19-45t-45-19h-576q0-53 2-98t10-89 22-86 37-91q28-58 42-118t15-126q0-14-9-23t-23-9q-6 0-10 4t-9 9L734 765q-32 32-68 56t-78 41q-80 34-171 34H128v640h320q178 0 345 69 144 59 295 59h512z"></path></svg></span></a> 2</span> </span>
 
 </header>
 
 
 </article>
 <ul class=children style=display:none!important>
 <li class="comment byuser comment-author-toub bypostauthor even depth-2 comment-show" id=li-comment-18871 style=display:none!important>
 <article id=comment-18871 class=comment style=display:none!important>
 
 <header style=display:none!important>
 
 
 
 <span class=voting style=display:none!important><span id=loggedoutvotes18871 style=display:none!important><a class="comment-reply-login x-hidden-focus" title data-toggle=tooltip href="https://devblogs.microsoft.com/dotnet/wp-login.php?redirect_to=https%3A%2F%2Fdevblogs.microsoft.com%2Fdotnet%2Fperformance-improvements-in-net-8%2F%23comment-18871" data-bi-id=comments data-bi-name="Login to vote" aria-label="Login to vote" data-original-title="Login to vote" style=display:none!important><span class=icon-like-dislike style=display:none!important><svg xmlns=http://www.w3.org/2000/svg viewBox="0 0 2048 2048" class="svg_dd790ee3 x-hidden-focus" focusable=false><path d="M1856 640q39 0 74 15t61 41 42 61 15 75q0 32-10 61l-256 768q-10 29-28 53t-42 42-52 26-60 10h-512q-179 0-345-69-72-29-144-44t-151-15H0V768h417q65 0 122-24t104-70l622-621q25-25 50-39t61-14q33 0 62 12t51 35 34 51 13 62q0 81-18 154t-53 146q-20 43-34 87t-19 93h444zm-256 1024q20 0 37-12t24-32q5-14 18-54t33-96 42-124 46-137 44-134 39-118 27-86 10-39q0-26-19-45t-45-19h-576q0-53 2-98t10-89 22-86 37-91q28-58 42-118t15-126q0-14-9-23t-23-9q-6 0-10 4t-9 9L734 765q-32 32-68 56t-78 41q-80 34-171 34H128v640h320q178 0 345 69 144 59 295 59h512z"></path></svg></span></a> 2</span> </span>
 
 </header>
 
 
 </article>
 </li>
</ul>
</li>
 <li class="comment byuser comment-author-giwrgos-stra odd alt thread-odd thread-alt depth-1 comment-show" id=li-comment-18872 style=display:none!important>
 <article id=comment-18872 class=comment style=display:none!important>
 
 <header style=display:none!important>
 
 
 
 <span class=voting style=display:none!important><span id=loggedoutvotes18872 style=display:none!important><a class="comment-reply-login x-hidden-focus" title data-toggle=tooltip href="https://devblogs.microsoft.com/dotnet/wp-login.php?redirect_to=https%3A%2F%2Fdevblogs.microsoft.com%2Fdotnet%2Fperformance-improvements-in-net-8%2F%23comment-18872" data-bi-id=comments data-bi-name="Login to vote" aria-label="Login to vote" data-original-title="Login to vote" style=display:none!important><span class=icon-like-dislike style=display:none!important><svg xmlns=http://www.w3.org/2000/svg viewBox="0 0 2048 2048" class="svg_dd790ee3 x-hidden-focus" focusable=false><path d="M1856 640q39 0 74 15t61 41 42 61 15 75q0 32-10 61l-256 768q-10 29-28 53t-42 42-52 26-60 10h-512q-179 0-345-69-72-29-144-44t-151-15H0V768h417q65 0 122-24t104-70l622-621q25-25 50-39t61-14q33 0 62 12t51 35 34 51 13 62q0 81-18 154t-53 146q-20 43-34 87t-19 93h444zm-256 1024q20 0 37-12t24-32q5-14 18-54t33-96 42-124 46-137 44-134 39-118 27-86 10-39q0-26-19-45t-45-19h-576q0-53 2-98t10-89 22-86 37-91q28-58 42-118t15-126q0-14-9-23t-23-9q-6 0-10 4t-9 9L734 765q-32 32-68 56t-78 41q-80 34-171 34H128v640h320q178 0 345 69 144 59 295 59h512z"></path></svg></span></a> 15</span> </span>
 
 </header>
 
 
 </article>
 <ul class=children style=display:none!important>
 <li class="comment byuser comment-author-andya even depth-2 comment-show" id=li-comment-18889 style=display:none!important>
 <article id=comment-18889 class=comment style=display:none!important>
 
 <header style=display:none!important>
 
 
 
 <span class=voting style=display:none!important><span id=loggedoutvotes18889 style=display:none!important><a class="comment-reply-login x-hidden-focus" title data-toggle=tooltip href="https://devblogs.microsoft.com/dotnet/wp-login.php?redirect_to=https%3A%2F%2Fdevblogs.microsoft.com%2Fdotnet%2Fperformance-improvements-in-net-8%2F%23comment-18889" data-bi-id=comments data-bi-name="Login to vote" aria-label="Login to vote" data-original-title="Login to vote" style=display:none!important><span class=icon-like-dislike style=display:none!important><svg xmlns=http://www.w3.org/2000/svg viewBox="0 0 2048 2048" class="svg_dd790ee3 x-hidden-focus" focusable=false><path d="M1856 640q39 0 74 15t61 41 42 61 15 75q0 32-10 61l-256 768q-10 29-28 53t-42 42-52 26-60 10h-512q-179 0-345-69-72-29-144-44t-151-15H0V768h417q65 0 122-24t104-70l622-621q25-25 50-39t61-14q33 0 62 12t51 35 34 51 13 62q0 81-18 154t-53 146q-20 43-34 87t-19 93h444zm-256 1024q20 0 37-12t24-32q5-14 18-54t33-96 42-124 46-137 44-134 39-118 27-86 10-39q0-26-19-45t-45-19h-576q0-53 2-98t10-89 22-86 37-91q28-58 42-118t15-126q0-14-9-23t-23-9q-6 0-10 4t-9 9L734 765q-32 32-68 56t-78 41q-80 34-171 34H128v640h320q178 0 345 69 144 59 295 59h512z"></path></svg></span></a> 3</span> </span>
 
 </header>
 
 
 </article>
 <ul class=children style=display:none!important>
 <li class="comment byuser comment-author-reelix odd alt depth-3 comment-show" id=li-comment-19059 style=display:none!important>
 <article id=comment-19059 class=comment style=display:none!important>
 
 <header style=display:none!important>
 
 
 
 <span class=voting style=display:none!important><span id=loggedoutvotes19059 style=display:none!important><a class="comment-reply-login x-hidden-focus" title data-toggle=tooltip href="https://devblogs.microsoft.com/dotnet/wp-login.php?redirect_to=https%3A%2F%2Fdevblogs.microsoft.com%2Fdotnet%2Fperformance-improvements-in-net-8%2F%23comment-19059" data-bi-id=comments data-bi-name="Login to vote" aria-label="Login to vote" data-original-title="Login to vote" style=display:none!important><span class=icon-like-dislike style=display:none!important><svg xmlns=http://www.w3.org/2000/svg viewBox="0 0 2048 2048" class="svg_dd790ee3 x-hidden-focus" focusable=false><path d="M1856 640q39 0 74 15t61 41 42 61 15 75q0 32-10 61l-256 768q-10 29-28 53t-42 42-52 26-60 10h-512q-179 0-345-69-72-29-144-44t-151-15H0V768h417q65 0 122-24t104-70l622-621q25-25 50-39t61-14q33 0 62 12t51 35 34 51 13 62q0 81-18 154t-53 146q-20 43-34 87t-19 93h444zm-256 1024q20 0 37-12t24-32q5-14 18-54t33-96 42-124 46-137 44-134 39-118 27-86 10-39q0-26-19-45t-45-19h-576q0-53 2-98t10-89 22-86 37-91q28-58 42-118t15-126q0-14-9-23t-23-9q-6 0-10 4t-9 9L734 765q-32 32-68 56t-78 41q-80 34-171 34H128v640h320q178 0 345 69 144 59 295 59h512z"></path></svg></span></a> 2</span> </span>
 
 </header>
 
 
 </article>
 </li>
 <li class="comment byuser comment-author-mikedoublewide-co-uk even depth-3 comment-show" id=li-comment-19385 style=display:none!important>
 <article id=comment-19385 class=comment style=display:none!important>
 
 <header style=display:none!important>
 
 
 
 <span class=voting style=display:none!important><span id=loggedoutvotes19385 style=display:none!important><a class="comment-reply-login x-hidden-focus" title data-toggle=tooltip href="https://devblogs.microsoft.com/dotnet/wp-login.php?redirect_to=https%3A%2F%2Fdevblogs.microsoft.com%2Fdotnet%2Fperformance-improvements-in-net-8%2F%23comment-19385" data-bi-id=comments data-bi-name="Login to vote" aria-label="Login to vote" data-original-title="Login to vote" style=display:none!important><span class=icon-like-dislike style=display:none!important><svg xmlns=http://www.w3.org/2000/svg viewBox="0 0 2048 2048" class="svg_dd790ee3 x-hidden-focus" focusable=false><path d="M1856 640q39 0 74 15t61 41 42 61 15 75q0 32-10 61l-256 768q-10 29-28 53t-42 42-52 26-60 10h-512q-179 0-345-69-72-29-144-44t-151-15H0V768h417q65 0 122-24t104-70l622-621q25-25 50-39t61-14q33 0 62 12t51 35 34 51 13 62q0 81-18 154t-53 146q-20 43-34 87t-19 93h444zm-256 1024q20 0 37-12t24-32q5-14 18-54t33-96 42-124 46-137 44-134 39-118 27-86 10-39q0-26-19-45t-45-19h-576q0-53 2-98t10-89 22-86 37-91q28-58 42-118t15-126q0-14-9-23t-23-9q-6 0-10 4t-9 9L734 765q-32 32-68 56t-78 41q-80 34-171 34H128v640h320q178 0 345 69 144 59 295 59h512z"></path></svg></span></a> 1</span> </span>
 
 </header>
 
 
 </article>
 </li>
</ul>
</li>
 <li class="comment byuser comment-author-pjmlp_ptyahoo-com odd alt depth-2 comment-show" id=li-comment-18921 style=display:none!important>
 <article id=comment-18921 class=comment style=display:none!important>
 
 <header style=display:none!important>
 
 
 
 <span class=voting style=display:none!important><span id=loggedoutvotes18921 style=display:none!important><a class="comment-reply-login x-hidden-focus" title data-toggle=tooltip href="https://devblogs.microsoft.com/dotnet/wp-login.php?redirect_to=https%3A%2F%2Fdevblogs.microsoft.com%2Fdotnet%2Fperformance-improvements-in-net-8%2F%23comment-18921" data-bi-id=comments data-bi-name="Login to vote" aria-label="Login to vote" data-original-title="Login to vote" style=display:none!important><span class=icon-like-dislike style=display:none!important><svg xmlns=http://www.w3.org/2000/svg viewBox="0 0 2048 2048" class="svg_dd790ee3 x-hidden-focus" focusable=false><path d="M1856 640q39 0 74 15t61 41 42 61 15 75q0 32-10 61l-256 768q-10 29-28 53t-42 42-52 26-60 10h-512q-179 0-345-69-72-29-144-44t-151-15H0V768h417q65 0 122-24t104-70l622-621q25-25 50-39t61-14q33 0 62 12t51 35 34 51 13 62q0 81-18 154t-53 146q-20 43-34 87t-19 93h444zm-256 1024q20 0 37-12t24-32q5-14 18-54t33-96 42-124 46-137 44-134 39-118 27-86 10-39q0-26-19-45t-45-19h-576q0-53 2-98t10-89 22-86 37-91q28-58 42-118t15-126q0-14-9-23t-23-9q-6 0-10 4t-9 9L734 765q-32 32-68 56t-78 41q-80 34-171 34H128v640h320q178 0 345 69 144 59 295 59h512z"></path></svg></span></a> 1</span> </span>
 
 </header>
 
 
 </article>
 <ul class=children style=display:none!important>
 <li class="comment byuser comment-author-danieldsmith even depth-3 comment-show" id=li-comment-18967 style=display:none!important>
 <article id=comment-18967 class=comment style=display:none!important>
 
 <header style=display:none!important>
 
 
 
 <span class=voting style=display:none!important><span id=loggedoutvotes18967 style=display:none!important><a class="comment-reply-login x-hidden-focus" title data-toggle=tooltip href="https://devblogs.microsoft.com/dotnet/wp-login.php?redirect_to=https%3A%2F%2Fdevblogs.microsoft.com%2Fdotnet%2Fperformance-improvements-in-net-8%2F%23comment-18967" data-bi-id=comments data-bi-name="Login to vote" aria-label="Login to vote" data-original-title="Login to vote" style=display:none!important><span class=icon-like-dislike style=display:none!important><svg xmlns=http://www.w3.org/2000/svg viewBox="0 0 2048 2048" class="svg_dd790ee3 x-hidden-focus" focusable=false><path d="M1856 640q39 0 74 15t61 41 42 61 15 75q0 32-10 61l-256 768q-10 29-28 53t-42 42-52 26-60 10h-512q-179 0-345-69-72-29-144-44t-151-15H0V768h417q65 0 122-24t104-70l622-621q25-25 50-39t61-14q33 0 62 12t51 35 34 51 13 62q0 81-18 154t-53 146q-20 43-34 87t-19 93h444zm-256 1024q20 0 37-12t24-32q5-14 18-54t33-96 42-124 46-137 44-134 39-118 27-86 10-39q0-26-19-45t-45-19h-576q0-53 2-98t10-89 22-86 37-91q28-58 42-118t15-126q0-14-9-23t-23-9q-6 0-10 4t-9 9L734 765q-32 32-68 56t-78 41q-80 34-171 34H128v640h320q178 0 345 69 144 59 295 59h512z"></path></svg></span></a> 2</span> </span>
 
 </header>
 
 
 </article>
 <ul class=children style=display:none!important>
 <li class="comment byuser comment-author-eric-spencer odd alt depth-4 comment-show" id=li-comment-19061 style=display:none!important>
 <article id=comment-19061 class=comment style=display:none!important>
 
 <header style=display:none!important>
 
 
 
 <span class=voting style=display:none!important><span id=loggedoutvotes19061 style=display:none!important><a class="comment-reply-login x-hidden-focus" title data-toggle=tooltip href="https://devblogs.microsoft.com/dotnet/wp-login.php?redirect_to=https%3A%2F%2Fdevblogs.microsoft.com%2Fdotnet%2Fperformance-improvements-in-net-8%2F%23comment-19061" data-bi-id=comments data-bi-name="Login to vote" aria-label="Login to vote" data-original-title="Login to vote" style=display:none!important><span class=icon-like-dislike style=display:none!important><svg xmlns=http://www.w3.org/2000/svg viewBox="0 0 2048 2048" class="svg_dd790ee3 x-hidden-focus" focusable=false><path d="M1856 640q39 0 74 15t61 41 42 61 15 75q0 32-10 61l-256 768q-10 29-28 53t-42 42-52 26-60 10h-512q-179 0-345-69-72-29-144-44t-151-15H0V768h417q65 0 122-24t104-70l622-621q25-25 50-39t61-14q33 0 62 12t51 35 34 51 13 62q0 81-18 154t-53 146q-20 43-34 87t-19 93h444zm-256 1024q20 0 37-12t24-32q5-14 18-54t33-96 42-124 46-137 44-134 39-118 27-86 10-39q0-26-19-45t-45-19h-576q0-53 2-98t10-89 22-86 37-91q28-58 42-118t15-126q0-14-9-23t-23-9q-6 0-10 4t-9 9L734 765q-32 32-68 56t-78 41q-80 34-171 34H128v640h320q178 0 345 69 144 59 295 59h512z"></path></svg></span></a> 4</span> </span>
 
 </header>
 
 
 </article>
 <ul class=children style=display:none!important>
 <li class="comment byuser comment-author-danieldsmith even depth-5 comment-show" id=li-comment-19082 style=display:none!important>
 <article id=comment-19082 class=comment style=display:none!important>
 
 <header style=display:none!important>
 
 
 
 <span class=voting style=display:none!important><span id=loggedoutvotes19082 style=display:none!important><a class="comment-reply-login x-hidden-focus" title data-toggle=tooltip href="https://devblogs.microsoft.com/dotnet/wp-login.php?redirect_to=https%3A%2F%2Fdevblogs.microsoft.com%2Fdotnet%2Fperformance-improvements-in-net-8%2F%23comment-19082" data-bi-id=comments data-bi-name="Login to vote" aria-label="Login to vote" data-original-title="Login to vote" style=display:none!important><span class=icon-like-dislike style=display:none!important><svg xmlns=http://www.w3.org/2000/svg viewBox="0 0 2048 2048" class="svg_dd790ee3 x-hidden-focus" focusable=false><path d="M1856 640q39 0 74 15t61 41 42 61 15 75q0 32-10 61l-256 768q-10 29-28 53t-42 42-52 26-60 10h-512q-179 0-345-69-72-29-144-44t-151-15H0V768h417q65 0 122-24t104-70l622-621q25-25 50-39t61-14q33 0 62 12t51 35 34 51 13 62q0 81-18 154t-53 146q-20 43-34 87t-19 93h444zm-256 1024q20 0 37-12t24-32q5-14 18-54t33-96 42-124 46-137 44-134 39-118 27-86 10-39q0-26-19-45t-45-19h-576q0-53 2-98t10-89 22-86 37-91q28-58 42-118t15-126q0-14-9-23t-23-9q-6 0-10 4t-9 9L734 765q-32 32-68 56t-78 41q-80 34-171 34H128v640h320q178 0 345 69 144 59 295 59h512z"></path></svg></span></a> 1</span> </span>
 
 </header>
 
 
 </article>
 </li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
 <li class="comment byuser comment-author-emil-kalchev odd alt depth-2 comment-show" id=li-comment-19057 style=display:none!important>
 <article id=comment-19057 class=comment style=display:none!important>
 
 <header style=display:none!important>
 
 
 
 <span class=voting style=display:none!important><span id=loggedoutvotes19057 style=display:none!important><a class="comment-reply-login x-hidden-focus" title data-toggle=tooltip href="https://devblogs.microsoft.com/dotnet/wp-login.php?redirect_to=https%3A%2F%2Fdevblogs.microsoft.com%2Fdotnet%2Fperformance-improvements-in-net-8%2F%23comment-19057" data-bi-id=comments data-bi-name="Login to vote" aria-label="Login to vote" data-original-title="Login to vote" style=display:none!important><span class=icon-like-dislike style=display:none!important><svg xmlns=http://www.w3.org/2000/svg viewBox="0 0 2048 2048" class="svg_dd790ee3 x-hidden-focus" focusable=false><path d="M1856 640q39 0 74 15t61 41 42 61 15 75q0 32-10 61l-256 768q-10 29-28 53t-42 42-52 26-60 10h-512q-179 0-345-69-72-29-144-44t-151-15H0V768h417q65 0 122-24t104-70l622-621q25-25 50-39t61-14q33 0 62 12t51 35 34 51 13 62q0 81-18 154t-53 146q-20 43-34 87t-19 93h444zm-256 1024q20 0 37-12t24-32q5-14 18-54t33-96 42-124 46-137 44-134 39-118 27-86 10-39q0-26-19-45t-45-19h-576q0-53 2-98t10-89 22-86 37-91q28-58 42-118t15-126q0-14-9-23t-23-9q-6 0-10 4t-9 9L734 765q-32 32-68 56t-78 41q-80 34-171 34H128v640h320q178 0 345 69 144 59 295 59h512z"></path></svg></span></a> 2</span> </span>
 
 </header>
 
 
 </article>
 </li>
</ul>
</li>
 </ul>
 
 </div>
 
 
 </div>
 </div>
</div>
</div>
 
</main>
<div class=wrapper id=wrapper-footer-1 style=display:none!important>
 
 <section class=container style=display:none!important>
 <div class=row style=display:none!important>
 <div class=col-12 style=display:none!important>
 <nav class=site-footer id=colophon aria-label="Secondary Footer Navigation" style=display:none!important>
 
 <div class="row justify-content-center featuresectiontwo" style=display:none!important>
 <div class=col-10 style=display:none!important>
 <div class=col-12 style=display:none!important><a class="no-underline stayinformedsite" title=twitter data-bi-id="follow blog within post" data-bi-name="blog follow post-.NET Blog-twitter" aria-label="Follow Us on Twitter" target=_blank href=https://aka.ms/dotnet/twitter style=display:none!important><svg xmlns=http://www.w3.org/2000/svg class="f-twitter-x hvr-pop" width=32 height=32 fill=#666 viewBox="0 0 512 512"><path d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8L200.7 275.5 26.8 48H172.4L272.9 180.9 389.2 48zM364.4 421.8h39.1L151.1 88h-42L364.4 421.8z"></path></svg></a></div>
 </div>
 </div>
 </nav>
 </div>
 </div>
 </section>
</div>
</div>
<div class=social-icon-bar data-bi-id="left gutter" style=display:none!important>
 <div class=social-icon-general style=display:none!important>
 
 <a href="https://twitter.com/intent/tweet?url=https://devblogs.microsoft.com/dotnet/performance-improvements-in-net-8/&amp;text=Performance%20Improvements%20in%20.NET%208" title="Share on Twitter" aria-label="Share on Twitter" target=_blank rel="noopener noreferrer nofollow" class=twitter style=display:none!important><svg xmlns=http://www.w3.org/2000/svg class=sd-twitter-x width=18 height=18 fill=#3c3c3c viewBox="0 0 512 512"><path d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8L200.7 275.5 26.8 48H172.4L272.9 180.9 389.2 48zM364.4 421.8h39.1L151.1 88h-42L364.4 421.8z"></path></svg></a>
 
 </div>
 
</div>
 
 
 
 
 <style>pre code.hljs{display:block;overflow-x:auto;padding:1em}.hljs-keyword{font-weight:700}.hljs-number{color:#800}.hljs-title{font-weight:700}pre .hljs-comment{color:#008000}pre .hljs-keyword,pre .hljs-built_in{color:#0101fd}pre .hljs-literal{color:#07704a}pre .hljs-string{color:#a31515}pre .hljs-type,pre .hljs-title{color:#006881}</style>
 
 
 
 
<div id=footerArea class=uhf data-m='{"cN":"footerArea","cT":"Area_coreuiArea","id":"a2Body","sN":2,"aN":"Body"}' style=display:none!important>
 <div id=footerRegion data-region-key=footerregion data-m='{"cN":"footerRegion","cT":"Region_coreui-region","id":"r1a2","sN":1,"aN":"a2"}' style=display:none!important>
 <div id=footerUniversalFooter data-m='{"cN":"footerUniversalFooter","cT":"Module_coreui-universalfooter","id":"m1r1a2","sN":1,"aN":"r1a2"}' data-module-id=Category|footerRegion|coreui-region|footerUniversalFooter|coreui-universalfooter style=display:none!important>
 
<footer id=uhf-footer class="c-uhff context-uhf" data-uhf-mscc-rq=false data-footer-footprint="/DEV_Blogs/DEV_BlogsFooter, fromService: True" data-m='{"cN":"Uhf footer_cont","cT":"Container","id":"c1m1r1a2","sN":1,"aN":"m1r1a2"}' style=display:none!important>
 
 <div class=c-uhff-base style=display:none!important>
 
 <a data-m='{"id":"n7c1c1m1r1a2","sN":7,"aN":"c1c1m1r1a2"}' href=https://aka.ms/yourcaliforniaprivacychoices class="c-uhff-link c-uhff-ccpa" target=_blank style=display:none!important>
 <svg role=img xmlns=http://www.w3.org/2000/svg viewBox="0 0 30 14" xml:space=preserve height=16 width=43>
 <title>California Consumer Privacy Act (CCPA) Opt-Out Icon</title>
 <path d="M7.4 12.8h6.8l3.1-11.6H7.4C4.2 1.2 1.6 3.8 1.6 7s2.6 5.8 5.8 5.8z" style=fill-rule:evenodd;clip-rule:evenodd;fill:#fff></path>
 <path d="M22.6 0H7.4c-3.9 0-7 3.1-7 7s3.1 7 7 7h15.2c3.9 0 7-3.1 7-7s-3.2-7-7-7zm-21 7c0-3.2 2.6-5.8 5.8-5.8h9.9l-3.1 11.6H7.4c-3.2 0-5.8-2.6-5.8-5.8z" style=fill-rule:evenodd;clip-rule:evenodd;fill:#06f></path>
 <path d="M24.6 4c.2.2.2.6 0 .8L22.5 7l2.2 2.2c.2.2.2.6 0 .8-.2.2-.6.2-.8 0l-2.2-2.2-2.2 2.2c-.2.2-.6.2-.8 0-.2-.2-.2-.6 0-.8L20.8 7l-2.2-2.2c-.2-.2-.2-.6 0-.8.2-.2.6-.2.8 0l2.2 2.2L23.8 4c.2-.2.6-.2.8 0z" style=fill:#fff></path>
 <path d="M12.7 4.1c.2.2.3.6.1.8L8.6 9.8c-.1.1-.2.2-.3.2-.2.1-.5.1-.7-.1L5.4 7.7c-.2-.2-.2-.6 0-.8.2-.2.6-.2.8 0L8 8.6l3.8-4.5c.2-.2.6-.2.9 0z" style=fill:#06f></path>
 </svg>
 
 </a>
 
 
 </div>
 
</footer>
 </div>
 </div>
 </div>
<div class=usabilla_live_button_container id=usabilla_live_button_container_409847393 role=button tabindex=0 aria-label="Usabilla Feedback Button" style=display:none!important></div>